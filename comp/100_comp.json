{"count": 24749, "results": [{"publisher": {"name": ""}, "description": "  We present an unsupervised framework for simultaneous appearance-based object\ndiscovery, detection, tracking and reconstruction using RGBD cameras and a\nrobot manipulator. The system performs dense 3D simultaneous localization and\nmapping concurrently with unsupervised object discovery. Putative objects that\nare spatially and visually coherent are manipulated by the robot to gain\nadditional motion-cues. The robot uses appearance alone, followed by structure\nand motion cues, to jointly discover, verify, learn and improve models of\nobjects. Induced motion segmentation reinforces learned models which are\nrepresented implicitly as 2D and 3D level sets to capture both shape and\nappearance. We compare three different approaches for appearance-based object\ndiscovery and find that a novel form of spatio-temporal super-pixels gives the\nhighest quality candidate object models in terms of precision and recall. Live\nexperiments with a Baxter robot demonstrate a holistic pipeline capable of\nautomatic discovery, verification, detection, tracking and reconstruction of\nunknown objects.\n", "contributors": [{"name": "Ma, Lu", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Lu", "email": ""}, {"name": "Ghafarianzadeh, Mahsa", "sameAs": [], "familyName": "Ghafarianzadeh", "additionalName": "", "givenName": "Mahsa", "email": ""}, {"name": "Coleman, Dave", "sameAs": [], "familyName": "Coleman", "additionalName": "", "givenName": "Dave", "email": ""}, {"name": "Correll, Nikolaus", "sameAs": [], "familyName": "Correll", "additionalName": "", "givenName": "Nikolaus", "email": ""}, {"name": "Sibley, Gabe", "sameAs": [], "familyName": "Sibley", "additionalName": "", "givenName": "Gabe", "email": ""}], "title": "Simultaneous Localization, Mapping, and Manipulation for Unsupervised\n  Object Discovery", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.0802", "oai:arXiv.org:1411.0802"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We present an unsupervised framework for simultaneous appearance-based object\ndiscovery, detection, tracking and reconstruction using RGBD cameras and a\nrobot manipulator. The system performs dense 3D simultaneous localization and\nmapping concurrently with unsupervised object discovery. Putative objects that\nare spatially and visually coherent are manipulated by the robot to gain\nadditional motion-cues. The robot uses appearance alone, followed by structure\nand motion cues, to jointly discover, verify, learn and improve models of\nobjects. Induced motion segmentation reinforces learned models which are\nrepresented implicitly as 2D and 3D level sets to capture both shape and\nappearance. We compare three different approaches for appearance-based object\ndiscovery and find that a novel form of spatio-temporal super-pixels gives the\nhighest quality candidate object models in terms of precision and recall. Live\nexperiments with a Baxter robot demonstrate a holistic pipeline capable of\nautomatic discovery, verification, detection, tracking and reconstruction of\nunknown objects.\n"}}], "languages": [null], "subjects": ["computer science - robotics", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.0802"}}, {"publisher": {"name": ""}, "description": "  In contrast to today's IP-based host-oriented Internet architecture,\nInformation-Centric Networking (ICN) emphasizes content by making it directly\naddressable and routable. Named Data Networking (NDN) architecture is an\ninstance of ICN that is being developed as a candidate next-generation Internet\narchitecture. By opportunistically caching content within the network (in\nrouters), NDN appears to be well-suited for large-scale content distribution\nand for meeting the needs of increasingly mobile and bandwidth-hungry\napplications that dominate today's Internet.\n  One key feature of NDN is the requirement for each content object to be\ndigitally signed by its producer. Thus, NDN should be, in principle, immune to\ndistributing fake (aka \"poisoned\") content. However, in practice, this poses\ntwo challenges for detecting fake content in NDN routers: (1) overhead due to\nsignature verification and certificate chain traversal, and (2) lack of trust\ncontext, i.e., determining which public keys are trusted to verify which\ncontent. Because of these issues, NDN does not force routers to verify content\nsignatures, which makes the architecture susceptible to content poisoning\nattacks.\n  This paper explores root causes of, and some cures for, content poisoning\nattacks in NDN. In the process, it becomes apparent that meaningful mitigation\nof content poisoning is contingent upon a network-layer trust management\narchitecture, elements of which we construct while carefully justifying\nspecific design choices. This work represents the initial effort towards\ncomprehensive trust management for NDN.\n", "contributors": [{"name": "Ghali, Cesar", "sameAs": [], "familyName": "Ghali", "additionalName": "", "givenName": "Cesar", "email": ""}, {"name": "Tsudik, Gene", "sameAs": [], "familyName": "Tsudik", "additionalName": "", "givenName": "Gene", "email": ""}, {"name": "Uzun, Ersin", "sameAs": [], "familyName": "Uzun", "additionalName": "", "givenName": "Ersin", "email": ""}], "title": "Elements of Trust in Named-Data Networking", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-13", "2014-10-30"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.3332", "ACM SIGCOMM Computer Communication Review, Volume 44 Issue 5,\n  October 2014", "doi:10.1145/2677046.2677049", "oai:arXiv.org:1402.3332"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In contrast to today's IP-based host-oriented Internet architecture,\nInformation-Centric Networking (ICN) emphasizes content by making it directly\naddressable and routable. Named Data Networking (NDN) architecture is an\ninstance of ICN that is being developed as a candidate next-generation Internet\narchitecture. By opportunistically caching content within the network (in\nrouters), NDN appears to be well-suited for large-scale content distribution\nand for meeting the needs of increasingly mobile and bandwidth-hungry\napplications that dominate today's Internet.\n  One key feature of NDN is the requirement for each content object to be\ndigitally signed by its producer. Thus, NDN should be, in principle, immune to\ndistributing fake (aka \"poisoned\") content. However, in practice, this poses\ntwo challenges for detecting fake content in NDN routers: (1) overhead due to\nsignature verification and certificate chain traversal, and (2) lack of trust\ncontext, i.e., determining which public keys are trusted to verify which\ncontent. Because of these issues, NDN does not force routers to verify content\nsignatures, which makes the architecture susceptible to content poisoning\nattacks.\n  This paper explores root causes of, and some cures for, content poisoning\nattacks in NDN. In the process, it becomes apparent that meaningful mitigation\nof content poisoning is contingent upon a network-layer trust management\narchitecture, elements of which we construct while carefully justifying\nspecific design choices. This work represents the initial effort towards\ncomprehensive trust management for NDN.\n", "Comment: 9 pages, 2 figures"]}}], "languages": [null], "subjects": ["computer science - cryptography and security", "computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-10-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.3332"}}, {"publisher": {"name": ""}, "description": "  We consider channel/subspace tracking systems for temporally correlated\nmillimeter wave (e.g., E-band) multiple-input multiple-output (MIMO) channels.\nOur focus is given to the tracking algorithm in the non-line-of-sight (NLoS)\nenvironment, where the transmitter and the receiver are equipped with hybrid\nanalog/digital precoder and combiner, respectively. In the absence of\nstraightforward time-correlated channel model in the millimeter wave MIMO\nliterature, we present a temporal MIMO channel evolution model for NLoS\nmillimeter wave scenarios. Considering that conventional MIMO channel tracking\nalgorithms in microwave bands are not directly applicable, we propose a new\nchannel tracking technique based on sequentially updating the precoder and\ncombiner. Numerical results demonstrate the superior channel tracking ability\nof the proposed technique over independent sounding approach in the presented\nchannel model and the spatial channel model (SCM) adopted in 3GPP\nspecification.\n", "contributors": [{"name": "He, Jiguang", "sameAs": [], "familyName": "He", "additionalName": "", "givenName": "Jiguang", "email": ""}, {"name": "Kim, Taejoon", "sameAs": [], "familyName": "Kim", "additionalName": "", "givenName": "Taejoon", "email": ""}, {"name": "Ghauch, Hadi", "sameAs": [], "familyName": "Ghauch", "additionalName": "", "givenName": "Hadi", "email": ""}, {"name": "Liu, Kunpeng", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Kunpeng", "email": ""}, {"name": "Wang, Guangjian", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Guangjian", "email": ""}], "title": "Millimeter Wave MIMO Channel Tracking Systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.4224", "oai:arXiv.org:1412.4224"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We consider channel/subspace tracking systems for temporally correlated\nmillimeter wave (e.g., E-band) multiple-input multiple-output (MIMO) channels.\nOur focus is given to the tracking algorithm in the non-line-of-sight (NLoS)\nenvironment, where the transmitter and the receiver are equipped with hybrid\nanalog/digital precoder and combiner, respectively. In the absence of\nstraightforward time-correlated channel model in the millimeter wave MIMO\nliterature, we present a temporal MIMO channel evolution model for NLoS\nmillimeter wave scenarios. Considering that conventional MIMO channel tracking\nalgorithms in microwave bands are not directly applicable, we propose a new\nchannel tracking technique based on sequentially updating the precoder and\ncombiner. Numerical results demonstrate the superior channel tracking ability\nof the proposed technique over independent sounding approach in the presented\nchannel model and the spatial channel model (SCM) adopted in 3GPP\nspecification.\n", "Comment: 6 pages, 3 figures, conference"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.4224"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "One of the primary problems in constructing risk-stratification models for medical applications is that the data are often noisy, incomplete, and suffer from high class-imbalance. This problem becomes more severe when the total amount of data relevant to the task of interest is small. We address this problem in the context of risk-stratifying patients receiving isolated surgical aortic valve replacements (isolated AVR) for the adverse outcomes of operative mortality and stroke. We work with data from two hospitals (Hospital 1 and Hospital 2) in the Society of Thoracic Surgeons (STS) Adult Cardiac Surgery Database. Because the data available for our application of interest (target data) are limited, developing an accurate model using only these data is infeasible. Instead, we investigate transfer learning approaches to utilize data from other cardiac surgery procedures as well as from other institutions (source data). We first evaluate the effectiveness of leveraging information across procedures within a single hospital. We achieve significant improvements over baseline: at Hospital 1, the average AUC for operative mortality increased from 0.58 to 0.70. However, not all source examples are equally useful. Next, we evaluate the effectiveness of leveraging data across hospitals. We show that leveraging information across hospitals has variable utility; although it can result in worse performance (average AUC for stroke at Hospital 1 dropped from 0.61 to 0.56), it can also lead to significant improvements (average AUC for operative mortality at Hospital 1 increased from 0.70 to 0.72). Finally, we present an automated approach to leveraging the available source data. We investigate how removing source data based on how far they are from the mean of the target data affects performance. We propose an instance-weighting scheme based on these distances. This automated instance-weighting approach can achieve small, but significant improvements over using all of the data without weights (average AUC for operative mortality at Hospital 1 increased from 0.72 to 0.73). Research on these methods can have an important impact on the development of clinical risk-stratification tools targeted towards specific patient populations.", "contributors": [{"name": "Gong, Jen J. (Jen Jian)", "sameAs": [], "familyName": "Gong", "additionalName": "J.", "givenName": "Jen", "email": ""}, {"name": "Massachusetts Institute of Technology. Department of Electrical Engineering and Computer Science.", "sameAs": [], "familyName": "Science.", "additionalName": "Institute of Technology. Department of Electrical Engineering and Computer", "givenName": "Massachusetts", "email": ""}, {"name": "John V. Guttag.", "sameAs": [], "familyName": "Guttag.", "additionalName": "V.", "givenName": "John", "email": ""}], "title": "Improving clinical risk-stratification tools : instance-transfer for selecting relevant training data", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "71 pages"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/91090", "892724540", "oai:dspace.mit.edu:1721.1/91090"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2014-10-21T17:25:32Z", "2014-10-21T17:25:32Z", "2014", "2014"]}}, {"name": "description", "properties": {"description": ["One of the primary problems in constructing risk-stratification models for medical applications is that the data are often noisy, incomplete, and suffer from high class-imbalance. This problem becomes more severe when the total amount of data relevant to the task of interest is small. We address this problem in the context of risk-stratifying patients receiving isolated surgical aortic valve replacements (isolated AVR) for the adverse outcomes of operative mortality and stroke. We work with data from two hospitals (Hospital 1 and Hospital 2) in the Society of Thoracic Surgeons (STS) Adult Cardiac Surgery Database. Because the data available for our application of interest (target data) are limited, developing an accurate model using only these data is infeasible. Instead, we investigate transfer learning approaches to utilize data from other cardiac surgery procedures as well as from other institutions (source data). We first evaluate the effectiveness of leveraging information across procedures within a single hospital. We achieve significant improvements over baseline: at Hospital 1, the average AUC for operative mortality increased from 0.58 to 0.70. However, not all source examples are equally useful. Next, we evaluate the effectiveness of leveraging data across hospitals. We show that leveraging information across hospitals has variable utility; although it can result in worse performance (average AUC for stroke at Hospital 1 dropped from 0.61 to 0.56), it can also lead to significant improvements (average AUC for operative mortality at Hospital 1 increased from 0.70 to 0.72). Finally, we present an automated approach to leveraging the available source data. We investigate how removing source data based on how far they are from the mean of the target data affects performance. We propose an instance-weighting scheme based on these distances. This automated instance-weighting approach can achieve small, but significant improvements over using all of the data without weights (average AUC for operative mortality at Hospital 1 increased from 0.72 to 0.73). Research on these methods can have an important impact on the development of clinical risk-stratification tools targeted towards specific patient populations.", "by Jen J. Gong.", "Thesis: S.M. in Computer Science and Engineering, Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science, 2014.", "52", "Cataloged from PDF version of thesis.", "Includes bibliographical references (pages 66-71)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_7817", "hdl_1721.1_7663"]}}], "languages": [null], "subjects": ["electrical engineering and computer science."], "providerUpdatedDateTime": "2015-04-09T06:21:41", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/91090"}}, {"publisher": {"name": ""}, "description": "  TCP and its variants have suffered from surprisingly poor performance for\ndecades. We argue the TCP family has little hope to achieve consistent high\nperformance due to a fundamental architectural deficiency: hardwiring\npacket-level events to control responses without understanding the real\nperformance result of its actions. We propose Performance-oriented Congestion\nControl (PCC), a new congestion control architecture in which each sender\ncontinuously observes the connection between its actions and empirically\nexperienced performance, enabling it to consistently adopt actions that result\nin high performance. We prove that PCC converges to a stable and fair\nequilibrium. Across many real-world and challenging environments, PCC shows\nconsistent and often 10x performance improvement, with better fairness and\nstability than TCP. PCC requires no router hardware support or new packet\nformat.\n", "contributors": [{"name": "Dong, Mo", "sameAs": [], "familyName": "Dong", "additionalName": "", "givenName": "Mo", "email": ""}, {"name": "Li, Qingxi", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Qingxi", "email": ""}, {"name": "Zarchy, Doron", "sameAs": [], "familyName": "Zarchy", "additionalName": "", "givenName": "Doron", "email": ""}, {"name": "Godfrey, Brighten", "sameAs": [], "familyName": "Godfrey", "additionalName": "", "givenName": "Brighten", "email": ""}, {"name": "Schapira, Michael", "sameAs": [], "familyName": "Schapira", "additionalName": "", "givenName": "Michael", "email": ""}], "title": "PCC: Re-architecting Congestion Control for Consistent High Performance", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-24", "2014-09-30"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.7092", "oai:arXiv.org:1409.7092"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  TCP and its variants have suffered from surprisingly poor performance for\ndecades. We argue the TCP family has little hope to achieve consistent high\nperformance due to a fundamental architectural deficiency: hardwiring\npacket-level events to control responses without understanding the real\nperformance result of its actions. We propose Performance-oriented Congestion\nControl (PCC), a new congestion control architecture in which each sender\ncontinuously observes the connection between its actions and empirically\nexperienced performance, enabling it to consistently adopt actions that result\nin high performance. We prove that PCC converges to a stable and fair\nequilibrium. Across many real-world and challenging environments, PCC shows\nconsistent and often 10x performance improvement, with better fairness and\nstability than TCP. PCC requires no router hardware support or new packet\nformat.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-10-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.7092"}}, {"publisher": {"name": ""}, "description": "  Mean Field Variational Bayes (MFVB) is a popular posterior approximation\nmethod due to its fast runtime on large-scale data sets. However, it is well\nknown that a major failing of MFVB is its (sometimes severe) underestimates of\nthe uncertainty of model variables and lack of information about model variable\ncovariance. We develop a fast, general methodology for exponential families\nthat augments MFVB to deliver accurate uncertainty estimates for model\nvariables -- both for individual variables and coherently across variables.\nMFVB for exponential families defines a fixed-point equation in the means of\nthe approximating posterior, and our approach yields a covariance estimate by\nperturbing this fixed point. Inspired by linear response theory, we call our\nmethod linear response variational Bayes (LRVB). We demonstrate the accuracy of\nour method on simulated data sets.\n", "contributors": [{"name": "Giordano, Ryan", "sameAs": [], "familyName": "Giordano", "additionalName": "", "givenName": "Ryan", "email": ""}, {"name": "Broderick, Tamara", "sameAs": [], "familyName": "Broderick", "additionalName": "", "givenName": "Tamara", "email": ""}], "title": "Covariance Matrices for Mean Field Variational Bayes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.6853", "oai:arXiv.org:1410.6853"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Mean Field Variational Bayes (MFVB) is a popular posterior approximation\nmethod due to its fast runtime on large-scale data sets. However, it is well\nknown that a major failing of MFVB is its (sometimes severe) underestimates of\nthe uncertainty of model variables and lack of information about model variable\ncovariance. We develop a fast, general methodology for exponential families\nthat augments MFVB to deliver accurate uncertainty estimates for model\nvariables -- both for individual variables and coherently across variables.\nMFVB for exponential families defines a fixed-point equation in the means of\nthe approximating posterior, and our approach yields a covariance estimate by\nperturbing this fixed point. Inspired by linear response theory, we call our\nmethod linear response variational Bayes (LRVB). We demonstrate the accuracy of\nour method on simulated data sets.\n", "Comment: 12 pages, 2 figures"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning", "statistics - methodology"], "providerUpdatedDateTime": "2014-10-28T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.6853"}}, {"publisher": {"name": ""}, "description": "  Based on the axiomatization of reversible computing RACP, we generalize it to\nquantum reversible computing which is called qRACP. By use of the framework of\nquantum configuration, we show that structural reversibility and quantum state\nreversibility must be satisfied simultaneously in quantum reversible\ncomputation. RACP and qRACP has the same axiomatization modulo the so-called\nquantum forward-reverse bisimularity, that is, classical reversible computing\nand quantum reversible computing are unified.\n", "contributors": [{"name": "Wang, Yong", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Yong", "email": ""}], "title": "An Algebra of Reversible Quantum Computing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05260", "oai:arXiv.org:1501.05260"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Based on the axiomatization of reversible computing RACP, we generalize it to\nquantum reversible computing which is called qRACP. By use of the framework of\nquantum configuration, we show that structural reversibility and quantum state\nreversibility must be satisfied simultaneously in quantum reversible\ncomputation. RACP and qRACP has the same axiomatization modulo the so-called\nquantum forward-reverse bisimularity, that is, classical reversible computing\nand quantum reversible computing are unified.\n", "Comment: arXiv admin note: substantial text overlap with arXiv:1311.2960,\n  arXiv:1410.5131, arXiv:1312.0686, arXiv:1404.0665"]}}], "languages": [null], "subjects": ["computer science - logic in computer science"], "providerUpdatedDateTime": "2015-01-22T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05260"}}, {"publisher": {"name": ""}, "description": "  Distributed Opportunistic Scheduling (DOS) is inherently harder than\nconventional opportunistic scheduling due to the absence of a central entity\nthat has knowledge of all the channel states. With DOS, stations contend for\nthe channel using random access; after a successful contention, they measure\nthe channel conditions and only transmit in case of a good channel, while\ngiving up the transmission opportunity when the channel conditions are poor.\nThe distributed nature of DOS systems makes them vulnerable to selfish users:\nby deviating from the protocol and using more transmission opportunities, a\nselfish user can gain a greater share of the wireless resources at the expense\nof the well-behaved users. In this paper, we address the selfishness problem in\nDOS from a game theoretic standpoint. We propose an algorithm that satisfies\nthe following properties: (i) when all stations implement the algorithm, the\nwireless network is driven to the optimal point of operation, and (ii) one or\nmore selfish stations cannot gain any profit by deviating from the algorithm.\nThe key idea of the algorithm is to react to a selfish station by using a more\naggressive configuration that (indirectly) punishes this station. We build on\nmultivariable control theory to design a mechanism for punishment that on the\none hand is sufficiently severe to prevent selfish behavior while on the other\nhand is light enough to guarantee that, in the absence of selfish behavior, the\nsystem is stable and converges to the optimum point of operation. We conduct a\ngame theoretic analysis based on repeated games to show the algorithm's\neffectiveness against selfish stations. These results are confirmed by\nextensive simulations.\n", "contributors": [{"name": "Banchs, Albert", "sameAs": [], "familyName": "Banchs", "additionalName": "", "givenName": "Albert", "email": ""}, {"name": "Garcia-Saavedra, Andres", "sameAs": [], "familyName": "Garcia-Saavedra", "additionalName": "", "givenName": "Andres", "email": ""}, {"name": "Serrano, Pablo", "sameAs": [], "familyName": "Serrano", "additionalName": "", "givenName": "Pablo", "email": ""}, {"name": "Widmer, Joerg", "sameAs": [], "familyName": "Widmer", "additionalName": "", "givenName": "Joerg", "email": ""}], "title": "A Game Theoretic Approach to Distributed Opportunistic Scheduling", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-07-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1107.4452", "oai:arXiv.org:1107.4452"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Distributed Opportunistic Scheduling (DOS) is inherently harder than\nconventional opportunistic scheduling due to the absence of a central entity\nthat has knowledge of all the channel states. With DOS, stations contend for\nthe channel using random access; after a successful contention, they measure\nthe channel conditions and only transmit in case of a good channel, while\ngiving up the transmission opportunity when the channel conditions are poor.\nThe distributed nature of DOS systems makes them vulnerable to selfish users:\nby deviating from the protocol and using more transmission opportunities, a\nselfish user can gain a greater share of the wireless resources at the expense\nof the well-behaved users. In this paper, we address the selfishness problem in\nDOS from a game theoretic standpoint. We propose an algorithm that satisfies\nthe following properties: (i) when all stations implement the algorithm, the\nwireless network is driven to the optimal point of operation, and (ii) one or\nmore selfish stations cannot gain any profit by deviating from the algorithm.\nThe key idea of the algorithm is to react to a selfish station by using a more\naggressive configuration that (indirectly) punishes this station. We build on\nmultivariable control theory to design a mechanism for punishment that on the\none hand is sufficiently severe to prevent selfish behavior while on the other\nhand is light enough to guarantee that, in the absence of selfish behavior, the\nsystem is stable and converges to the optimum point of operation. We conduct a\ngame theoretic analysis based on repeated games to show the algorithm's\neffectiveness against selfish stations. These results are confirmed by\nextensive simulations.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1107.4452"}}, {"publisher": {"name": ""}, "description": "  Security metrics serve as a powerful tool for organizations to understand the\neffectiveness of protecting computer networks. However majority of these\nmeasurement techniques don't adequately help corporations to make informed risk\nmanagement decisions. In this paper we present a stochastic security framework\nfor obtaining quantitative measures of security by taking into account the\ndynamic attributes associated with vulnerabilities that can change over time.\nOur model is novel as existing research in attack graph analysis do not\nconsider the temporal aspects associated with the vulnerabilities, such as the\navailability of exploits and patches which can affect the overall network\nsecurity based on how the vulnerabilities are interconnected and leveraged to\ncompromise the system. In order to have a more realistic representation of how\nthe security state of the network would vary over time, a nonhomogeneous model\nis developed which incorporates a time dependent covariate, namely the\nvulnerability age. The daily transition-probability matrices are estimated\nusing Frei's Vulnerability Lifecycle model. We also leverage the trusted CVSS\nmetric domain to analyze how the total exploitability and impact measures\nevolve over a time period for a given network.\n", "contributors": [{"name": "Abraham, Subil", "sameAs": [], "familyName": "Abraham", "additionalName": "", "givenName": "Subil", "email": ""}, {"name": "Nair, Suku", "sameAs": [], "familyName": "Nair", "additionalName": "", "givenName": "Suku", "email": ""}], "title": "A Predictive Framework for Cyber Security Analytics using Attack Graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01240", "oai:arXiv.org:1502.01240"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Security metrics serve as a powerful tool for organizations to understand the\neffectiveness of protecting computer networks. However majority of these\nmeasurement techniques don't adequately help corporations to make informed risk\nmanagement decisions. In this paper we present a stochastic security framework\nfor obtaining quantitative measures of security by taking into account the\ndynamic attributes associated with vulnerabilities that can change over time.\nOur model is novel as existing research in attack graph analysis do not\nconsider the temporal aspects associated with the vulnerabilities, such as the\navailability of exploits and patches which can affect the overall network\nsecurity based on how the vulnerabilities are interconnected and leveraged to\ncompromise the system. In order to have a more realistic representation of how\nthe security state of the network would vary over time, a nonhomogeneous model\nis developed which incorporates a time dependent covariate, namely the\nvulnerability age. The daily transition-probability matrices are estimated\nusing Frei's Vulnerability Lifecycle model. We also leverage the trusted CVSS\nmetric domain to analyze how the total exploitability and impact measures\nevolve over a time period for a given network.\n", "Comment: 17 pages, 8 figures in International Journal of Computer Networks &\n  Communications (IJCNC) January 2015. ISSN:0974-9322 [Online]; 0975-2293\n  [Print]"]}}], "languages": [null], "subjects": ["computer science - cryptography and security"], "providerUpdatedDateTime": "2015-02-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01240"}}, {"publisher": {"name": ""}, "description": "  Network control refers to a very large and diverse set of problems including\ncontrollability of linear time-invariant dynamical systems evolving over time\nthat have inputs and outputs. The network control problem in this setting is to\nselect the appropriate input to steer the network into a desired output state.\nExamples of the output state include the throughput of a communications\nnetwork, transcription factor concentration in a gene regulatory network,\ncustomer purchases in a marketing context subject to social influences and the\namount of flux flowing through a biochemical network.\n  We focus on control of linear dynamical systems under the notion of\nstructural controllability which is intimately connected to finding maximum\nmatchings. Hence, a natural objective is studying scalable and fast algorithms\nfor this task. We first show the convergence of matching algorithms for\ndifferent random networks and then analyze a popular, fast and practical\nheuristic due to Karp and Sipser. We establish the optimality of both the\nKarp-Sipser Algorithm as well as a simplification of it, and provide results\nconcerning the asymptotic size of maximum matchings for an extensive class of\nrandom networks.\n", "contributors": [{"name": "Faradonbeh, Mohamad Kazem Shirani", "sameAs": [], "familyName": "Faradonbeh", "additionalName": "Kazem Shirani", "givenName": "Mohamad", "email": ""}, {"name": "Tewari, Ambuj", "sameAs": [], "familyName": "Tewari", "additionalName": "", "givenName": "Ambuj", "email": ""}, {"name": "Michailidis, George", "sameAs": [], "familyName": "Michailidis", "additionalName": "", "givenName": "George", "email": ""}], "title": "Optimality of Fast Matching Algorithms for Random Networks with\n  Applications to Structural Controllability", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.08019", "oai:arXiv.org:1503.08019"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": "  Network control refers to a very large and diverse set of problems including\ncontrollability of linear time-invariant dynamical systems evolving over time\nthat have inputs and outputs. The network control problem in this setting is to\nselect the appropriate input to steer the network into a desired output state.\nExamples of the output state include the throughput of a communications\nnetwork, transcription factor concentration in a gene regulatory network,\ncustomer purchases in a marketing context subject to social influences and the\namount of flux flowing through a biochemical network.\n  We focus on control of linear dynamical systems under the notion of\nstructural controllability which is intimately connected to finding maximum\nmatchings. Hence, a natural objective is studying scalable and fast algorithms\nfor this task. We first show the convergence of matching algorithms for\ndifferent random networks and then analyze a popular, fast and practical\nheuristic due to Karp and Sipser. We establish the optimality of both the\nKarp-Sipser Algorithm as well as a simplification of it, and provide results\nconcerning the asymptotic size of maximum matchings for an extensive class of\nrandom networks.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - systems and control", "statistics - other statistics"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.08019"}}, {"publisher": {"name": "American Diabetes Association"}, "description": "", "contributors": [{"name": "D\u2019Addio, Francesca", "sameAs": [], "familyName": "D\u2019Addio", "additionalName": "", "givenName": "Francesca", "email": ""}, {"name": "Maffi, Paola", "sameAs": [], "familyName": "Maffi", "additionalName": "", "givenName": "Paola", "email": ""}, {"name": "Vezzulli, Paolo", "sameAs": [], "familyName": "Vezzulli", "additionalName": "", "givenName": "Paolo", "email": ""}, {"name": "Vergani, Andrea", "sameAs": [], "familyName": "Vergani", "additionalName": "", "givenName": "Andrea", "email": ""}, {"name": "Mello, Alessandra", "sameAs": [], "familyName": "Mello", "additionalName": "", "givenName": "Alessandra", "email": ""}, {"name": "Bassi, Roberto", "sameAs": [], "familyName": "Bassi", "additionalName": "", "givenName": "Roberto", "email": ""}, {"name": "Nano, Rita", "sameAs": [], "familyName": "Nano", "additionalName": "", "givenName": "Rita", "email": ""}, {"name": "Falautano, Monica", "sameAs": [], "familyName": "Falautano", "additionalName": "", "givenName": "Monica", "email": ""}, {"name": "Coppi, Elisabetta", "sameAs": [], "familyName": "Coppi", "additionalName": "", "givenName": "Elisabetta", "email": ""}, {"name": "Finzi, Giovanna", "sameAs": [], "familyName": "Finzi", "additionalName": "", "givenName": "Giovanna", "email": ""}, {"name": "D\u2019Angelo, Armando", "sameAs": [], "familyName": "D\u2019Angelo", "additionalName": "", "givenName": "Armando", "email": ""}, {"name": "Fermo, Isabella", "sameAs": [], "familyName": "Fermo", "additionalName": "", "givenName": "Isabella", "email": ""}, {"name": "Pellegatta, Fabio", "sameAs": [], "familyName": "Pellegatta", "additionalName": "", "givenName": "Fabio", "email": ""}, {"name": "La Rosa, Stefano", "sameAs": [], "familyName": "La Rosa", "additionalName": "", "givenName": "Stefano", "email": ""}, {"name": "Magnani, Giuseppe", "sameAs": [], "familyName": "Magnani", "additionalName": "", "givenName": "Giuseppe", "email": ""}, {"name": "Piemonti, Lorenzo", "sameAs": [], "familyName": "Piemonti", "additionalName": "", "givenName": "Lorenzo", "email": ""}, {"name": "Falini, Andrea", "sameAs": [], "familyName": "Falini", "additionalName": "", "givenName": "Andrea", "email": ""}, {"name": "Folli, Franco", "sameAs": [], "familyName": "Folli", "additionalName": "", "givenName": "Franco", "email": ""}, {"name": "Secchi, Antonio", "sameAs": [], "familyName": "Secchi", "additionalName": "", "givenName": "Antonio", "email": ""}, {"name": "Fiorina, Paolo", "sameAs": [], "familyName": "Fiorina", "additionalName": "", "givenName": "Paolo", "email": ""}], "title": "Islet Transplantation Stabilizes Hemostatic Abnormalities and Cerebral Metabolism in Individuals With Type 1 Diabetes", "shareProperties": {"source": "pubmedcentral"}, "languages": [null], "subjects": ["pathophysiology/complications"], "providerUpdatedDateTime": "2015-01-01T00:00:00", "uris": {"canonicalUri": "http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3867995"}}, {"publisher": {"name": ""}, "description": "  The goal of this survey is to present various results concerning the\ncohomology of pseudoeffective line bundles on compact K{\\\"a}hler manifolds, and\nrelated properties of their multiplier ideal sheaves. In case the curvature is\nstrictly positive, the prototype is the well known Nadel vanishing theorem,\nwhich is itself a generalized analytic version of the fundamental\nKawamata-Viehweg vanishing theorem of algebraic geometry. We are interested\nhere in the case where the curvature is merely semipositive in the sense of\ncurrents, and the base manifold is not necessarily projective. In this\nsituation, one can still obtain interesting information on cohomology, e.g. a\nHard Lefschetz theorem with pseudoeffective coefficients, in the form of a\nsurjectivity statement for the Lefschetz map. More recently, Junyan Cao, in his\nPhD thesis defended in Grenoble, obtained a general K{\\\"a}hler vanishing\ntheorem that depends on the concept of numerical dimension of a given\npseudoeffective line bundle. The proof of these results depends in a crucial\nway on a general approximation result for closed (1,1)-currents, based on the\nuse of Bergman kernels, and the related intersection theory of currents.\nAnother important ingredient is the recent proof by Guan and Zhou of the strong\nopenness conjecture. As an application, we discuss a structure theorem for\ncompact K{\\\"a}hler threefolds without nontrivial subvarieties, following a\njoint work with F.Campana and M.Verbitsky. We hope that these notes will serve\nas a useful guide to the more detailed and more technical papers in the\nliterature; in some cases, we provide here substantially simplified proofs and\nunifying viewpoints.\n", "contributors": [{"name": "Demailly, Jean-Pierre", "sameAs": [], "familyName": "Demailly", "additionalName": "", "givenName": "Jean-Pierre", "email": ""}], "title": "On the cohomology of pseudoeffective line bundles", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-01-21", "2015-01-02"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1401.5432", "oai:arXiv.org:1401.5432"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  The goal of this survey is to present various results concerning the\ncohomology of pseudoeffective line bundles on compact K{\\\"a}hler manifolds, and\nrelated properties of their multiplier ideal sheaves. In case the curvature is\nstrictly positive, the prototype is the well known Nadel vanishing theorem,\nwhich is itself a generalized analytic version of the fundamental\nKawamata-Viehweg vanishing theorem of algebraic geometry. We are interested\nhere in the case where the curvature is merely semipositive in the sense of\ncurrents, and the base manifold is not necessarily projective. In this\nsituation, one can still obtain interesting information on cohomology, e.g. a\nHard Lefschetz theorem with pseudoeffective coefficients, in the form of a\nsurjectivity statement for the Lefschetz map. More recently, Junyan Cao, in his\nPhD thesis defended in Grenoble, obtained a general K{\\\"a}hler vanishing\ntheorem that depends on the concept of numerical dimension of a given\npseudoeffective line bundle. The proof of these results depends in a crucial\nway on a general approximation result for closed (1,1)-currents, based on the\nuse of Bergman kernels, and the related intersection theory of currents.\nAnother important ingredient is the recent proof by Guan and Zhou of the strong\nopenness conjecture. As an application, we discuss a structure theorem for\ncompact K{\\\"a}hler threefolds without nontrivial subvarieties, following a\njoint work with F.Campana and M.Verbitsky. We hope that these notes will serve\nas a useful guide to the more detailed and more technical papers in the\nliterature; in some cases, we provide here substantially simplified proofs and\nunifying viewpoints.\n", "Comment: 39 pages. This survey is a written account of a lecture given at the\n  Abel Symposium, Trondheim, July 2013"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-01-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1401.5432"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "It is important for companies to manage their revenues and -reduce their costs efficiently. These goals can be achieved through effective pricing and inventory control strategies. This thesis studies a joint multi-period pricing and inventory control problem for a make-to-stock manufacturing system. Multiple products are produced under shared production capacity over a finite time horizon. The demand for each product is a function of the prices and no back orders are allowed. Inventory and production costs are linear functions of the levels of inventory and production, respectively. In this thesis, we introduce an iterative gradient-based algorithm. A key idea is that given a demand realization, the cost minimization part of the problem becomes a linear transportation problem. Given this idea, if we knew the optimal demand, we could solve the production problem efficiently. At each iteration of the algorithm, given a demand vector we solve a linear transportation problem and use its dual variables in order to solve a quadratic optimization problem that optimizes the revenue part and generates a new pricing policy. We illustrate computationally that this algorithm obtains the optimal production and pricing policy over the finite time horizon efficiently. The computational experiments in this thesis use a wide range of simulated data. The results show that the algorithm we study in this thesis indeed computes the optimal solution for the joint pricing and inventory control problem and is efficient as compared to solving a reformulation of the problem directly using commercial software. The algorithm proposed in this thesis solves large scale problems and can handle a wide range of nonlinear demand functions.", "contributors": [{"name": "Rao, Tingting", "sameAs": [], "familyName": "Rao", "additionalName": "", "givenName": "Tingting", "email": ""}, {"name": "Massachusetts Institute of Technology. Computation for Design and Optimization Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computation for Design and Optimization", "givenName": "Massachusetts", "email": ""}, {"name": "Retsef Levi and Georgia Perakis.", "sameAs": [], "familyName": "Perakis.", "additionalName": "Levi and Georgia", "givenName": "Retsef", "email": ""}], "title": "LP-based subgradient algorithm for joint pricing and inventory control problems", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "94 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/45282", "311815436", "oai:dspace.mit.edu:1721.1/45282"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2009-04-29T17:20:09Z", "2009-04-29T17:20:09Z", "2008", "2008"]}}, {"name": "description", "properties": {"description": ["It is important for companies to manage their revenues and -reduce their costs efficiently. These goals can be achieved through effective pricing and inventory control strategies. This thesis studies a joint multi-period pricing and inventory control problem for a make-to-stock manufacturing system. Multiple products are produced under shared production capacity over a finite time horizon. The demand for each product is a function of the prices and no back orders are allowed. Inventory and production costs are linear functions of the levels of inventory and production, respectively. In this thesis, we introduce an iterative gradient-based algorithm. A key idea is that given a demand realization, the cost minimization part of the problem becomes a linear transportation problem. Given this idea, if we knew the optimal demand, we could solve the production problem efficiently. At each iteration of the algorithm, given a demand vector we solve a linear transportation problem and use its dual variables in order to solve a quadratic optimization problem that optimizes the revenue part and generates a new pricing policy. We illustrate computationally that this algorithm obtains the optimal production and pricing policy over the finite time horizon efficiently. The computational experiments in this thesis use a wide range of simulated data. The results show that the algorithm we study in this thesis indeed computes the optimal solution for the joint pricing and inventory control problem and is efficient as compared to solving a reformulation of the problem directly using commercial software. The algorithm proposed in this thesis solves large scale problems and can handle a wide range of nonlinear demand functions.", "by Tingting Rao.", "Thesis (S.M.)--Massachusetts Institute of Technology, Computation for Design and Optimization Program, 2008.", "Includes bibliographical references (p. 93-94)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39115", "hdl_1721.1_39117"]}}], "languages": [null], "subjects": ["computation for design and optimization program."], "providerUpdatedDateTime": "2015-04-27T14:56:17", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/45282"}}, {"publisher": {"name": ""}, "description": "  We study the fundamental algorithmic rigidity problems for generic frameworks\nperiodic with respect to a fixed lattice or a finite-order rotation in the\nplane. For fixed-lattice frameworks we give an $O(n^2)$ algorithm for deciding\ngeneric rigidity and an O(n^3) algorithm for computing rigid components. If the\norder of rotation is part of the input, we give an O(n^4) algorithm for\ndeciding rigidity; in the case where the rotation's order is 3, a more\nspecialized algorithm solves all the fundamental algorithmic rigidity problems\nin O(n^2) time.\n", "contributors": [{"name": "Berardi, Matthew", "sameAs": [], "familyName": "Berardi", "additionalName": "", "givenName": "Matthew", "email": ""}, {"name": "Heeringa, Brent", "sameAs": [], "familyName": "Heeringa", "additionalName": "", "givenName": "Brent", "email": ""}, {"name": "Malestein, Justin", "sameAs": [], "familyName": "Malestein", "additionalName": "", "givenName": "Justin", "email": ""}, {"name": "Theran, Louis", "sameAs": [], "familyName": "Theran", "additionalName": "", "givenName": "Louis", "email": ""}], "title": "Rigid components in fixed-lattice and cone frameworks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-05-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.3234", "oai:arXiv.org:1105.3234"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We study the fundamental algorithmic rigidity problems for generic frameworks\nperiodic with respect to a fixed lattice or a finite-order rotation in the\nplane. For fixed-lattice frameworks we give an $O(n^2)$ algorithm for deciding\ngeneric rigidity and an O(n^3) algorithm for computing rigid components. If the\norder of rotation is part of the input, we give an O(n^4) algorithm for\ndeciding rigidity; in the case where the rotation's order is 3, a more\nspecialized algorithm solves all the fundamental algorithmic rigidity problems\nin O(n^2) time.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "mathematics - combinatorics"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.3234"}}, {"publisher": {"name": ""}, "description": "  Spreadsheets are widely used within companies and often form the basis for\nbusiness decisions. Numerous cases are known where incorrect information in\nspreadsheets has lead to incorrect decisions. Such cases underline the\nrelevance of research on the professional use of spreadsheets.\n  Recently a new dataset became available for research, containing over 15.000\nbusiness spreadsheets that were extracted from the Enron E-mail Archive. With\nthis dataset, we 1) aim to obtain a thorough understanding of the\ncharacteristics of spreadsheets used within companies, and 2) compare the\ncharacteristics of the Enron spreadsheets with the EUSES corpus which is the\nexisting state of the art set of spreadsheets that is frequently used in\nspreadsheet studies.\n  Our analysis shows that 1) the majority of spreadsheets are not large in\nterms of worksheets and formulas, do not have a high degree of coupling, and\ntheir formulas are relatively simple; 2) the spreadsheets from the EUSES corpus\nare, with respect to the measured characteristics, quite similar to the Enron\nspreadsheets.\n", "contributors": [{"name": "Jansen, Bas", "sameAs": [], "familyName": "Jansen", "additionalName": "", "givenName": "Bas", "email": ""}], "title": "Enron versus EUSES: A Comparison of Two Spreadsheet Corpora", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.04055", "oai:arXiv.org:1503.04055"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Spreadsheets are widely used within companies and often form the basis for\nbusiness decisions. Numerous cases are known where incorrect information in\nspreadsheets has lead to incorrect decisions. Such cases underline the\nrelevance of research on the professional use of spreadsheets.\n  Recently a new dataset became available for research, containing over 15.000\nbusiness spreadsheets that were extracted from the Enron E-mail Archive. With\nthis dataset, we 1) aim to obtain a thorough understanding of the\ncharacteristics of spreadsheets used within companies, and 2) compare the\ncharacteristics of the Enron spreadsheets with the EUSES corpus which is the\nexisting state of the art set of spreadsheets that is frequently used in\nspreadsheet studies.\n  Our analysis shows that 1) the majority of spreadsheets are not large in\nterms of worksheets and formulas, do not have a high degree of coupling, and\ntheir formulas are relatively simple; 2) the spreadsheets from the EUSES corpus\nare, with respect to the measured characteristics, quite similar to the Enron\nspreadsheets.\n", "Comment: In Proceedings of the 2nd Workshop on Software Engineering Methods in\n  Spreadsheets"]}}], "languages": [null], "subjects": ["computer science - software engineering"], "providerUpdatedDateTime": "2015-03-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.04055"}}, {"publisher": {"name": ""}, "description": "  In this paper we study the automorphism groups of real curves admitting a\nregular meromorphic function $f$ of degree $p$, so called real cyclic $p$-gonal\ncurves. When $p=2$ the automorphism groups of real hyperelliptic curves where\ngiven by Bujalance et al. in \\cite{BCGG}.\n", "contributors": [{"name": "Izquierdo, Milagros", "sameAs": [], "familyName": "Izquierdo", "additionalName": "", "givenName": "Milagros", "email": ""}, {"name": "Shaska, Tony", "sameAs": [], "familyName": "Shaska", "additionalName": "", "givenName": "Tony", "email": ""}], "title": "Cyclic curves over the reals", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-07"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.01559", "oai:arXiv.org:1501.01559"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  In this paper we study the automorphism groups of real curves admitting a\nregular meromorphic function $f$ of degree $p$, so called real cyclic $p$-gonal\ncurves. When $p=2$ the automorphism groups of real hyperelliptic curves where\ngiven by Bujalance et al. in \\cite{BCGG}.\n", "Comment: NATO Advanced Study Institute, 2014, Ohrid, Macedonia"]}}], "languages": [null], "subjects": ["mathematics - algebraic geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-01-08T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.01559"}}, {"publisher": {"name": ""}, "description": "  The wiretap channel models secure communication of two users in the presence\nof a non-legitimate eavesdropper who must be kept ignorant of transmitted\nmessages. The performance of such a system is usually characterized by its\nsecrecy capacity determining the maximum transmission rate of secure\ncommunication. In this paper, the issue of whether the secrecy capacity is a\ncontinuous function of the system parameters or not is examined. In particular,\nthis is done for channel uncertainty modeled via compound channels and\narbitrarily varying channels, in which the legitimate users know only that the\ntrue channel realization is from a pre-specified uncertainty set. In the former\nmodel, this realization remains constant for the whole duration of\ntransmission, while in the latter the realization varies from channel use to\nchannel use in an unknown and arbitrary manner. These models not only capture\nthe case of channel uncertainty, but are also suitable to model scenarios in\nwhich a malicious adversary influences or jams the legitimate transmission. The\nsecrecy capacity of the compound wiretap channel is shown to be robust in the\nsense that it is a continuous function of the uncertainty set. Thus, small\nvariations in the uncertainty set lead to small variations in secrecy capacity.\nOn the other hand, the deterministic secrecy capacity of the arbitrarily\nvarying wiretap channel is shown to be discontinuous in the uncertainty set\nmeaning that small variations can lead to dramatic losses in capacity.\n", "contributors": [{"name": "Boche, Holger", "sameAs": [], "familyName": "Boche", "additionalName": "", "givenName": "Holger", "email": ""}, {"name": "Schaefer, Rafael F.", "sameAs": [], "familyName": "Schaefer", "additionalName": "F.", "givenName": "Rafael", "email": ""}, {"name": "Poor, H. Vincent", "sameAs": [], "familyName": "Poor", "additionalName": "Vincent", "givenName": "H.", "email": ""}], "title": "On the Continuity of the Secrecy Capacity of Compound and Arbitrarily\n  Varying Wiretap Channels", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-16", "2015-03-25"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.4752", "oai:arXiv.org:1409.4752"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  The wiretap channel models secure communication of two users in the presence\nof a non-legitimate eavesdropper who must be kept ignorant of transmitted\nmessages. The performance of such a system is usually characterized by its\nsecrecy capacity determining the maximum transmission rate of secure\ncommunication. In this paper, the issue of whether the secrecy capacity is a\ncontinuous function of the system parameters or not is examined. In particular,\nthis is done for channel uncertainty modeled via compound channels and\narbitrarily varying channels, in which the legitimate users know only that the\ntrue channel realization is from a pre-specified uncertainty set. In the former\nmodel, this realization remains constant for the whole duration of\ntransmission, while in the latter the realization varies from channel use to\nchannel use in an unknown and arbitrary manner. These models not only capture\nthe case of channel uncertainty, but are also suitable to model scenarios in\nwhich a malicious adversary influences or jams the legitimate transmission. The\nsecrecy capacity of the compound wiretap channel is shown to be robust in the\nsense that it is a continuous function of the uncertainty set. Thus, small\nvariations in the uncertainty set lead to small variations in secrecy capacity.\nOn the other hand, the deterministic secrecy capacity of the arbitrarily\nvarying wiretap channel is shown to be discontinuous in the uncertainty set\nmeaning that small variations can lead to dramatic losses in capacity.\n", "Comment: revised. Section VI added"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.4752"}}, {"publisher": {"name": ""}, "description": "  The water uptake by roots of plants is examined for an ideal situation, with\nan approximation that resembles plants growing in pots, meaning that the total\nsoil volume is fixed. We propose a coupled water uptake-root growth model. A\none-dimensional model for water flux and water uptake by a root system growing\nuniformly distributed in the soil is presented, and the Van Genuchten model for\nthe transport of water in soil is used. The governing equations are represented\nby a moving boundary model for which the root length, as a function of time, is\nprescribed. The solution of the model is obtained by front-fixing and finite\nelement methods. Model predictions for water uptake by a same plant growing in\nloam, silt and clay soils are obtained and compared. A sensitivity analysis to\ndetermine relative effects on water uptake when system parameters are changed\nis also presented and shows that the model and numerical method proposed are\nmore sensitive to the root growth rate than to the rest of the parameters. This\nsensitivity decreases along time, reaching its maximum at thirty days. A\ncomparison of this model with a fixed boundary model with and without root\ngrowth is also made. The results show qualitative differences from the\nbeginning of the simulations, and quantitative differences after ten days of\nsimulations.\n", "contributors": [{"name": "Albrieu, J. L. Blengino", "sameAs": [], "familyName": "Albrieu", "additionalName": "L. Blengino", "givenName": "J.", "email": ""}, {"name": "Reginato, J. C.", "sameAs": [], "familyName": "Reginato", "additionalName": "C.", "givenName": "J.", "email": ""}, {"name": "Tarzia, D. A.", "sameAs": [], "familyName": "Tarzia", "additionalName": "A.", "givenName": "D.", "email": ""}], "title": "Modeling water uptake by a root system growing in a fixed soil volume", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.03331", "doi:10.1016/j.apm.2014.11.042", "oai:arXiv.org:1503.03331"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:physics", "q-bio"]}}, {"name": "description", "properties": {"description": ["  The water uptake by roots of plants is examined for an ideal situation, with\nan approximation that resembles plants growing in pots, meaning that the total\nsoil volume is fixed. We propose a coupled water uptake-root growth model. A\none-dimensional model for water flux and water uptake by a root system growing\nuniformly distributed in the soil is presented, and the Van Genuchten model for\nthe transport of water in soil is used. The governing equations are represented\nby a moving boundary model for which the root length, as a function of time, is\nprescribed. The solution of the model is obtained by front-fixing and finite\nelement methods. Model predictions for water uptake by a same plant growing in\nloam, silt and clay soils are obtained and compared. A sensitivity analysis to\ndetermine relative effects on water uptake when system parameters are changed\nis also presented and shows that the model and numerical method proposed are\nmore sensitive to the root growth rate than to the rest of the parameters. This\nsensitivity decreases along time, reaching its maximum at thirty days. A\ncomparison of this model with a fixed boundary model with and without root\ngrowth is also made. The results show qualitative differences from the\nbeginning of the simulations, and quantitative differences after ten days of\nsimulations.\n", "Comment: To Appear in Applied mathematical modelling 23 pages, 10 figures"]}}], "languages": [null], "subjects": ["35r37", "35q92", "physics - biological physics", "76505", "quantitative biology - tissues and organs", "physics - computational physics", "65m60"], "providerUpdatedDateTime": "2015-03-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.03331"}}, {"publisher": {"name": ""}, "description": "  This paper investigates the role of factorial speech processing models in\nnoise-robust automatic speech recognition tasks. Factorial models can embed\nnon-stationary noise models using Markov chains as one of its source chain. The\npaper proposes a modeling scheme for modeling state-conditional observation\ndistribution of factorial models based on weighted stereo samples. This scheme\nis an extension to previous single pass retraining for ideal model compensation\nand here we used it to construct ideal state-conditional observation\ndistributions. Experiments of this paper over the set A of the Aurora 2 dataset\nshows that by considering noise models with multiple states, system performance\ncan be improved especially in low SNR conditions up to 4% absolute word\nrecognition performance. In addition to its power in accurate representation of\nstate-conditional observation distribution, it has an important advantage over\nprevious methods by providing the opportunity to independently select feature\nspaces for both source and corrupted features. This opens a new window for\nseeking better feature spaces appropriate for noise-robust tasks independent\nfrom clean speech feature space.\n", "contributors": [{"name": "Khademian, Mahdi", "sameAs": [], "familyName": "", "additionalName": "", "givenName": "Khademian", "email": ""}, {"name": "Homayounpour, Mohammad Mehdi", "sameAs": [], "familyName": "Homayounpour", "additionalName": "Mehdi", "givenName": "Mohammad", "email": ""}], "title": "Modeling State-Conditional Observation Distribution using Weighted\n  Stereo Samples for Factorial Speech Processing Models", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.02578", "oai:arXiv.org:1503.02578"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  This paper investigates the role of factorial speech processing models in\nnoise-robust automatic speech recognition tasks. Factorial models can embed\nnon-stationary noise models using Markov chains as one of its source chain. The\npaper proposes a modeling scheme for modeling state-conditional observation\ndistribution of factorial models based on weighted stereo samples. This scheme\nis an extension to previous single pass retraining for ideal model compensation\nand here we used it to construct ideal state-conditional observation\ndistributions. Experiments of this paper over the set A of the Aurora 2 dataset\nshows that by considering noise models with multiple states, system performance\ncan be improved especially in low SNR conditions up to 4% absolute word\nrecognition performance. In addition to its power in accurate representation of\nstate-conditional observation distribution, it has an important advantage over\nprevious methods by providing the opportunity to independently select feature\nspaces for both source and corrupted features. This opens a new window for\nseeking better feature spaces appropriate for noise-robust tasks independent\nfrom clean speech feature space.\n"}}], "languages": [null], "subjects": ["computer science - artificial intelligence", "computer science - learning", "computer science - sound"], "providerUpdatedDateTime": "2015-03-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.02578"}}, {"publisher": {"name": ""}, "description": "  The flow field and the heat transfer around six in-line iso-thermal circular\ncylinders has been studied by mean of numerical simulations. Two values of the\ncenter to center spacing ($s=3.6d$ and $4d$, where $d$ is the cylinder\ndiameter) at Reynolds number of $100$ and Prandtl number of $0.7$ has been\ninvestigated. Similarly to the in-line two cylinder configuration, in this\nrange a transition in the flow and in the heat transfer occurs. Two different\nflow patterns have been identified: the stable shear layer (SSL) mode and the\nshear layer secondary vortices (SLSV) mode, at $3.6$ and $4$ spacing ratio\n($s/d$), respectively. At $s/d=3.6$ the flow pattern causes the entrainment of\ncold fluid on the downstream cylinders enhancing the heat transfer. On the\nother hand at $s/d=4$ two stable opposite shear layer prevent the cold fluid\nentrainment over the downstream cylinders reducing their heat exchange. The\noverall time average heat transfer of the array is enhanced up to 25%\ndecreasing the spacing ratio from $4$ to $3.6$. Furthermore, it is found that\nthe increased heat transfer is related to the phase shift between the Nusselt\ntime series of successive cylinders.\n", "contributors": [{"name": "Fornarelli, Francesco", "sameAs": [], "familyName": "Fornarelli", "additionalName": "", "givenName": "Francesco", "email": ""}, {"name": "Oresta, Paolo", "sameAs": [], "familyName": "Oresta", "additionalName": "", "givenName": "Paolo", "email": ""}, {"name": "Lippolis, Antonio", "sameAs": [], "familyName": "Lippolis", "additionalName": "", "givenName": "Antonio", "email": ""}], "title": "Flow patterns and heat transfer around six in-line circular cylinders at\n  low Reynolds number", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.5836", "oai:arXiv.org:1410.5836"]}}, {"name": "setSpec", "properties": {"setSpec": "physics:physics"}}, {"name": "description", "properties": {"description": ["  The flow field and the heat transfer around six in-line iso-thermal circular\ncylinders has been studied by mean of numerical simulations. Two values of the\ncenter to center spacing ($s=3.6d$ and $4d$, where $d$ is the cylinder\ndiameter) at Reynolds number of $100$ and Prandtl number of $0.7$ has been\ninvestigated. Similarly to the in-line two cylinder configuration, in this\nrange a transition in the flow and in the heat transfer occurs. Two different\nflow patterns have been identified: the stable shear layer (SSL) mode and the\nshear layer secondary vortices (SLSV) mode, at $3.6$ and $4$ spacing ratio\n($s/d$), respectively. At $s/d=3.6$ the flow pattern causes the entrainment of\ncold fluid on the downstream cylinders enhancing the heat transfer. On the\nother hand at $s/d=4$ two stable opposite shear layer prevent the cold fluid\nentrainment over the downstream cylinders reducing their heat exchange. The\noverall time average heat transfer of the array is enhanced up to 25%\ndecreasing the spacing ratio from $4$ to $3.6$. Furthermore, it is found that\nthe increased heat transfer is related to the phase shift between the Nusselt\ntime series of successive cylinders.\n", "Comment: Accepted by JP Journal of Heat and Mass Transfer (2015)"]}}], "languages": [null], "subjects": ["physics - computational physics", "physics - fluid dynamics"], "providerUpdatedDateTime": "2014-10-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.5836"}}, {"publisher": {"name": ""}, "description": "  This paper looks into the problem of pedestrian tracking using a monocular,\npotentially moving, uncalibrated camera. The pedestrians are located in each\nframe using a standard human detector, which are then tracked in subsequent\nframes. This is a challenging problem as one has to deal with complex\nsituations like changing background, partial or full occlusion and camera\nmotion. In order to carry out successful tracking, it is necessary to resolve\nassociations between the detected windows in the current frame with those\nobtained from the previous frame. Compared to methods that use temporal windows\nincorporating past as well as future information, we attempt to make decision\non a frame-by-frame basis. An occlusion reasoning scheme is proposed to resolve\nthe association problem between a pair of consecutive frames by using an\naffinity matrix that defines the closeness between a pair of windows and then,\nuses a binary integer programming to obtain unique association between them. A\nsecond stage of verification based on SURF matching is used to deal with those\ncases where the above optimization scheme might yield wrong associations. The\nefficacy of the approach is demonstrated through experiments on several\nstandard pedestrian datasets.\n", "contributors": [{"name": "Garg, Sourav", "sameAs": [], "familyName": "Garg", "additionalName": "", "givenName": "Sourav", "email": ""}, {"name": "Kumar, Swagat", "sameAs": [], "familyName": "Kumar", "additionalName": "", "givenName": "Swagat", "email": ""}, {"name": "Ratnakaram, Rajesh", "sameAs": [], "familyName": "Ratnakaram", "additionalName": "", "givenName": "Rajesh", "email": ""}, {"name": "Guha, Prithwijit", "sameAs": [], "familyName": "Guha", "additionalName": "", "givenName": "Prithwijit", "email": ""}], "title": "An Occlusion Reasoning Scheme for Monocular Pedestrian Tracking in\n  Dynamic Scenes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06129", "oai:arXiv.org:1501.06129"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper looks into the problem of pedestrian tracking using a monocular,\npotentially moving, uncalibrated camera. The pedestrians are located in each\nframe using a standard human detector, which are then tracked in subsequent\nframes. This is a challenging problem as one has to deal with complex\nsituations like changing background, partial or full occlusion and camera\nmotion. In order to carry out successful tracking, it is necessary to resolve\nassociations between the detected windows in the current frame with those\nobtained from the previous frame. Compared to methods that use temporal windows\nincorporating past as well as future information, we attempt to make decision\non a frame-by-frame basis. An occlusion reasoning scheme is proposed to resolve\nthe association problem between a pair of consecutive frames by using an\naffinity matrix that defines the closeness between a pair of windows and then,\nuses a binary integer programming to obtain unique association between them. A\nsecond stage of verification based on SURF matching is used to deal with those\ncases where the above optimization scheme might yield wrong associations. The\nefficacy of the approach is demonstrated through experiments on several\nstandard pedestrian datasets.\n", "Comment: 8 pages"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-01-27T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06129"}}, {"publisher": {"name": ""}, "description": "  We study the problem of distributed coverage control in a network of mobile\nagents arranged on a line. The goal is to design distributed dynamics for the\nagents to achieve optimal coverage positions with respect to a scalar density\nfield that measures the relative importance of each point on the line. Unlike\nprevious work, which has implicitly assumed the agents know this density field,\nwe only assume that each agent can access noisy samples of the field at points\nclose to its current location. We provide a simple randomized protocol wherein\nevery agent samples the scalar field at three nearby points at each step and\nwhich guarantees convergence to the optimal positions. We further analyze the\nconvergence time of this protocol and show that, under suitable assumptions,\nthe squared distance to the optimal coverage configuration decays as $O(1/t)$\nwith the number of iterations $t$, where the constant scales polynomially with\nthe number of agents $n$. We illustrate these results with simulations.\n", "contributors": [{"name": "Davison, P.", "sameAs": [], "familyName": "Davison", "additionalName": "", "givenName": "P.", "email": ""}, {"name": "Leonard, N. E.", "sameAs": [], "familyName": "Leonard", "additionalName": "E.", "givenName": "N.", "email": ""}, {"name": "Olshevsky, A.", "sameAs": [], "familyName": "Olshevsky", "additionalName": "", "givenName": "A.", "email": ""}, {"name": "Schwemmer, M.", "sameAs": [], "familyName": "Schwemmer", "additionalName": "", "givenName": "M.", "email": ""}], "title": "Nonuniform Line Coverage from Noisy Scalar Measurements", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-10-15", "2014-11-21"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.4188", "oai:arXiv.org:1310.4188"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We study the problem of distributed coverage control in a network of mobile\nagents arranged on a line. The goal is to design distributed dynamics for the\nagents to achieve optimal coverage positions with respect to a scalar density\nfield that measures the relative importance of each point on the line. Unlike\nprevious work, which has implicitly assumed the agents know this density field,\nwe only assume that each agent can access noisy samples of the field at points\nclose to its current location. We provide a simple randomized protocol wherein\nevery agent samples the scalar field at three nearby points at each step and\nwhich guarantees convergence to the optimal positions. We further analyze the\nconvergence time of this protocol and show that, under suitable assumptions,\nthe squared distance to the optimal coverage configuration decays as $O(1/t)$\nwith the number of iterations $t$, where the constant scales polynomially with\nthe number of agents $n$. We illustrate these results with simulations.\n"}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - systems and control"], "providerUpdatedDateTime": "2014-11-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.4188"}}, {"publisher": {"name": ""}, "description": "  Generic matrix multiplication (GEMM) and one-dimensional\nconvolution/cross-correlation (CONV) kernels often constitute the bulk of the\ncompute- and memory-intensive processing within image/audio recognition and\nmatching systems. We propose a novel method to scale the energy and processing\nthroughput of GEMM and CONV kernels for such error-tolerant multimedia\napplications by adjusting the precision of computation. Our technique employs\nlinear projections to the input matrix or signal data during the top-level GEMM\nand CONV blocking and reordering. The GEMM and CONV kernel processing then uses\nthe projected inputs and the results are accumulated to form the final outputs.\nThroughput and energy scaling takes place by changing the number of projections\ncomputed by each kernel, which in turn produces approximate results, i.e.\nchanges the precision of the performed computation. Results derived from a\nvoltage- and frequency-scaled ARM Cortex A15 processor running face recognition\nand music matching algorithms demonstrate that the proposed approach allows for\n280%~440% increase of processing throughput and 75%~80% decrease of energy\nconsumption against optimized GEMM and CONV kernels without any impact in the\nobtained recognition or matching accuracy. Even higher gains can be obtained if\none is willing to tolerate some reduction in the accuracy of the recognition\nand matching applications.\n", "contributors": [{"name": "Anam, Mohammad Ashraful", "sameAs": [], "familyName": "Anam", "additionalName": "Ashraful", "givenName": "Mohammad", "email": ""}, {"name": "Whatmough, Paul N.", "sameAs": [], "familyName": "Whatmough", "additionalName": "N.", "givenName": "Paul", "email": ""}, {"name": "Andreopoulos, Yiannis", "sameAs": [], "familyName": "Andreopoulos", "additionalName": "", "givenName": "Yiannis", "email": ""}], "title": "Precision-Energy-Throughput Scaling Of Generic Matrix Multiplication and\n  Convolution Kernels Via Linear Projections", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.2860", "IEEE Transactions on Circuits and Systems for Video Technology,\n  vol. 24, no. 11, pp. 1860-1873, Nov. 2014", "oai:arXiv.org:1411.2860"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Generic matrix multiplication (GEMM) and one-dimensional\nconvolution/cross-correlation (CONV) kernels often constitute the bulk of the\ncompute- and memory-intensive processing within image/audio recognition and\nmatching systems. We propose a novel method to scale the energy and processing\nthroughput of GEMM and CONV kernels for such error-tolerant multimedia\napplications by adjusting the precision of computation. Our technique employs\nlinear projections to the input matrix or signal data during the top-level GEMM\nand CONV blocking and reordering. The GEMM and CONV kernel processing then uses\nthe projected inputs and the results are accumulated to form the final outputs.\nThroughput and energy scaling takes place by changing the number of projections\ncomputed by each kernel, which in turn produces approximate results, i.e.\nchanges the precision of the performed computation. Results derived from a\nvoltage- and frequency-scaled ARM Cortex A15 processor running face recognition\nand music matching algorithms demonstrate that the proposed approach allows for\n280%~440% increase of processing throughput and 75%~80% decrease of energy\nconsumption against optimized GEMM and CONV kernels without any impact in the\nobtained recognition or matching accuracy. Even higher gains can be obtained if\none is willing to tolerate some reduction in the accuracy of the recognition\nand matching applications.\n"}}], "languages": [null], "subjects": ["computer science - mathematical software", "computer science - multimedia"], "providerUpdatedDateTime": "2014-11-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.2860"}}, {"publisher": {"name": ""}, "description": "  We focus on designing combinatorial algorithms for the Capacitated Network\nDesign problem (Cap-SNDP). The Cap-SNDP is the problem of satisfying\nconnectivity requirements when edges have costs and hard capacities. We begin\nby showing that the Group Steiner tree problem (GST) is a special case of\nCap-SNDP even when there is connectivity requirement between only one\nsource-sink pair. This implies the first poly-logarithmic lower bound for the\nCap-SNDP. We next provide combinatorial algorithms for several special cases of\nthis problem. The Cap-SNDP is equivalent to its special case when every edge\nhas either zero cost or infinite capacity. We consider a special case, called\nConnected Cap-SNDP, where all infinite-capacity edges in the solution are\nrequired to form a connected component containing the sinks. This problem is\nmotivated by its similarity to the Connected Facility Location problem\n[G+01,SW04]. We solve this problem by reducing it to Submodular tree cover\nproblem, which is a common generalization of Connected Cap-SNDP and Group\nSteiner tree problem. We generalize the recursive greedy algorithm [CEK]\nachieving a poly-logarithmic approximation algorithm for Submodular tree cover\nproblem. This result is interesting in its own right and gives the first\npoly-logarithmic approximation algorithms for Connected hard capacities set\nmulti-cover and Connected source location.\n  We then study another special case of Cap-SNDP called Unbalanced\npoint-to-point connection problem. Besides its practical applications to shift\ndesign problems [EKS], it generalizes many problems such as k-MST, Steiner\nForest and Point-to-Point Connection. We give a combinatorial logarithmic\napproximation algorithm for this problem by reducing it to degree-bounded SNDP.\n", "contributors": [{"name": "Hajiaghayi, MohammadTaghi", "sameAs": [], "familyName": "Hajiaghayi", "additionalName": "", "givenName": "MohammadTaghi", "email": ""}, {"name": "Khandekar, Rohit", "sameAs": [], "familyName": "Khandekar", "additionalName": "", "givenName": "Rohit", "email": ""}, {"name": "Kortsarz, Guy", "sameAs": [], "familyName": "Kortsarz", "additionalName": "", "givenName": "Guy", "email": ""}, {"name": "Nutov, Zeev", "sameAs": [], "familyName": "Nutov", "additionalName": "", "givenName": "Zeev", "email": ""}], "title": "Combinatorial Algorithms for Capacitated Network Design", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-08-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1108.1176", "oai:arXiv.org:1108.1176"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We focus on designing combinatorial algorithms for the Capacitated Network\nDesign problem (Cap-SNDP). The Cap-SNDP is the problem of satisfying\nconnectivity requirements when edges have costs and hard capacities. We begin\nby showing that the Group Steiner tree problem (GST) is a special case of\nCap-SNDP even when there is connectivity requirement between only one\nsource-sink pair. This implies the first poly-logarithmic lower bound for the\nCap-SNDP. We next provide combinatorial algorithms for several special cases of\nthis problem. The Cap-SNDP is equivalent to its special case when every edge\nhas either zero cost or infinite capacity. We consider a special case, called\nConnected Cap-SNDP, where all infinite-capacity edges in the solution are\nrequired to form a connected component containing the sinks. This problem is\nmotivated by its similarity to the Connected Facility Location problem\n[G+01,SW04]. We solve this problem by reducing it to Submodular tree cover\nproblem, which is a common generalization of Connected Cap-SNDP and Group\nSteiner tree problem. We generalize the recursive greedy algorithm [CEK]\nachieving a poly-logarithmic approximation algorithm for Submodular tree cover\nproblem. This result is interesting in its own right and gives the first\npoly-logarithmic approximation algorithms for Connected hard capacities set\nmulti-cover and Connected source location.\n  We then study another special case of Cap-SNDP called Unbalanced\npoint-to-point connection problem. Besides its practical applications to shift\ndesign problems [EKS], it generalizes many problems such as k-MST, Steiner\nForest and Point-to-Point Connection. We give a combinatorial logarithmic\napproximation algorithm for this problem by reducing it to degree-bounded SNDP.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1108.1176"}}, {"publisher": {"name": ""}, "description": "  Subspace clustering is the problem of clustering data points into a union of\nlow-dimensional linear or affine subspaces. It is the mathematical abstraction\nof many important problems in computer vision, image processing and has been\ndrawing avid attention in machine learning and statistics recently. In\nparticular, a line of recent work (Elhamifar and Vidal, 2013; Soltanolkotabi et\nal., 2012; Wang and Xu, 2013; Soltanolkotabi et al., 2014) provided strong\ntheoretical guarantee for the seminal algorithm: Sparse Subspace Clustering\n(SSC) (Elhamifar and Vidal, 2013) under various settings, and to some extent,\njustified its state-of-the-art performance in applications such as motion\nsegmentation and face clustering. The focus of these work has been getting\nmilder conditions under which SSC obeys \"self-expressiveness property\", which\nensures that no two points from different subspaces can be clustered together.\nSuch guarantee however is not sufficient for the clustering to be correct,\nthanks to the notorious \"graph connectivity problem\" (Nasihatkon and Hartley,\n2011). In this paper, we show that this issue can be resolved by a very simple\npost-processing procedure under only a mild \"general position\" assumption. In\naddition, we show that the approach is robust to arbitrary bounded perturbation\nof the data whenever the \"general position\" assumption holds with a margin.\nThese results provide the first exact clustering guarantee of SSC for subspaces\nof dimension greater than 3.\n", "contributors": [{"name": "Wang, Yining", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Yining", "email": ""}, {"name": "Wang, Yu-Xiang", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Yu-Xiang", "email": ""}, {"name": "Singh, Aarti", "sameAs": [], "familyName": "Singh", "additionalName": "", "givenName": "Aarti", "email": ""}], "title": "Clustering Consistent Sparse Subspace Clustering", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-04"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.01046", "oai:arXiv.org:1504.01046"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "stat"]}}, {"name": "description", "properties": {"description": ["  Subspace clustering is the problem of clustering data points into a union of\nlow-dimensional linear or affine subspaces. It is the mathematical abstraction\nof many important problems in computer vision, image processing and has been\ndrawing avid attention in machine learning and statistics recently. In\nparticular, a line of recent work (Elhamifar and Vidal, 2013; Soltanolkotabi et\nal., 2012; Wang and Xu, 2013; Soltanolkotabi et al., 2014) provided strong\ntheoretical guarantee for the seminal algorithm: Sparse Subspace Clustering\n(SSC) (Elhamifar and Vidal, 2013) under various settings, and to some extent,\njustified its state-of-the-art performance in applications such as motion\nsegmentation and face clustering. The focus of these work has been getting\nmilder conditions under which SSC obeys \"self-expressiveness property\", which\nensures that no two points from different subspaces can be clustered together.\nSuch guarantee however is not sufficient for the clustering to be correct,\nthanks to the notorious \"graph connectivity problem\" (Nasihatkon and Hartley,\n2011). In this paper, we show that this issue can be resolved by a very simple\npost-processing procedure under only a mild \"general position\" assumption. In\naddition, we show that the approach is robust to arbitrary bounded perturbation\nof the data whenever the \"general position\" assumption holds with a margin.\nThese results provide the first exact clustering guarantee of SSC for subspaces\nof dimension greater than 3.\n", "Comment: 14 pages"]}}], "languages": [null], "subjects": ["computer science - learning", "statistics - machine learning"], "providerUpdatedDateTime": "2015-04-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.01046"}}, {"publisher": {"name": ""}, "description": "  More and more scientific research shows that there is a close correlation\nbetween the Internet and brain science. This paper presents the idea of\nestablishing the Internet neurology, which means to make a cross-contrast\nbetween the two in terms of physiology and psychology, so that a complete\ninfrastructure system of the Internet is established, predicting the\ndevelopment trend of the Internet in the future as well as the brain structure\nand operation mechanism, and providing theoretical support for the generation\nprinciple of intelligence, cognition and emotion. It also proposes the\nviewpoint that the Internet can be divided into Internet neurophysiology,\nInternet neuropsychology, Brain Internet physiology, Brain Internet psychology\nand the Internet in cognitive science.\n", "contributors": [{"name": "Liu, Feng", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Feng", "email": ""}], "title": "Definition and Research of Internet Neurology", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-04-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.02842", "oai:arXiv.org:1504.02842"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  More and more scientific research shows that there is a close correlation\nbetween the Internet and brain science. This paper presents the idea of\nestablishing the Internet neurology, which means to make a cross-contrast\nbetween the two in terms of physiology and psychology, so that a complete\ninfrastructure system of the Internet is established, predicting the\ndevelopment trend of the Internet in the future as well as the brain structure\nand operation mechanism, and providing theoretical support for the generation\nprinciple of intelligence, cognition and emotion. It also proposes the\nviewpoint that the Internet can be divided into Internet neurophysiology,\nInternet neuropsychology, Brain Internet physiology, Brain Internet psychology\nand the Internet in cognitive science.\n"}}], "languages": [null], "subjects": ["computer science - other computer science"], "providerUpdatedDateTime": "2015-04-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.02842"}}, {"publisher": {"name": ""}, "description": "  This paper considers the controllability analysis problem for a class of\nmultirotor systems subject to rotor failure/wear. It is shown that classical\ncontrollability theories of linear systems are not sufficient to test the\ncontrollability of the considered multirotors. Owing to this, an easy-to-use\nmeasurement index is introduced to assess the available control authority.\nBased on it, a new necessary and sufficient condition for the controllability\nof multirotors is derived. Furthermore, a controllability test procedure is\napproached. The proposed controllability test method is applied to a class of\nhexacopters with different rotor configurations and different rotor efficiency\nparameters to show its effectiveness. The analysis results show that\nhexacopters with different rotor configurations have different fault-tolerant\ncapabilities. It is therefore necessary to test the controllability of the\nmultirotors before any fault-tolerant control strategies are employed.\n", "contributors": [{"name": "Du, Guang-Xun", "sameAs": [], "familyName": "Du", "additionalName": "", "givenName": "Guang-Xun", "email": ""}, {"name": "Quan, Quan", "sameAs": [], "familyName": "Quan", "additionalName": "", "givenName": "Quan", "email": ""}, {"name": "Yang, Binxian", "sameAs": [], "familyName": "Yang", "additionalName": "", "givenName": "Binxian", "email": ""}, {"name": "Cai, Kai-Yuan", "sameAs": [], "familyName": "Cai", "additionalName": "", "givenName": "Kai-Yuan", "email": ""}], "title": "Controllability Analysis for Multirotor Helicopter Rotor Degradation and\n  Failure", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-03-24", "2015-02-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1403.5986", "oai:arXiv.org:1403.5986"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper considers the controllability analysis problem for a class of\nmultirotor systems subject to rotor failure/wear. It is shown that classical\ncontrollability theories of linear systems are not sufficient to test the\ncontrollability of the considered multirotors. Owing to this, an easy-to-use\nmeasurement index is introduced to assess the available control authority.\nBased on it, a new necessary and sufficient condition for the controllability\nof multirotors is derived. Furthermore, a controllability test procedure is\napproached. The proposed controllability test method is applied to a class of\nhexacopters with different rotor configurations and different rotor efficiency\nparameters to show its effectiveness. The analysis results show that\nhexacopters with different rotor configurations have different fault-tolerant\ncapabilities. It is therefore necessary to test the controllability of the\nmultirotors before any fault-tolerant control strategies are employed.\n", "Comment: 21 pages, 4 figures"]}}], "languages": [null], "subjects": ["computer science - systems and control", "computer science - robotics"], "providerUpdatedDateTime": "2015-02-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1403.5986"}}, {"publisher": {"name": ""}, "description": "  We describe four algorithms for neural network training, each adapted to\ndifferent scalability constraints. These algorithms are mathematically\nprincipled and invariant under a number of transformations in data and network\nrepresentation, from which performance is thus independent. These algorithms\nare obtained from the setting of differential geometry, and are based on either\nthe natural gradient using the Fisher information matrix, or on Hessian\nmethods, scaled down in a specific way to allow for scalability while keeping\nsome of their key mathematical properties.\n", "contributors": [{"name": "Ollivier, Yann", "sameAs": [], "familyName": "Ollivier", "additionalName": "", "givenName": "Yann", "email": ""}], "title": "Riemannian metrics for neural networks I: feedforward networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-03-04", "2015-02-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1303.0818", "oai:arXiv.org:1303.0818"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We describe four algorithms for neural network training, each adapted to\ndifferent scalability constraints. These algorithms are mathematically\nprincipled and invariant under a number of transformations in data and network\nrepresentation, from which performance is thus independent. These algorithms\nare obtained from the setting of differential geometry, and are based on either\nthe natural gradient using the Fisher information matrix, or on Hessian\nmethods, scaled down in a specific way to allow for scalability while keeping\nsome of their key mathematical properties.\n", "Comment: (5th version, minor changes)"]}}], "languages": [null], "subjects": ["mathematics - differential geometry", "68t05", "computer science - neural and evolutionary computing", "computer science - information theory", "computer science - learning"], "providerUpdatedDateTime": "2015-02-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1303.0818"}}, {"publisher": {"name": ""}, "description": "  In this work, we propose and study optimal proactive resource allocation and\ndemand shaping for data networks. Motivated by the recent findings on the\npredictability of human behavior patterns in data networks, and the emergence\nof highly capable handheld devices, our design aims to smooth out the network\ntraffic over time and minimize the data delivery costs.\n  Our framework utilizes proactive data services as well as smart content\nrecommendation schemes for shaping the demand. Proactive data services take\nplace during the off-peak hours based on a statistical prediction of a demand\nprofile for each user, whereas smart content recommendation assigns modified\nvaluations to data items so as to render the users' demand less uncertain.\nHence, our recommendation scheme aims to boost the performance of proactive\nservices within the allowed flexibility of user requirements. We conduct\ntheoretical performance analysis that quantifies the leveraged cost reduction\nthrough the proposed framework. We show that the cost reduction scales at the\nsame rate as the cost function scales with the number of users. Further, we\nprove that \\emph{demand shaping} through smart recommendation strictly reduces\nthe incurred cost even below that of proactive downloads without\nrecommendation.\n", "contributors": [{"name": "Tadrous, John", "sameAs": [], "familyName": "Tadrous", "additionalName": "", "givenName": "John", "email": ""}, {"name": "Eryilmaz, Atilla", "sameAs": [], "familyName": "Eryilmaz", "additionalName": "", "givenName": "Atilla", "email": ""}, {"name": "Gamal, Hesham El", "sameAs": [], "familyName": "Gamal", "additionalName": "El", "givenName": "Hesham", "email": ""}], "title": "Proactive Data Download and User Demand Shaping for Data Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-04-21", "2014-12-28"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1304.5745", "oai:arXiv.org:1304.5745"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  In this work, we propose and study optimal proactive resource allocation and\ndemand shaping for data networks. Motivated by the recent findings on the\npredictability of human behavior patterns in data networks, and the emergence\nof highly capable handheld devices, our design aims to smooth out the network\ntraffic over time and minimize the data delivery costs.\n  Our framework utilizes proactive data services as well as smart content\nrecommendation schemes for shaping the demand. Proactive data services take\nplace during the off-peak hours based on a statistical prediction of a demand\nprofile for each user, whereas smart content recommendation assigns modified\nvaluations to data items so as to render the users' demand less uncertain.\nHence, our recommendation scheme aims to boost the performance of proactive\nservices within the allowed flexibility of user requirements. We conduct\ntheoretical performance analysis that quantifies the leveraged cost reduction\nthrough the proposed framework. We show that the cost reduction scales at the\nsame rate as the cost function scales with the number of users. Further, we\nprove that \\emph{demand shaping} through smart recommendation strictly reduces\nthe incurred cost even below that of proactive downloads without\nrecommendation.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "computer science - information theory"], "providerUpdatedDateTime": "2014-12-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1304.5745"}}, {"publisher": {"name": ""}, "description": "  We provide a comprehensive view of various phase transitions in random\n$K$-satisfiability problems solved by stochastic-local-search algorithms. In\nparticular, we focus on the finite-size scaling (FSS) exponent, which is\nmathematically important and practically useful in analyzing finite systems.\nUsing the FSS theory of nonequilibrium absorbing phase transitions, we show\nthat the density of unsatisfied clauses clearly indicates the transition from\nthe solvable (absorbing) phase to the unsolvable (active) phase as varying the\nnoise parameter and the density of constraints. Based on the solution\nclustering (percolation-type) argument, we conjecture two possible values of\nthe FSS exponent, which are confirmed reasonably well in numerical simulations\nfor $2\\le K \\le 3$.\n", "contributors": [{"name": "Lee, Sang Hoon", "sameAs": [], "familyName": "Lee", "additionalName": "Hoon", "givenName": "Sang", "email": ""}, {"name": "Ha, Meesoon", "sameAs": [], "familyName": "Ha", "additionalName": "", "givenName": "Meesoon", "email": ""}, {"name": "Jeon, Chanil", "sameAs": [], "familyName": "Jeon", "additionalName": "", "givenName": "Chanil", "email": ""}, {"name": "Jeong, Hawoong", "sameAs": [], "familyName": "Jeong", "additionalName": "", "givenName": "Hawoong", "email": ""}], "title": "Finite-size scaling in random $K$-satisfiability problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2010-05-03", "2010-12-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1005.0251", "PRE v82, 061109 (2010)", "doi:10.1103/PhysRevE.82.061109", "oai:arXiv.org:1005.0251"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  We provide a comprehensive view of various phase transitions in random\n$K$-satisfiability problems solved by stochastic-local-search algorithms. In\nparticular, we focus on the finite-size scaling (FSS) exponent, which is\nmathematically important and practically useful in analyzing finite systems.\nUsing the FSS theory of nonequilibrium absorbing phase transitions, we show\nthat the density of unsatisfied clauses clearly indicates the transition from\nthe solvable (absorbing) phase to the unsolvable (active) phase as varying the\nnoise parameter and the density of constraints. Based on the solution\nclustering (percolation-type) argument, we conjecture two possible values of\nthe FSS exponent, which are confirmed reasonably well in numerical simulations\nfor $2\\le K \\le 3$.\n", "Comment: 5 pages, 3 figures (6 eps files), 1 table; published version"]}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "physics - computational physics", "condensed matter - statistical mechanics"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1005.0251"}}, {"publisher": {"name": ""}, "description": "  Novel energy-aware cloud management methods dynamically reallocate\ncomputation across geographically distributed data centers to leverage regional\nelectricity price and temperature differences. As a result, a managed VM may\nsuffer occasional downtimes. Current cloud providers only offer high\navailability VMs, without enough flexibility to apply such energy-aware\nmanagement. In this paper we show how to analyse past traces of dynamic cloud\nmanagement actions based on electricity prices and temperatures to estimate VM\navailability and price values. We propose a novel SLA specification approach\nfor offering VMs with different availability and price values guaranteed over\nmultiple SLAs to enable flexible energy-aware cloud management. We determine\nthe optimal number of such SLAs as well as their availability and price\nguaranteed values. We evaluate our approach in a user SLA selection simulation\nusing Wikipedia and Grid'5000 workloads. The results show higher customer\nconversion and 39% average energy savings per VM.\n", "contributors": [{"name": "Lu\u010danin, Dra\u017een", "sameAs": [], "familyName": "Lu\u010danin", "additionalName": "", "givenName": "Dra\u017een", "email": ""}, {"name": "Jrad, Foued", "sameAs": [], "familyName": "Jrad", "additionalName": "", "givenName": "Foued", "email": ""}, {"name": "Brandic, Ivona", "sameAs": [], "familyName": "Brandic", "additionalName": "", "givenName": "Ivona", "email": ""}, {"name": "Streit, Achim", "sameAs": [], "familyName": "Streit", "additionalName": "", "givenName": "Achim", "email": ""}], "title": "Energy-Aware Cloud Management through Progressive SLA Specification", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-09-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.0325", "doi:10.1007/978-3-319-14609-6", "oai:arXiv.org:1409.0325"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Novel energy-aware cloud management methods dynamically reallocate\ncomputation across geographically distributed data centers to leverage regional\nelectricity price and temperature differences. As a result, a managed VM may\nsuffer occasional downtimes. Current cloud providers only offer high\navailability VMs, without enough flexibility to apply such energy-aware\nmanagement. In this paper we show how to analyse past traces of dynamic cloud\nmanagement actions based on electricity prices and temperatures to estimate VM\navailability and price values. We propose a novel SLA specification approach\nfor offering VMs with different availability and price values guaranteed over\nmultiple SLAs to enable flexible energy-aware cloud management. We determine\nthe optimal number of such SLAs as well as their availability and price\nguaranteed values. We evaluate our approach in a user SLA selection simulation\nusing Wikipedia and Grid'5000 workloads. The results show higher customer\nconversion and 39% average energy savings per VM.\n", "Comment: 14 pages, conference"]}}], "languages": [null], "subjects": ["computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2015-03-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.0325"}}, {"publisher": {"name": ""}, "description": "  The essential variables in a finite function $f$ are defined as variables\nwhich occur in $f$ and weigh with the values of that function.\n  The number of essential variables is an important measure of complexity for\ndiscrete functions.\n  When replacing some variables in a function with constants the resulting\nfunctions are called subfunctions, and when replacing all essential variables\nin a function with constants we obtain an implementation of this function.\n  Such an implementation corresponds with a path in an ordered decision diagram\n(ODD) of the function which connects the root with a leaf of the diagram. The\nsets of essential variables in subfunctions of $f$ are called separable in $f$.\nIn this paper we study several properties of separable sets of variables in\nfunctions which directly impact on the number of implementations and\nsubfunctions in these functions.\n  We define equivalence relations which classify the functions of $k$-valued\nlogic into classes with same number of implementations, subfunctions or\nseparable sets. These relations induce three transformation groups which are\ncompared with the lattice of all subgroups of restricted affine group (RAG).\nThis allows us to solve several important computational and combinatorial\nproblems.\n", "contributors": [{"name": "Shtrakov, Sl.", "sameAs": [], "familyName": "Shtrakov", "additionalName": "", "givenName": "Sl.", "email": ""}, {"name": "Damyanov, I.", "sameAs": [], "familyName": "Damyanov", "additionalName": "", "givenName": "I.", "email": ""}], "title": "On the complexity of finite valued functions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-01"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00265", "oai:arXiv.org:1501.00265"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The essential variables in a finite function $f$ are defined as variables\nwhich occur in $f$ and weigh with the values of that function.\n  The number of essential variables is an important measure of complexity for\ndiscrete functions.\n  When replacing some variables in a function with constants the resulting\nfunctions are called subfunctions, and when replacing all essential variables\nin a function with constants we obtain an implementation of this function.\n  Such an implementation corresponds with a path in an ordered decision diagram\n(ODD) of the function which connects the root with a leaf of the diagram. The\nsets of essential variables in subfunctions of $f$ are called separable in $f$.\nIn this paper we study several properties of separable sets of variables in\nfunctions which directly impact on the number of implementations and\nsubfunctions in these functions.\n  We define equivalence relations which classify the functions of $k$-valued\nlogic into classes with same number of implementations, subfunctions or\nseparable sets. These relations induce three transformation groups which are\ncompared with the lattice of all subgroups of restricted affine group (RAG).\nThis allows us to solve several important computational and combinatorial\nproblems.\n", "Comment: 23 pages, 4 figures, 6 tables, Preprint of the article is submitted\n  for consideration in [WSPC (2015)]\n  [http://www.worldscientific.com/worldscinet/ijfcs]"]}}], "languages": [null], "subjects": ["computer science - computational complexity", "03d15", "f.1.3"], "providerUpdatedDateTime": "2015-01-05T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00265"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Thesis. 1975. Ph.D.--Massachusetts Institute of Technology. Dept. of Chemistry.", "contributors": [{"name": "McDermott, Joseph Xavier", "sameAs": [], "familyName": "McDermott", "additionalName": "Xavier", "givenName": "Joseph", "email": ""}, {"name": "G.M. Whitesides.", "sameAs": [], "familyName": "Whitesides.", "additionalName": "", "givenName": "G.M.", "email": ""}], "title": "Platinum and titanium metallocycles.", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "135 leaves"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/80423", "01331355", "oai:dspace.mit.edu:1721.1/80423"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2013-09-12T19:00:09Z", "2013-09-12T19:00:09Z", "1975"]}}, {"name": "description", "properties": {"description": ["Thesis. 1975. Ph.D.--Massachusetts Institute of Technology. Dept. of Chemistry.", "Vita.", "Includes bibliographical references."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_7646", "hdl_1721.1_7794"]}}], "languages": [null], "subjects": ["organoplatinum compounds", "chemistry", "transition metal compounds", "organotitanium compounds", "decomposition (chemistry)"], "providerUpdatedDateTime": "2015-04-27T22:56:24", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/80423"}}, {"publisher": {"name": ""}, "description": "  We consider two CSP problems: the first CSP encodes 2D Sperner's lemma for\nthe standard triangulation of the right triangle on $n^2$ small triangles; the\nsecond CSP encodes the fact that it is impossible to match cells of $n \\times\nn$ square to arrows (two horizontal, two vertical and four diagonal) such that\narrows in two cells with a common edge differ by at most $45^\\circ$, and all\narrows on the boundary of the square do not look outside (this fact is a\ncorollary of the Brower's fixed point theorem). We prove that the tree-like\nresolution complexities of these CSPs are $2^{\\Theta(n)}$. For Sperner's lemma\nour result implies $\\Omega(n)$ lower bound on the number of request to colors\nof vertices that is enough to make in order to find a trichromatic triangle;\nthis lower bound was originally proved by Crescenzi and Silvestri.\n  CSP based on Sperner's lemma is related with the $\\rm PPAD$-complete problem.\nWe show that CSP corresponding to arrows is also related with a $\\rm\nPPAD$-complete problem.\n", "contributors": [{"name": "Itsykson, Dmitry", "sameAs": [], "familyName": "Itsykson", "additionalName": "", "givenName": "Dmitry", "email": ""}, {"name": "Malova, Anna", "sameAs": [], "familyName": "Malova", "additionalName": "", "givenName": "Anna", "email": ""}, {"name": "Oparin, Vsevolod", "sameAs": [], "familyName": "Oparin", "additionalName": "", "givenName": "Vsevolod", "email": ""}, {"name": "Sokolov, Dmitry", "sameAs": [], "familyName": "Sokolov", "additionalName": "", "givenName": "Dmitry", "email": ""}], "title": "Tree-like resolution complexity of two planar problems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-02"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.1124", "oai:arXiv.org:1412.1124"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We consider two CSP problems: the first CSP encodes 2D Sperner's lemma for\nthe standard triangulation of the right triangle on $n^2$ small triangles; the\nsecond CSP encodes the fact that it is impossible to match cells of $n \\times\nn$ square to arrows (two horizontal, two vertical and four diagonal) such that\narrows in two cells with a common edge differ by at most $45^\\circ$, and all\narrows on the boundary of the square do not look outside (this fact is a\ncorollary of the Brower's fixed point theorem). We prove that the tree-like\nresolution complexities of these CSPs are $2^{\\Theta(n)}$. For Sperner's lemma\nour result implies $\\Omega(n)$ lower bound on the number of request to colors\nof vertices that is enough to make in order to find a trichromatic triangle;\nthis lower bound was originally proved by Crescenzi and Silvestri.\n  CSP based on Sperner's lemma is related with the $\\rm PPAD$-complete problem.\nWe show that CSP corresponding to arrows is also related with a $\\rm\nPPAD$-complete problem.\n"}}], "languages": [null], "subjects": ["computer science - computational complexity", "f.2.2", "68q25"], "providerUpdatedDateTime": "2014-12-04T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.1124"}}, {"publisher": {"name": ""}, "description": "  Implicit electron-density solvation models based on joint density-functional\ntheory offer a computationally efficient solution to the problem of calculating\nthermodynamic quantities of solvated systems from firstprinciples quantum\nmechanics. However, despite much recent interest in such models, to date the\napplicability of such models in the plane-wave context to non-aqueous solvents\nhas been limited because the determination of the model parameters requires\nfitting to a large database of experimental solvation energies for each new\nsolvent considered. This work presents an alternate approach which allows\ndevelopment of new iso-density models for a large class of protic and aprotic\nsolvents from only simple, single-molecule ab initio calculations and readily\navailable bulk thermodynamic data.\n", "contributors": [{"name": "Gunceler, Deniz", "sameAs": [], "familyName": "Gunceler", "additionalName": "", "givenName": "Deniz", "email": ""}, {"name": "Arias, T. A.", "sameAs": [], "familyName": "Arias", "additionalName": "A.", "givenName": "T.", "email": ""}], "title": "Universal iso-density polarizable continuum model for molecular solvents", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-03-25", "2015-02-11"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1403.6465", "oai:arXiv.org:1403.6465"]}}, {"name": "setSpec", "properties": {"setSpec": ["physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": "  Implicit electron-density solvation models based on joint density-functional\ntheory offer a computationally efficient solution to the problem of calculating\nthermodynamic quantities of solvated systems from firstprinciples quantum\nmechanics. However, despite much recent interest in such models, to date the\napplicability of such models in the plane-wave context to non-aqueous solvents\nhas been limited because the determination of the model parameters requires\nfitting to a large database of experimental solvation energies for each new\nsolvent considered. This work presents an alternate approach which allows\ndevelopment of new iso-density models for a large class of protic and aprotic\nsolvents from only simple, single-molecule ab initio calculations and readily\navailable bulk thermodynamic data.\n"}}], "languages": [null], "subjects": ["physics - computational physics", "physics - chemical physics", "condensed matter - materials science"], "providerUpdatedDateTime": "2015-02-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1403.6465"}}, {"publisher": {"name": ""}, "description": "  Cloud Data centers aim to provide reliable, sustainable and scalable services\nfor all kinds of applications. Resource scheduling is one of keys to cloud\nservices. To model and evaluate different scheduling policies and algorithms,\nwe propose FlexCloud, a flexible and scalable simulator that enables users to\nsimulate the process of initializing cloud data centers, allocating virtual\nmachine requests and providing performance evaluation for various scheduling\nalgorithms. FlexCloud can be run on a single computer with JVM to simulate\nlarge scale cloud environments with focus on infrastructure as a service;\nadopts agile design patterns to assure the flexibility and extensibility;\nmodels virtual machine migrations which is lack in the existing tools; provides\nuser-friendly interfaces for customized configurations and replaying. Comparing\nto existing simulators, FlexCloud has combining features for supporting public\ncloud providers, load-balance and energy-efficiency scheduling. FlexCloud has\nadvantage in computing time and memory consumption to support large-scale\nsimulations. The detailed design of FlexCloud is introduced and performance\nevaluation is provided.\n", "contributors": [{"name": "Xu, Minxian", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Minxian", "email": ""}, {"name": "Tian, Wenhong", "sameAs": [], "familyName": "Tian", "additionalName": "", "givenName": "Wenhong", "email": ""}, {"name": "Wang, Xinyang", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Xinyang", "email": ""}, {"name": "Xiong, Qin", "sameAs": [], "familyName": "Xiong", "additionalName": "", "givenName": "Qin", "email": ""}], "title": "FlexCloud: A Flexible and Extendible Simulator for Performance\n  Evaluation of Virtual Machine Allocation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05789", "oai:arXiv.org:1501.05789"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Cloud Data centers aim to provide reliable, sustainable and scalable services\nfor all kinds of applications. Resource scheduling is one of keys to cloud\nservices. To model and evaluate different scheduling policies and algorithms,\nwe propose FlexCloud, a flexible and scalable simulator that enables users to\nsimulate the process of initializing cloud data centers, allocating virtual\nmachine requests and providing performance evaluation for various scheduling\nalgorithms. FlexCloud can be run on a single computer with JVM to simulate\nlarge scale cloud environments with focus on infrastructure as a service;\nadopts agile design patterns to assure the flexibility and extensibility;\nmodels virtual machine migrations which is lack in the existing tools; provides\nuser-friendly interfaces for customized configurations and replaying. Comparing\nto existing simulators, FlexCloud has combining features for supporting public\ncloud providers, load-balance and energy-efficiency scheduling. FlexCloud has\nadvantage in computing time and memory consumption to support large-scale\nsimulations. The detailed design of FlexCloud is introduced and performance\nevaluation is provided.\n"}}], "languages": [null], "subjects": ["computer science - distributed", "parallel", "and cluster computing"], "providerUpdatedDateTime": "2015-01-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05789"}}, {"publisher": {"name": ""}, "description": "  Location and mobility patterns of individuals are important to environmental\nplanning, societal resilience, public health, and a host of commercial\napplications. Mining telecommunication traffic and transactions data for such\npurposes is controversial, in particular raising issues of privacy. However,\nour hypothesis is that privacy-sensitive uses are possible and often beneficial\nenough to warrant considerable research and development efforts. Our work\ncontends that peoples behavior can yield patterns of both significant\ncommercial, and research, value. For such purposes, methods and algorithms for\nmining telecommunication data to extract commonly used routes and locations,\narticulated through time-geographical constructs, are described in a case study\nwithin the area of transportation planning and analysis. From the outset, these\nwere designed to balance the privacy of subscribers and the added value of\nmobility patterns derived from their mobile communication traffic and\ntransactions data. Our work directly contrasts the current, commonly held\nnotion that value can only be added to services by directly monitoring the\nbehavior of individuals, such as in current attempts at location-based\nservices. We position our work within relevant legal frameworks for privacy and\ndata protection, and show that our methods comply with such requirements and\nalso follow best-practices\n", "contributors": [{"name": "Sanches, Pedro", "sameAs": [], "familyName": "Sanches", "additionalName": "", "givenName": "Pedro", "email": ""}, {"name": "Svee, Eric-Oluf", "sameAs": [], "familyName": "Svee", "additionalName": "", "givenName": "Eric-Oluf", "email": ""}, {"name": "Bylund, Markus", "sameAs": [], "familyName": "Bylund", "additionalName": "", "givenName": "Markus", "email": ""}, {"name": "Hirsch, Benjamin", "sameAs": [], "familyName": "Hirsch", "additionalName": "", "givenName": "Benjamin", "email": ""}, {"name": "Boman, Magnus", "sameAs": [], "familyName": "Boman", "additionalName": "", "givenName": "Magnus", "email": ""}], "title": "Knowing Your Population: Privacy-Sensitive Mining of Massive Data", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.2247", "Network and Communication Technologies 2, no. 1 (2013): p34", "doi:10.5539/nct.v2n1p34", "oai:arXiv.org:1412.2247"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Location and mobility patterns of individuals are important to environmental\nplanning, societal resilience, public health, and a host of commercial\napplications. Mining telecommunication traffic and transactions data for such\npurposes is controversial, in particular raising issues of privacy. However,\nour hypothesis is that privacy-sensitive uses are possible and often beneficial\nenough to warrant considerable research and development efforts. Our work\ncontends that peoples behavior can yield patterns of both significant\ncommercial, and research, value. For such purposes, methods and algorithms for\nmining telecommunication data to extract commonly used routes and locations,\narticulated through time-geographical constructs, are described in a case study\nwithin the area of transportation planning and analysis. From the outset, these\nwere designed to balance the privacy of subscribers and the added value of\nmobility patterns derived from their mobile communication traffic and\ntransactions data. Our work directly contrasts the current, commonly held\nnotion that value can only be added to services by directly monitoring the\nbehavior of individuals, such as in current attempts at location-based\nservices. We position our work within relevant legal frameworks for privacy and\ndata protection, and show that our methods comply with such requirements and\nalso follow best-practices\n"}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2014-12-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.2247"}}, {"publisher": {"name": ""}, "description": "  The $\\beta$-skeleton $\\{G_{\\beta}(V)\\}$ for a point set V is a family of\ngeometric graphs, defined by the notion of neighborhoods parameterized by real\nnumber $0 < \\beta < \\infty$. By using the distance-based version definition of\n$\\beta$-skeletons we study those graphs for a set of points in $\\mathbb{R}^d$\nspace with $l_1$ and $l_{\\infty}$ metrics. We present algorithms for the entire\nspectrum of $\\beta$ values and we discuss properties of lens-based and\ncircle-based $\\beta$-skeletons in those metrics.\n  Let $V \\in \\mathbb{R}^d$ in $L_{\\infty}$ metric be a set of $n$ points in\ngeneral position. Then, for $\\beta<2$ lens-based $\\beta$-skeleton\n$G_{\\beta}(V)$ can be computed in $O(n^2 \\log^d n)$ time. For $\\beta \\geq 2$\nthere exists an $O(n \\log^{d-1} n)$ time algorithm that constructs\n$\\beta$-skeleton for the set $V$. We show that in $\\mathbb{R}^d$ with\n$L_{\\infty}$ metric, for $\\beta<2$ $\\beta$-skeleton $G_{\\beta}(V)$ for $n$\npoints can be computed in $O(n^2 \\log^d n)$ time. For $\\beta \\geq 2$ there\nexists an $O(n \\log^{d-1} n)$ time algorithm. In $\\mathbb{R}^d$ with $L_1$\nmetric for a set of $n$ points in arbitrary position $\\beta$-skeleton\n$G_{\\beta}(V)$ can be computed in $O(n^2 \\log^{d+2} n)$ time.\n", "contributors": [{"name": "Kowaluk, Miros\u0142aw", "sameAs": [], "familyName": "Kowaluk", "additionalName": "", "givenName": "Miros\u0142aw", "email": ""}, {"name": "Majewska, Gabriela", "sameAs": [], "familyName": "Majewska", "additionalName": "", "givenName": "Gabriela", "email": ""}], "title": "Multidimensional $\\beta$-skeletons in $L_1$ and $L_{\\infty}$ metric", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.5472", "oai:arXiv.org:1411.5472"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The $\\beta$-skeleton $\\{G_{\\beta}(V)\\}$ for a point set V is a family of\ngeometric graphs, defined by the notion of neighborhoods parameterized by real\nnumber $0 < \\beta < \\infty$. By using the distance-based version definition of\n$\\beta$-skeletons we study those graphs for a set of points in $\\mathbb{R}^d$\nspace with $l_1$ and $l_{\\infty}$ metrics. We present algorithms for the entire\nspectrum of $\\beta$ values and we discuss properties of lens-based and\ncircle-based $\\beta$-skeletons in those metrics.\n  Let $V \\in \\mathbb{R}^d$ in $L_{\\infty}$ metric be a set of $n$ points in\ngeneral position. Then, for $\\beta<2$ lens-based $\\beta$-skeleton\n$G_{\\beta}(V)$ can be computed in $O(n^2 \\log^d n)$ time. For $\\beta \\geq 2$\nthere exists an $O(n \\log^{d-1} n)$ time algorithm that constructs\n$\\beta$-skeleton for the set $V$. We show that in $\\mathbb{R}^d$ with\n$L_{\\infty}$ metric, for $\\beta<2$ $\\beta$-skeleton $G_{\\beta}(V)$ for $n$\npoints can be computed in $O(n^2 \\log^d n)$ time. For $\\beta \\geq 2$ there\nexists an $O(n \\log^{d-1} n)$ time algorithm. In $\\mathbb{R}^d$ with $L_1$\nmetric for a set of $n$ points in arbitrary position $\\beta$-skeleton\n$G_{\\beta}(V)$ can be computed in $O(n^2 \\log^{d+2} n)$ time.\n"}}], "languages": [null], "subjects": ["computer science - computational geometry"], "providerUpdatedDateTime": "2014-11-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.5472"}}, {"publisher": {"name": ""}, "description": "  We show that very simple algorithms based on local search are polynomial-time\napproximation schemes for Maximum Independent Set, Minimum Vertex Cover and\nMinimum Dominating Set, when the input graphs have a fixed forbidden minor.\n", "contributors": [{"name": "Cabello, Sergio", "sameAs": [], "familyName": "Cabello", "additionalName": "", "givenName": "Sergio", "email": ""}, {"name": "Gajser, David", "sameAs": [], "familyName": "Gajser", "additionalName": "", "givenName": "David", "email": ""}], "title": "Simple PTAS's for families of graphs excluding a minor", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-10-21", "2015-03-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.5778", "oai:arXiv.org:1410.5778"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We show that very simple algorithms based on local search are polynomial-time\napproximation schemes for Maximum Independent Set, Minimum Vertex Cover and\nMinimum Dominating Set, when the input graphs have a fixed forbidden minor.\n", "Comment: To appear in Discrete Applied Mathematics"]}}], "languages": [null], "subjects": ["05c83", "computer science - discrete mathematics", "68w40", "computer science - data structures and algorithms", "05c85", "68w25"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.5778"}}, {"publisher": {"name": ""}, "description": "  In the case of ordinary identification coding, a code is devised to identify\na single object among $N$ objects. But, in this paper, we consider an\nidentification coding problem to identify $K$ objects at once among $N$ objects\nin the both cases that $K$ objects are ranked or not ranked. By combining\nKurosawa-Yoshida scheme with Moulin-Koetter scheme, an efficient identification\ncoding scheme is proposed, which can attain high coding rate and error\nexponents compared with the case that an ordinary identification code is used\n$K$ times. Furthermore, the achievable triplet of rate and error exponents of\ntype I and type II decoding error probabilities are derived for the proposed\ncoding scheme.\n", "contributors": [{"name": "Yamamoto, Hirosuke", "sameAs": [], "familyName": "Yamamoto", "additionalName": "", "givenName": "Hirosuke", "email": ""}, {"name": "Ueda, Masashi", "sameAs": [], "familyName": "Ueda", "additionalName": "", "givenName": "Masashi", "email": ""}], "title": "Identification Codes to Identify Multiple Objects", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.4612", "oai:arXiv.org:1410.4612"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In the case of ordinary identification coding, a code is devised to identify\na single object among $N$ objects. But, in this paper, we consider an\nidentification coding problem to identify $K$ objects at once among $N$ objects\nin the both cases that $K$ objects are ranked or not ranked. By combining\nKurosawa-Yoshida scheme with Moulin-Koetter scheme, an efficient identification\ncoding scheme is proposed, which can attain high coding rate and error\nexponents compared with the case that an ordinary identification code is used\n$K$ times. Furthermore, the achievable triplet of rate and error exponents of\ntype I and type II decoding error probabilities are derived for the proposed\ncoding scheme.\n", "Comment: 14 pages, submitted to IEEE Transactions on Information Theory"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-10-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.4612"}}, {"publisher": {"name": ""}, "description": "  In the present article, a new system architecture for the next generation of\nsatellite communication (SatComs) is presented. The key concept lies in the\ncollaboration between multibeam satellites that share one orbital position.\nMulti-satellite constellations in unique orbital slots offer gradual deployment\nto cover unpredictable traffic patterns and redundancy to hardware failure\nadvantages. They are also of high relevance during the satellite replacement\nphases or necessitated by constraints in the maximum communications payload\nthat a single satellite can bear. In this context, the potential gains of\nadvanced architectures, that is architectures enabled by the general class of\ncooperative and cognitive techniques, are exhibited via a simple paradigm. More\nspecifically, the scenario presented herein, involves two co-existing multibeam\nsatellites which illuminate overlapping coverage areas. Based on this scenario,\nspecific types of cooperative and cognitive techniques are herein considered as\ncandidate technologies that can boost the performance of multibeam satellite\nconstellations. These techniques are compared to conventional frequency\nsplitting configurations in terms of three different criteria, namely the\nspectral efficiency, the power efficiency and the fairness. Consequently,\ninsightful guidelines for the design of future high throughput constellations\nof multibeam satellites are given.\n", "contributors": [{"name": "Christopoulos, Dimitrios", "sameAs": [], "familyName": "Christopoulos", "additionalName": "", "givenName": "Dimitrios", "email": ""}, {"name": "Sharma, Shree Krishna", "sameAs": [], "familyName": "Sharma", "additionalName": "Krishna", "givenName": "Shree", "email": ""}, {"name": "Chatzinotas, Symeon", "sameAs": [], "familyName": "Chatzinotas", "additionalName": "", "givenName": "Symeon", "email": ""}, {"name": "Ottersten, Jens Krauseand Bjorn", "sameAs": [], "familyName": "Ottersten", "additionalName": "Krauseand Bjorn", "givenName": "Jens", "email": ""}], "title": "Coordinated Multibeam Satellite Co-location: The Dual Satellite Paradigm", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.06981", "oai:arXiv.org:1503.06981"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In the present article, a new system architecture for the next generation of\nsatellite communication (SatComs) is presented. The key concept lies in the\ncollaboration between multibeam satellites that share one orbital position.\nMulti-satellite constellations in unique orbital slots offer gradual deployment\nto cover unpredictable traffic patterns and redundancy to hardware failure\nadvantages. They are also of high relevance during the satellite replacement\nphases or necessitated by constraints in the maximum communications payload\nthat a single satellite can bear. In this context, the potential gains of\nadvanced architectures, that is architectures enabled by the general class of\ncooperative and cognitive techniques, are exhibited via a simple paradigm. More\nspecifically, the scenario presented herein, involves two co-existing multibeam\nsatellites which illuminate overlapping coverage areas. Based on this scenario,\nspecific types of cooperative and cognitive techniques are herein considered as\ncandidate technologies that can boost the performance of multibeam satellite\nconstellations. These techniques are compared to conventional frequency\nsplitting configurations in terms of three different criteria, namely the\nspectral efficiency, the power efficiency and the fairness. Consequently,\ninsightful guidelines for the design of future high throughput constellations\nof multibeam satellites are given.\n", "Comment: Submitted to the IEEE wirless. Comms. Magazine"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.06981"}}, {"publisher": {"name": ""}, "description": "  The proliferation of online social networks in the last decade has not\nstopped short of pets, and many different online platforms now exist catering\nto owners of various pets such as cats and dogs. These online pet social\nnetworks provide a unique opportunity to study an online social network in\nwhich a single user manages multiple user profiles, i.e. one for each pet they\nown. These types of multi-profile networks allow us to investigate two\nquestions: (1) What is the relationship between the pet-level and human-level\nnetwork, and (2) what is the relationship between friendship links and family\nties? Concretely, we study the online social pet networks Catster, Dogster and\nHamsterster, the first two of which are the two largest online pet networks in\nexistence. We show how the networks on the two levels interact, and perform\nexperiments to find out whether knowledge about friendships on a profile-level\nalone can be used to predict which users are behind which profile. In order to\ndo so, we introduce the concept of multi-profile social network, extend a\npreviously defined spectral test of diagonality to multi-profile networks,\ndefine two new homophily measures for multi-profile social networks, perform a\ntwo-level social network analysis, and present an algorithm for predicting\nwhether two profiles were created by the same user. As a result, we are able to\npredict with very high precision whether two profiles were created by a same\nuser. Our work is thus relevant for the analysis of other online communities in\nwhich users may use multiple profiles.\n", "contributors": [{"name": "D\u00fcnker, Daniel", "sameAs": [], "familyName": "D\u00fcnker", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Kunegis, J\u00e9r\u00f4me", "sameAs": [], "familyName": "Kunegis", "additionalName": "", "givenName": "J\u00e9r\u00f4me", "email": ""}], "title": "Social Networking by Proxy: A Case Study of Catster, Dogster and\n  Hamsterster", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-19"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04527", "oai:arXiv.org:1501.04527"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  The proliferation of online social networks in the last decade has not\nstopped short of pets, and many different online platforms now exist catering\nto owners of various pets such as cats and dogs. These online pet social\nnetworks provide a unique opportunity to study an online social network in\nwhich a single user manages multiple user profiles, i.e. one for each pet they\nown. These types of multi-profile networks allow us to investigate two\nquestions: (1) What is the relationship between the pet-level and human-level\nnetwork, and (2) what is the relationship between friendship links and family\nties? Concretely, we study the online social pet networks Catster, Dogster and\nHamsterster, the first two of which are the two largest online pet networks in\nexistence. We show how the networks on the two levels interact, and perform\nexperiments to find out whether knowledge about friendships on a profile-level\nalone can be used to predict which users are behind which profile. In order to\ndo so, we introduce the concept of multi-profile social network, extend a\npreviously defined spectral test of diagonality to multi-profile networks,\ndefine two new homophily measures for multi-profile social networks, perform a\ntwo-level social network analysis, and present an algorithm for predicting\nwhether two profiles were created by the same user. As a result, we are able to\npredict with very high precision whether two profiles were created by a same\nuser. Our work is thus relevant for the analysis of other online communities in\nwhich users may use multiple profiles.\n", "Comment: 10 pages"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04527"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Understanding the microbial world is key to understanding global biogeochemistry, human health and disease, yet this world is largely inaccessible. Microbial genomes, an increasingly accessible data source, provide an ideal entry point. The genome sequences of different microbes may be compared using the tools of population genetics to infer important genetic changes allowing them to diversify ecologically and adapt to distinct ecological niches. Yet the toolkit of population genetics was developed largely with sexual eukaryotes in mind. In this work, I assess and develop tools for inferring natural selection in microbial genomes. Many tools rely on population genetics theory, and thus require defining distinct populations, or species, of bacteria. Because sex (recombination) is not required for reproduction, some bacteria recombine only rarely, while others are extremely promiscuous, exchanging genes across great genetic distances. This behavior poses a challenge for defining microbial population boundaries. This thesis begins with a discussion of how recombination and positive selection interact to promote ecological adaptation. I then describe a general pipeline for quantifying the impacts of mutation, recombination and selection on microbial genomes, and apply it to two closely related, yet ecologically distinct populations of Vibrio splendidus, each with its own microhabitat preference. I introduce a new tool, STARRInIGHTS, for inferring homologous recombination events. By assessing rates of recombination within and between ecological populations, I conclude that ecological differentiation is driven by small number of habitat-specific alleles, while most loci are shared freely across habitats. The remainder of the thesis focuses on lineage-specific changes in natural selection among anciently diverged species of gamma proteobacteria. I develop two new metrics, selective signatures and slow:fast, for detecting deviations from the expected rate of evolution in 'core' proteins (present in single copy in most species). Because they rely on empirical distributions of evolutionary rates across species, these methods should become increasingly powerful as more and more microbial genomes are sampled. Overall, the methods described here significantly expand the repertoire of tools available for microbial population genomics, both for investigating the process of ecological differentiation at the finest of time scales, and over billions of years of microbial evolution.", "contributors": [{"name": "Shapiro, B. Jesse (Benjamin Jesse)", "sameAs": [], "familyName": "Shapiro", "additionalName": "Jesse", "givenName": "B.", "email": ""}, {"name": "Massachusetts Institute of Technology. Computational and Systems Biology Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computational and Systems Biology", "givenName": "Massachusetts", "email": ""}, {"name": "Eric J. Alm.", "sameAs": [], "familyName": "Alm.", "additionalName": "J.", "givenName": "Eric", "email": ""}], "title": "Genomic signatures of sex, selection and speciation in the microbial world", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "228 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/61788", "706715014", "oai:dspace.mit.edu:1721.1/61788"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2011-03-24T18:52:25Z", "2011-03-24T18:52:25Z", "2010", "2010"]}}, {"name": "description", "properties": {"description": ["Understanding the microbial world is key to understanding global biogeochemistry, human health and disease, yet this world is largely inaccessible. Microbial genomes, an increasingly accessible data source, provide an ideal entry point. The genome sequences of different microbes may be compared using the tools of population genetics to infer important genetic changes allowing them to diversify ecologically and adapt to distinct ecological niches. Yet the toolkit of population genetics was developed largely with sexual eukaryotes in mind. In this work, I assess and develop tools for inferring natural selection in microbial genomes. Many tools rely on population genetics theory, and thus require defining distinct populations, or species, of bacteria. Because sex (recombination) is not required for reproduction, some bacteria recombine only rarely, while others are extremely promiscuous, exchanging genes across great genetic distances. This behavior poses a challenge for defining microbial population boundaries. This thesis begins with a discussion of how recombination and positive selection interact to promote ecological adaptation. I then describe a general pipeline for quantifying the impacts of mutation, recombination and selection on microbial genomes, and apply it to two closely related, yet ecologically distinct populations of Vibrio splendidus, each with its own microhabitat preference. I introduce a new tool, STARRInIGHTS, for inferring homologous recombination events. By assessing rates of recombination within and between ecological populations, I conclude that ecological differentiation is driven by small number of habitat-specific alleles, while most loci are shared freely across habitats. The remainder of the thesis focuses on lineage-specific changes in natural selection among anciently diverged species of gamma proteobacteria. I develop two new metrics, selective signatures and slow:fast, for detecting deviations from the expected rate of evolution in 'core' proteins (present in single copy in most species). Because they rely on empirical distributions of evolutionary rates across species, these methods should become increasingly powerful as more and more microbial genomes are sampled. Overall, the methods described here significantly expand the repertoire of tools available for microbial population genomics, both for investigating the process of ecological differentiation at the finest of time scales, and over billions of years of microbial evolution.", "by B. Jesse Shapiro.", "Thesis (Ph. D.)--Massachusetts Institute of Technology, Computational and Systems Biology Program, 2010.", "This electronic version was submitted by the student author.  The certified thesis is available in the Institute Archives and Special Collections.", "Cataloged from student-submitted PDF version of thesis.", "Includes bibliographical references (p. 218-228)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_54823", "hdl_1721.1_54828"]}}], "languages": [null], "subjects": ["computational and systems biology program."], "providerUpdatedDateTime": "2015-04-27T14:53:05", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/61788"}}, {"publisher": {"name": ""}, "description": "  We study the problem of selling $n$ items to a number of buyers with additive\nvaluation functions. We consider the items to be correlated, i.e.,\ndesirabilities of buyers for the items are not drawn independently. Ideally,\nthe goal is to design a mechanism to maximize the revenue. However, it has been\nshown that the optimum-revenue mechanism might be very complicated and as a\nresult inapplicable to real-world auctions. Therefore, our focus is on\ndesigning a simple mechanism that gets a constant fraction of the optimal\nrevenue. This problem was posed by Babaioff et al. in paper \"A Simple and\nApproximately Optimal Mechanism for an Additive Buyer\" (FOCS 2014) as an open\nquestion. In their paper they show a constant approximation of the optimal\nrevenue can be achieved by either selling the items separately or as a whole\nbundle in the independent setting. We show a similar result for the correlated\nsetting when the desirabilities of buyers are drawn from a common-base\ncorrelation. It is worth mentioning that the core decomposition lemma which is\nmainly the heart of the proofs for efficiency of the mechanisms does not hold\nfor correlated settings. Therefore we proposed a modified version of this lemma\nwhich plays a key role in proving bounds on the approximation of the mechanism.\nIn addition, we introduce a generalized form of correlation for items and show\nthe same mechanism can achieve an approximation of the optimal revenue in that\nsetting.\n", "contributors": [{"name": "Bateni, MohammadHossein", "sameAs": [], "familyName": "Bateni", "additionalName": "", "givenName": "MohammadHossein", "email": ""}, {"name": "Dehghani, Sina", "sameAs": [], "familyName": "Dehghani", "additionalName": "", "givenName": "Sina", "email": ""}, {"name": "Hajiaghayi, MohammadTaghi", "sameAs": [], "familyName": "Hajiaghayi", "additionalName": "", "givenName": "MohammadTaghi", "email": ""}, {"name": "Seddighin, Saeed", "sameAs": [], "familyName": "Seddighin", "additionalName": "", "givenName": "Saeed", "email": ""}], "title": "Revenue Maximization for Selling Multiple Correlated Items", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-09"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3187", "oai:arXiv.org:1412.3187"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We study the problem of selling $n$ items to a number of buyers with additive\nvaluation functions. We consider the items to be correlated, i.e.,\ndesirabilities of buyers for the items are not drawn independently. Ideally,\nthe goal is to design a mechanism to maximize the revenue. However, it has been\nshown that the optimum-revenue mechanism might be very complicated and as a\nresult inapplicable to real-world auctions. Therefore, our focus is on\ndesigning a simple mechanism that gets a constant fraction of the optimal\nrevenue. This problem was posed by Babaioff et al. in paper \"A Simple and\nApproximately Optimal Mechanism for an Additive Buyer\" (FOCS 2014) as an open\nquestion. In their paper they show a constant approximation of the optimal\nrevenue can be achieved by either selling the items separately or as a whole\nbundle in the independent setting. We show a similar result for the correlated\nsetting when the desirabilities of buyers are drawn from a common-base\ncorrelation. It is worth mentioning that the core decomposition lemma which is\nmainly the heart of the proofs for efficiency of the mechanisms does not hold\nfor correlated settings. Therefore we proposed a modified version of this lemma\nwhich plays a key role in proving bounds on the approximation of the mechanism.\nIn addition, we introduce a generalized form of correlation for items and show\nthe same mechanism can achieve an approximation of the optimal revenue in that\nsetting.\n"}}], "languages": [null], "subjects": ["computer science - computer science and game theory"], "providerUpdatedDateTime": "2014-12-11T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3187"}}, {"publisher": {"name": ""}, "description": "  A good deal of current research in complex networks involves the\ncharacterization and/or classification of the topological properties of given\nstructures, which has motivated several respective measurements. This letter\nproposes a framework for evaluating the quality of complex network measurements\nin terms of their effective resolution, degree of degeneracy and\ndiscriminability. The potential of the suggested approach is illustrated with\nrespect to comparing the characterization of several model and real-world\nnetworks by using concentric and symmetry measurements. The results indicate a\nmarkedly superior performance for the latter type of mapping.\n", "contributors": [{"name": "Comin, Cesar H.", "sameAs": [], "familyName": "Comin", "additionalName": "H.", "givenName": "Cesar", "email": ""}, {"name": "Silva, Filipi N.", "sameAs": [], "familyName": "Silva", "additionalName": "N.", "givenName": "Filipi", "email": ""}, {"name": "Costa, Luciano da F.", "sameAs": [], "familyName": "Costa", "additionalName": "da F.", "givenName": "Luciano", "email": ""}], "title": "A Framework for Evaluating Complex Networks Measurements", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-12-23", "2015-02-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.7367", "oai:arXiv.org:1412.7367"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": "  A good deal of current research in complex networks involves the\ncharacterization and/or classification of the topological properties of given\nstructures, which has motivated several respective measurements. This letter\nproposes a framework for evaluating the quality of complex network measurements\nin terms of their effective resolution, degree of degeneracy and\ndiscriminability. The potential of the suggested approach is illustrated with\nrespect to comparing the characterization of several model and real-world\nnetworks by using concentric and symmetry measurements. The results indicate a\nmarkedly superior performance for the latter type of mapping.\n"}}], "languages": [null], "subjects": ["physics - physics and society", "physics - data analysis", "statistics and probability", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-02-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.7367"}}, {"publisher": {"name": ""}, "description": "  Google Scholar allows merging multiple article versions into one. This\nmerging affects the H-index computed by Google Scholar. We analyze the\nparameterized complexity of maximizing the H-index using article merges.\nHerein, multiple possible measures for computing the citation count of a merged\narticle are considered. Among others, for the measure used by Google Scholar,\nwe give an algorithm that maximizes the H-index in linear time if there is only\na constant number of versions of the same article. In contrast, if we are\nallowed to merge arbitrary articles, then already increasing the H-index by one\nis NP-hard.\n", "contributors": [{"name": "van Bevern, Ren\u00e9", "sameAs": [], "familyName": "van Bevern", "additionalName": "", "givenName": "Ren\u00e9", "email": ""}, {"name": "Komusiewicz, Christian", "sameAs": [], "familyName": "Komusiewicz", "additionalName": "", "givenName": "Christian", "email": ""}, {"name": "Niedermeier, Rolf", "sameAs": [], "familyName": "Niedermeier", "additionalName": "", "givenName": "Rolf", "email": ""}, {"name": "Sorge, Manuel", "sameAs": [], "familyName": "Sorge", "additionalName": "", "givenName": "Manuel", "email": ""}, {"name": "Walsh, Toby", "sameAs": [], "familyName": "Walsh", "additionalName": "", "givenName": "Toby", "email": ""}], "title": "On Google Scholar H-Index Manipulation by Merging Articles", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-17"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.5498", "oai:arXiv.org:1412.5498"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Google Scholar allows merging multiple article versions into one. This\nmerging affects the H-index computed by Google Scholar. We analyze the\nparameterized complexity of maximizing the H-index using article merges.\nHerein, multiple possible measures for computing the citation count of a merged\narticle are considered. Among others, for the measure used by Google Scholar,\nwe give an algorithm that maximizes the H-index in linear time if there is only\na constant number of versions of the same article. In contrast, if we are\nallowed to merge arbitrary articles, then already increasing the H-index by one\nis NP-hard.\n"}}], "languages": [null], "subjects": ["g.2.1", "g.2.2", "f.2.2", "computer science - discrete mathematics", "h.3.7", "computer science - digital libraries", "computer science - social and information networks", "91d30", "computer science - data structures and algorithms"], "providerUpdatedDateTime": "2014-12-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.5498"}}, {"publisher": {"name": ""}, "description": "  Visual media has always been the most enjoyed way of communication. From the\nadvent of television to the modern day hand held computers, we have witnessed\nthe exponential growth of images around us. Undoubtedly it's a fact that they\ncarry a lot of information in them which needs be utilized in an effective\nmanner. Hence intense need has been felt to efficiently index and store large\nimage collections for effective and on- demand retrieval. For this purpose\nlow-level features extracted from the image contents like color, texture and\nshape has been used. Content based image retrieval systems employing these\nfeatures has proven very successful. Image retrieval has promising applications\nin numerous fields and hence has motivated researchers all over the world. New\nand improved ways to represent visual content are being developed each day.\nTremendous amount of research has been carried out in the last decade. In this\npaper we will present a detailed overview of some of the powerful color,\ntexture and shape descriptors for content based image retrieval. A comparative\nanalysis will also be carried out for providing an insight into outstanding\nchallenges in this field.\n", "contributors": [{"name": "Ahmad, Jamil", "sameAs": [], "familyName": "Ahmad", "additionalName": "", "givenName": "Jamil", "email": ""}, {"name": "Sajjad, Muhammad", "sameAs": [], "familyName": "Sajjad", "additionalName": "", "givenName": "Muhammad", "email": ""}, {"name": "Mehmood, Irfan", "sameAs": [], "familyName": "Mehmood", "additionalName": "", "givenName": "Irfan", "email": ""}, {"name": "Rho, Seungmin", "sameAs": [], "familyName": "Rho", "additionalName": "", "givenName": "Seungmin", "email": ""}, {"name": "Baik, Sung Wook", "sameAs": [], "familyName": "Baik", "additionalName": "Wook", "givenName": "Sung", "email": ""}], "title": "Describing Colors, Textures and Shapes for Content Based Image Retrieval\n  - A Survey", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-24"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07041", "(2014), Journal of Platform Technology 2(4): 34-48", "oai:arXiv.org:1502.07041"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Visual media has always been the most enjoyed way of communication. From the\nadvent of television to the modern day hand held computers, we have witnessed\nthe exponential growth of images around us. Undoubtedly it's a fact that they\ncarry a lot of information in them which needs be utilized in an effective\nmanner. Hence intense need has been felt to efficiently index and store large\nimage collections for effective and on- demand retrieval. For this purpose\nlow-level features extracted from the image contents like color, texture and\nshape has been used. Content based image retrieval systems employing these\nfeatures has proven very successful. Image retrieval has promising applications\nin numerous fields and hence has motivated researchers all over the world. New\nand improved ways to represent visual content are being developed each day.\nTremendous amount of research has been carried out in the last decade. In this\npaper we will present a detailed overview of some of the powerful color,\ntexture and shape descriptors for content based image retrieval. A comparative\nanalysis will also be carried out for providing an insight into outstanding\nchallenges in this field.\n"}}], "languages": [null], "subjects": ["computer science - information retrieval", "computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2015-02-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07041"}}, {"publisher": {"name": ""}, "description": "  The aim of this article is to use generalized complex structures in order to\nextend the definition of twistor spaces given by Penrose. We will adapt the\nintegrability result of Atiyah, Hitchin and Singer. We will deduce new\ncorrespondences betwenn differential geometry and (generalized) complex\ngeometry. In the last section we will show how these results generalized\nBredthauer's work.\n", "contributors": [{"name": "Deschamps, Guillaume", "sameAs": [], "familyName": "Deschamps", "additionalName": "", "givenName": "Guillaume", "email": ""}], "title": "Espaces de twisteurs des structures complexes g\\'en\\'eralis\\'ees", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-09-26", "2015-02-18"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1209.5870", "oai:arXiv.org:1209.5870"]}}, {"name": "setSpec", "properties": {"setSpec": "math"}}, {"name": "description", "properties": {"description": ["  The aim of this article is to use generalized complex structures in order to\nextend the definition of twistor spaces given by Penrose. We will adapt the\nintegrability result of Atiyah, Hitchin and Singer. We will deduce new\ncorrespondences betwenn differential geometry and (generalized) complex\ngeometry. In the last section we will show how these results generalized\nBredthauer's work.\n", "Comment: 19 pages, in French"]}}], "languages": [null], "subjects": ["mathematics - differential geometry", "mathematics - complex variables"], "providerUpdatedDateTime": "2015-02-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1209.5870"}}, {"publisher": {"name": ""}, "description": "  We are interested in characterising pairs $S,T$ of $F$-linear subspaces in a\nfield extension $L/F$ such that the linear span $ST$ of the set of products of\nelements of $S$ and of elements of $T$ has small dimension. Our central result\nis a linear analogue of Vosper's Theorem, which gives the structure of vector\nspaces $S,T$ in a prime extension $L$ of a finite field $F$ for which\n$\\dim_F(ST) =\\dim_F(S)+\\dim_F(T)-1$, when $\\dim_F(S), \\dim_F(T) >1$ and\n$\\dim_F(ST) < [L:F]-1$.\n", "contributors": [{"name": "Bachoc, Christine", "sameAs": [], "familyName": "Bachoc", "additionalName": "", "givenName": "Christine", "email": ""}, {"name": "Serra, Oriol", "sameAs": [], "familyName": "Serra", "additionalName": "", "givenName": "Oriol", "email": ""}, {"name": "Zemor, Gilles", "sameAs": [], "familyName": "Zemor", "additionalName": "", "givenName": "Gilles", "email": ""}], "title": "An analogue of Vosper's Theorem for Extension Fields", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.00602", "oai:arXiv.org:1501.00602"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  We are interested in characterising pairs $S,T$ of $F$-linear subspaces in a\nfield extension $L/F$ such that the linear span $ST$ of the set of products of\nelements of $S$ and of elements of $T$ has small dimension. Our central result\nis a linear analogue of Vosper's Theorem, which gives the structure of vector\nspaces $S,T$ in a prime extension $L$ of a finite field $F$ for which\n$\\dim_F(ST) =\\dim_F(S)+\\dim_F(T)-1$, when $\\dim_F(S), \\dim_F(T) >1$ and\n$\\dim_F(ST) < [L:F]-1$.\n"}}], "languages": [null], "subjects": ["mathematics - number theory", "computer science - information theory", "mathematics - combinatorics", "11p70 (primary) 94b65 12f99 (secondary)"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.00602"}}, {"publisher": {"name": ""}, "description": "  Reconstructing complex networks from measurable data is a fundamental problem\nfor understanding and controlling collective dynamics of complex networked\nsystems. However, a significant challenge arises when we attempt to decode\nstructural information hidden in limited amounts of data accompanied by noise\nand in the presence of inaccessible nodes. Here, we develop a general framework\nfor robust reconstruction of complex networks from sparse and noisy data.\nSpecifically, we decompose the task of reconstructing the whole network into\nrecovering local structures centered at each node. Thus, the natural sparsity\nof complex networks ensures a conversion from the local structure\nreconstruction into a sparse signal reconstruction problem that can be\naddressed by using the lasso, a convex optimization method. We apply our method\nto evolutionary games, transportation and communication processes taking place\nin a variety of model and real complex networks, finding that universal high\nreconstruction accuracy can be achieved from sparse data in spite of noise in\ntime series and missing data of partial nodes. Our approach opens new routes to\nthe network reconstruction problem and has potential applications in a wide\nrange of fields.\n", "contributors": [{"name": "Han, Xiao", "sameAs": [], "familyName": "Han", "additionalName": "", "givenName": "Xiao", "email": ""}, {"name": "Shen, Zhesi", "sameAs": [], "familyName": "Shen", "additionalName": "", "givenName": "Zhesi", "email": ""}, {"name": "Wang, Wen-Xu", "sameAs": [], "familyName": "Wang", "additionalName": "", "givenName": "Wen-Xu", "email": ""}, {"name": "Di, Zengru", "sameAs": [], "familyName": "Di", "additionalName": "", "givenName": "Zengru", "email": ""}], "title": "Robust Reconstruction of Complex Networks from Sparse Data", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-20"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.04731", "doi:10.1103/PhysRevLett.114.028701", "oai:arXiv.org:1501.04731"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Reconstructing complex networks from measurable data is a fundamental problem\nfor understanding and controlling collective dynamics of complex networked\nsystems. However, a significant challenge arises when we attempt to decode\nstructural information hidden in limited amounts of data accompanied by noise\nand in the presence of inaccessible nodes. Here, we develop a general framework\nfor robust reconstruction of complex networks from sparse and noisy data.\nSpecifically, we decompose the task of reconstructing the whole network into\nrecovering local structures centered at each node. Thus, the natural sparsity\nof complex networks ensures a conversion from the local structure\nreconstruction into a sparse signal reconstruction problem that can be\naddressed by using the lasso, a convex optimization method. We apply our method\nto evolutionary games, transportation and communication processes taking place\nin a variety of model and real complex networks, finding that universal high\nreconstruction accuracy can be achieved from sparse data in spite of noise in\ntime series and missing data of partial nodes. Our approach opens new routes to\nthe network reconstruction problem and has potential applications in a wide\nrange of fields.\n", "Comment: 5 pages, 2 figures, 2 tables"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-01-21T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.04731"}}, {"publisher": {"name": ""}, "description": "  The main aim of this paper is to document the performance of $p$-refinement\nwith respect to maximum principles and the non-negative constraint. The model\nproblem is (steady-state) anisotropic diffusion with decay (which is a\nsecond-order elliptic partial differential equation). We considered the\nstandard single-field formulation (which is based on the Galerkin formalism)\nand two least-squares-based mixed formulations. We have employed non-uniform\nLagrange polynomials for altering the polynomial order in each element, and we\nhave used $p = 1, ..., 10$.\n  It will be shown that the violation of the non-negative constraint will not\nvanish with $p$-refinement for anisotropic diffusion. We shall illustrate the\nperformance of $p$-refinement using several representative problems. The\nintended outcome of the paper is twofold. Firstly, this study will caution the\nusers of high-order approximations about its performance with respect to\nmaximum principles and the non-negative constraint. Secondly, this study will\nhelp researchers to develop new methodologies for enforcing maximum principles\nand the non-negative constraint under high-order approximations.\n", "contributors": [{"name": "Payette, G. S.", "sameAs": [], "familyName": "Payette", "additionalName": "S.", "givenName": "G.", "email": ""}, {"name": "Nakshatrala, K. B.", "sameAs": [], "familyName": "Nakshatrala", "additionalName": "B.", "givenName": "K.", "email": ""}, {"name": "Reddy, J. N.", "sameAs": [], "familyName": "Reddy", "additionalName": "N.", "givenName": "J.", "email": ""}], "title": "On the performance of high-order finite elements with respect to maximum\n  principles and the non-negative constraint for diffusion-type equations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-08-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1108.0952", "oai:arXiv.org:1108.0952"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  The main aim of this paper is to document the performance of $p$-refinement\nwith respect to maximum principles and the non-negative constraint. The model\nproblem is (steady-state) anisotropic diffusion with decay (which is a\nsecond-order elliptic partial differential equation). We considered the\nstandard single-field formulation (which is based on the Galerkin formalism)\nand two least-squares-based mixed formulations. We have employed non-uniform\nLagrange polynomials for altering the polynomial order in each element, and we\nhave used $p = 1, ..., 10$.\n  It will be shown that the violation of the non-negative constraint will not\nvanish with $p$-refinement for anisotropic diffusion. We shall illustrate the\nperformance of $p$-refinement using several representative problems. The\nintended outcome of the paper is twofold. Firstly, this study will caution the\nusers of high-order approximations about its performance with respect to\nmaximum principles and the non-negative constraint. Secondly, this study will\nhelp researchers to develop new methodologies for enforcing maximum principles\nand the non-negative constraint under high-order approximations.\n"}}], "languages": [null], "subjects": ["mathematics - numerical analysis", "computer science - numerical analysis"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1108.0952"}}, {"publisher": {"name": ""}, "description": "  The article revisits spatial interaction and distance decay from the\nperspective of human mobility patterns and spatially-embedded networks based on\nan empirical data set. We extract nationwide inter-urban movements in China\nfrom a check-in data set that covers half million individuals and 370 cities to\nanalyze the underlying patterns of trips and spatial interactions. By fitting\nthe gravity model, we find that the observed spatial interactions are governed\nby a power law distance decay effect. The obtained gravity model also well\nreproduces the exponential trip displacement distribution. However, due to the\necological fallacy issue, the movement of an individual may not obey the same\ndistance decay effect. We also construct a spatial network where the edge\nweights denote the interaction strengths. The communities detected from the\nnetwork are spatially connected and roughly consistent with province\nboundaries. We attribute this pattern to different distance decay parameters\nbetween intra-province and inter-province trips.\n", "contributors": [{"name": "Liu, Yu", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Yu", "email": ""}, {"name": "Sui, Zhengwei", "sameAs": [], "familyName": "Sui", "additionalName": "", "givenName": "Zhengwei", "email": ""}, {"name": "Kang, Chaogui", "sameAs": [], "familyName": "Kang", "additionalName": "", "givenName": "Chaogui", "email": ""}, {"name": "Gao, Yong", "sameAs": [], "familyName": "Gao", "additionalName": "", "givenName": "Yong", "email": ""}], "title": "Uncovering patterns of inter-urban trip and spatial interaction from\n  social media check-in data", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-10-01", "2013-11-17"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1310.0282", "PLoS ONE 9(1): e86026", "doi:10.1371/journal.pone.0086026", "oai:arXiv.org:1310.0282"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  The article revisits spatial interaction and distance decay from the\nperspective of human mobility patterns and spatially-embedded networks based on\nan empirical data set. We extract nationwide inter-urban movements in China\nfrom a check-in data set that covers half million individuals and 370 cities to\nanalyze the underlying patterns of trips and spatial interactions. By fitting\nthe gravity model, we find that the observed spatial interactions are governed\nby a power law distance decay effect. The obtained gravity model also well\nreproduces the exponential trip displacement distribution. However, due to the\necological fallacy issue, the movement of an individual may not obey the same\ndistance decay effect. We also construct a spatial network where the edge\nweights denote the interaction strengths. The communities detected from the\nnetwork are spatially connected and roughly consistent with province\nboundaries. We attribute this pattern to different distance decay parameters\nbetween intra-province and inter-province trips.\n", "Comment: 20 pages, 10 figures"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-04-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1310.0282"}}, {"publisher": {"name": ""}, "description": "  In a recent series of papers a surprisingly strong connection was discovered\nbetween standard models of evolution in mathematical biology and Multiplicative\nWeights Updates Algorithm, a ubiquitous model of online learning and\noptimization. These papers establish that mathematical models of biological\nevolution are tantamount to applying discrete Multiplicative Weights Updates\nAlgorithm, a close variant of MWUA, on coordination games. This connection\nallows for introducing insights from the study of game theoretic dynamics into\nthe field of mathematical biology. Using these results as a stepping stone, we\nshow that mathematical models of haploid evolution imply the extinction of\ngenetic diversity in the long term limit, a widely believed conjecture in\ngenetics. In game theoretic terms we show that in the case of coordination\ngames, under minimal genericity assumptions, discrete MWUA converges to pure\nNash equilibria for all but a zero measure of initial conditions. This result\nholds despite the fact that mixed Nash equilibria can be exponentially (or even\nuncountably) many, completely dominating in number the set of pure Nash\nequilibria. Thus, in haploid organisms the long term preservation of genetic\ndiversity needs to be safeguarded by other evolutionary mechanisms such as\nmutations and speciation.\n", "contributors": [{"name": "Mehta, Ruta", "sameAs": [], "familyName": "Mehta", "additionalName": "", "givenName": "Ruta", "email": ""}, {"name": "Panageas, Ioannis", "sameAs": [], "familyName": "Panageas", "additionalName": "", "givenName": "Ioannis", "email": ""}, {"name": "Piliouras, Georgios", "sameAs": [], "familyName": "Piliouras", "additionalName": "", "givenName": "Georgios", "email": ""}], "title": "Natural Selection as an Inhibitor of Genetic Diversity: Multiplicative\n  Weights Updates Algorithm and a Conjecture of Haploid Genetics", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-26", "2014-10-07"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.6270", "oai:arXiv.org:1408.6270"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "q-bio"]}}, {"name": "description", "properties": {"description": ["  In a recent series of papers a surprisingly strong connection was discovered\nbetween standard models of evolution in mathematical biology and Multiplicative\nWeights Updates Algorithm, a ubiquitous model of online learning and\noptimization. These papers establish that mathematical models of biological\nevolution are tantamount to applying discrete Multiplicative Weights Updates\nAlgorithm, a close variant of MWUA, on coordination games. This connection\nallows for introducing insights from the study of game theoretic dynamics into\nthe field of mathematical biology. Using these results as a stepping stone, we\nshow that mathematical models of haploid evolution imply the extinction of\ngenetic diversity in the long term limit, a widely believed conjecture in\ngenetics. In game theoretic terms we show that in the case of coordination\ngames, under minimal genericity assumptions, discrete MWUA converges to pure\nNash equilibria for all but a zero measure of initial conditions. This result\nholds despite the fact that mixed Nash equilibria can be exponentially (or even\nuncountably) many, completely dominating in number the set of pure Nash\nequilibria. Thus, in haploid organisms the long term preservation of genetic\ndiversity needs to be safeguarded by other evolutionary mechanisms such as\nmutations and speciation.\n", "Comment: 18 pages, 1 figure"]}}], "languages": [null], "subjects": ["quantitative biology - quantitative methods", "computer science - computational engineering", "finance", "mathematics - dynamical systems", "and science"], "providerUpdatedDateTime": "2014-10-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.6270"}}, {"publisher": {"name": ""}, "description": "  XML-based communication governs most of today's systems communication, due to\nits capability of representing complex structural and hierarchical data.\nHowever, XML document structure is considered a huge and bulky data that can be\nreduced to minimize bandwidth usage, transmission time, and maximize\nperformance. This contributes to a more efficient and utilized resource usage.\nIn cloud environments, this affects the amount of money the consumer pays.\nSeveral techniques are used to achieve this goal. This paper discusses these\ntechniques and proposes a new XML Schema-based Minification technique. The\nproposed technique works on XML Structure reduction using minification. The\nproposed technique provides a separation between the meaningful names and the\nunderlying minified names, which enhances software/code readability. This\ntechnique is applied to Intrusion Detection Message Exchange Format (IDMEF)\nmessages, as part of Security Information and Event Management (SIEM) system\ncommunication hosted on Microsoft Azure Cloud. Test results show message size\nreduction ranging from 8.15% to 50.34% in the raw message, without using\ntime-consuming compression techniques. Adding GZip compression to the proposed\ntechnique produces 66.1% shorter message size compared to original XML\nmessages.\n", "contributors": [{"name": "Moussa, Bishoy", "sameAs": [], "familyName": "Moussa", "additionalName": "", "givenName": "Bishoy", "email": ""}, {"name": "Mostafa, Mahmoud", "sameAs": [], "familyName": "Mostafa", "additionalName": "", "givenName": "Mahmoud", "email": ""}, {"name": "El-Khouly, Mahmoud", "sameAs": [], "familyName": "El-Khouly", "additionalName": "", "givenName": "Mahmoud", "email": ""}], "title": "XML Schema-based Minification for Communication of Security Information\n  and Event Management (SIEM) Systems in Cloud Environments", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-03"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.2553", "International Journal of Advanced Computer Science and\n  Applications (IJACSA), 5(9), 2014", "doi:10.14569/IJACSA.2014.050912", "oai:arXiv.org:1410.2553"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  XML-based communication governs most of today's systems communication, due to\nits capability of representing complex structural and hierarchical data.\nHowever, XML document structure is considered a huge and bulky data that can be\nreduced to minimize bandwidth usage, transmission time, and maximize\nperformance. This contributes to a more efficient and utilized resource usage.\nIn cloud environments, this affects the amount of money the consumer pays.\nSeveral techniques are used to achieve this goal. This paper discusses these\ntechniques and proposes a new XML Schema-based Minification technique. The\nproposed technique works on XML Structure reduction using minification. The\nproposed technique provides a separation between the meaningful names and the\nunderlying minified names, which enhances software/code readability. This\ntechnique is applied to Intrusion Detection Message Exchange Format (IDMEF)\nmessages, as part of Security Information and Event Management (SIEM) system\ncommunication hosted on Microsoft Azure Cloud. Test results show message size\nreduction ranging from 8.15% to 50.34% in the raw message, without using\ntime-consuming compression techniques. Adding GZip compression to the proposed\ntechnique produces 66.1% shorter message size compared to original XML\nmessages.\n", "Comment: XML, JSON, Minification, XML Schema, Cloud, Log, Communication,\n  Compression, XMill, GZip, Code Generation, Code Readability, 9 pages, 12\n  figures, 5 tables, Journal Article"]}}], "languages": [null], "subjects": ["computer science - distributed", "computer science - networking and internet architecture", "parallel", "and cluster computing", "computer science - cryptography and security"], "providerUpdatedDateTime": "2014-10-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.2553"}}, {"publisher": {"name": ""}, "description": "  We consider the problems of finding optimal identifying codes, (open)\nlocating-dominating sets and resolving sets (denoted IDENTIFYING CODE, (OPEN)\nLOCATING-DOMINATING SET and METRIC DIMENSION) of an interval or a permutation\ngraph. In these problems, one asks to distinguish all vertices of a graph by a\nsubset of the vertices, using either the neighbourhood within the solution set\nor the distances to the solution vertices. Using a general reduction for this\nclass of problems, we prove that the decision problems associated to these four\nnotions are NP-complete, even for graphs that are at the same time interval\ngraphs and permutation graphs and have diameter 2. While IDENTIFYING CODE and\n(OPEN) LOCATING-DOMINATING SET are trivially fixed-parameter-tractable when\nparameterized by solution size, it is known that in the same setting METRIC\nDIMENSION is W[2]-hard. We show that for interval graphs, this parameterization\nof METRIC DIMENSION is fixed-parameter-tractable.\n", "contributors": [{"name": "Foucaud, Florent", "sameAs": [], "familyName": "Foucaud", "additionalName": "", "givenName": "Florent", "email": ""}, {"name": "Mertzios, George B.", "sameAs": [], "familyName": "Mertzios", "additionalName": "B.", "givenName": "George", "email": ""}, {"name": "Naserasr, Reza", "sameAs": [], "familyName": "Naserasr", "additionalName": "", "givenName": "Reza", "email": ""}, {"name": "Parreau, Aline", "sameAs": [], "familyName": "Parreau", "additionalName": "", "givenName": "Aline", "email": ""}, {"name": "Valicov, Petru", "sameAs": [], "familyName": "Valicov", "additionalName": "", "givenName": "Petru", "email": ""}], "title": "Identification, location-domination and metric dimension on interval and\n  permutation graphs. II. Algorithms and complexity", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-05-10", "2015-02-27"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1405.2424", "oai:arXiv.org:1405.2424"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We consider the problems of finding optimal identifying codes, (open)\nlocating-dominating sets and resolving sets (denoted IDENTIFYING CODE, (OPEN)\nLOCATING-DOMINATING SET and METRIC DIMENSION) of an interval or a permutation\ngraph. In these problems, one asks to distinguish all vertices of a graph by a\nsubset of the vertices, using either the neighbourhood within the solution set\nor the distances to the solution vertices. Using a general reduction for this\nclass of problems, we prove that the decision problems associated to these four\nnotions are NP-complete, even for graphs that are at the same time interval\ngraphs and permutation graphs and have diameter 2. While IDENTIFYING CODE and\n(OPEN) LOCATING-DOMINATING SET are trivially fixed-parameter-tractable when\nparameterized by solution size, it is known that in the same setting METRIC\nDIMENSION is W[2]-hard. We show that for interval graphs, this parameterization\nof METRIC DIMENSION is fixed-parameter-tractable.\n", "Comment: 22 pages, 8 figures. The new version contains a new algorithm. The\n  combinatorial bounds of the original version have been removed and will be\n  included in another paper"]}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "mathematics - combinatorics"], "providerUpdatedDateTime": "2015-03-02T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1405.2424"}}, {"publisher": {"name": ""}, "description": "  The novel STEVE (i.e., Space-Time-Enclosing Volume Extraction) algorithm is\ndescribed here for the very first time. It generates iso-valued hypersurfaces\nthat may be implicitly contained in four-dimensional (4D) data sets, such as\ntemporal sequences of three-dimensional images from time-varying computed\ntomography. Any final hypersurface that will be generated by STEVE is\nguaranteed to be free from accidental rifts, i.e., it always fully encloses a\nregion in the 4D space under consideration. Furthermore, the information of the\ninterior/exterior of the enclosed regions is propagated to each one of the\ntetrahedrons, which are embedded into 4D and which in their union represent the\nfinal, iso-valued hypersurface(s). We argue that STEVE - while using a minimum\nof data redundancy in representing the final results - is faster than other\ntechniques that generate simplex-based manifolds of codimension 1.\n", "contributors": [{"name": "Schlei, B. R.", "sameAs": [], "familyName": "Schlei", "additionalName": "R.", "givenName": "B.", "email": ""}], "title": "STEVE - Space-Time-Enclosing Volume Extraction", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-02-22", "2015-02-23"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1302.5683", "oai:arXiv.org:1302.5683"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The novel STEVE (i.e., Space-Time-Enclosing Volume Extraction) algorithm is\ndescribed here for the very first time. It generates iso-valued hypersurfaces\nthat may be implicitly contained in four-dimensional (4D) data sets, such as\ntemporal sequences of three-dimensional images from time-varying computed\ntomography. Any final hypersurface that will be generated by STEVE is\nguaranteed to be free from accidental rifts, i.e., it always fully encloses a\nregion in the 4D space under consideration. Furthermore, the information of the\ninterior/exterior of the enclosed regions is propagated to each one of the\ntetrahedrons, which are embedded into 4D and which in their union represent the\nfinal, iso-valued hypersurface(s). We argue that STEVE - while using a minimum\nof data redundancy in representing the final results - is faster than other\ntechniques that generate simplex-based manifolds of codimension 1.\n", "Comment: 16 pages, 26 figures, 1 table"]}}], "languages": [null], "subjects": ["computer science - graphics", "computer science - computational geometry"], "providerUpdatedDateTime": "2015-02-24T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1302.5683"}}, {"publisher": {"name": ""}, "description": "  Random tilings are interesting as idealizations of atomistic models of\nquasicrystals and for their connection to problems in combinatorics and\nalgorithms. Of particular interest is the tiling entropy density, which\nmeasures the relation of the number of distinct tilings to the number of\nconstituent tiles. Tilings by squares and 45 degree rhombi receive special\nattention as presumably the simplest model that has not yet been solved exactly\nin the thermodynamic limit. However, an exact enumeration formula can be\nevaluated for tilings in finite regions with fixed boundaries. We implement\nthis algorithm in an efficient manner, enabling the investigation of larger\nregions of parameter space than previously were possible. Our new results\nappear to yield monotone increasing and decreasing lower and upper bounds on\nthe fixed boundary entropy density that converge toward S = 0.36021(3).\n", "contributors": [{"name": "Hutchinson, Maxwell", "sameAs": [], "familyName": "Hutchinson", "additionalName": "", "givenName": "Maxwell", "email": ""}, {"name": "Widom, Michael", "sameAs": [], "familyName": "Widom", "additionalName": "", "givenName": "Michael", "email": ""}], "title": "Enumeration of octagonal tilings", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-06-24", "2015-03-16"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1306.5977", "doi:10.1016/j.tcs.2015.03.019", "oai:arXiv.org:1306.5977"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:math-ph"]}}, {"name": "description", "properties": {"description": "  Random tilings are interesting as idealizations of atomistic models of\nquasicrystals and for their connection to problems in combinatorics and\nalgorithms. Of particular interest is the tiling entropy density, which\nmeasures the relation of the number of distinct tilings to the number of\nconstituent tiles. Tilings by squares and 45 degree rhombi receive special\nattention as presumably the simplest model that has not yet been solved exactly\nin the thermodynamic limit. However, an exact enumeration formula can be\nevaluated for tilings in finite regions with fixed boundaries. We implement\nthis algorithm in an efficient manner, enabling the investigation of larger\nregions of parameter space than previously were possible. Our new results\nappear to yield monotone increasing and decreasing lower and upper bounds on\nthe fixed boundary entropy density that converge toward S = 0.36021(3).\n"}}], "languages": [null], "subjects": ["mathematical physics", "computer science - discrete mathematics", "mathematics - combinatorics"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1306.5977"}}, {"publisher": {"name": ""}, "description": "  In this paper, we propose opportunistic interference alignment (OIA) schemes\nfor three-transmitter multiple-input multiple-output (MIMO) interference\nchannels (ICs). In the proposed OIA, each transmitter has its own user group\nand selects a single user who has the most aligned interference signals. The\nuser dimensions provided by multiple users are exploited to align interfering\nsignals. Contrary to conventional IA, perfect channel state information of all\nchannel links is not required at the transmitter, and each user just feeds back\none scalar value to indicate how well the interfering channels are aligned. We\nprove that each transmitter can achieve the same degrees of freedom (DoF) as\nthe interference free case via user selection in our system model that the\nnumber of receive antennas is twice of the number of transmit antennas. Using\nthe geometric interpretation, we find the required user scaling to obtain an\narbitrary non-zero DoF. Two OIA schemes are proposed and compared with various\nuser selection schemes in terms of achievable rate/DoF and complexity.\n", "contributors": [{"name": "Lee, Jung Hoon", "sameAs": [], "familyName": "Lee", "additionalName": "Hoon", "givenName": "Jung", "email": ""}, {"name": "Choi, Wan", "sameAs": [], "familyName": "Choi", "additionalName": "", "givenName": "Wan", "email": ""}], "title": "On the Achievable DoF and User Scaling Law of Opportunistic Interference\n  Alignment in 3-Transmitter MIMO Interference Channels", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-09-29", "2013-03-08"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1109.6541", "doi:10.1109/TWC.2013.041713.120773", "oai:arXiv.org:1109.6541"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we propose opportunistic interference alignment (OIA) schemes\nfor three-transmitter multiple-input multiple-output (MIMO) interference\nchannels (ICs). In the proposed OIA, each transmitter has its own user group\nand selects a single user who has the most aligned interference signals. The\nuser dimensions provided by multiple users are exploited to align interfering\nsignals. Contrary to conventional IA, perfect channel state information of all\nchannel links is not required at the transmitter, and each user just feeds back\none scalar value to indicate how well the interfering channels are aligned. We\nprove that each transmitter can achieve the same degrees of freedom (DoF) as\nthe interference free case via user selection in our system model that the\nnumber of receive antennas is twice of the number of transmit antennas. Using\nthe geometric interpretation, we find the required user scaling to obtain an\narbitrary non-zero DoF. Two OIA schemes are proposed and compared with various\nuser selection schemes in terms of achievable rate/DoF and complexity.\n", "Comment: To appear in IEEE Transactions on Wireless Communications"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1109.6541"}}, {"publisher": {"name": ""}, "description": "  A self-organization of efficient and robust networks is important for a\nfuture design of communication or transportation systems, however both\ncharacteristics are incompatible in many real networks. Recently, it has been\nfound that the robustness of onion-like structure with positive degree-degree\ncorrelations is optimal against intentional attacks. We show that, by\nbiologically inspired copying, an onion-like network emerges in the incremental\ngrowth with functions of proxy access and reinforced connectivity on a space.\nThe proposed network consists of the backbone of tree-like structure by\ncopyings and the periphery by adding shortcut links between low degree nodes to\nenhance the connectivity. It has the fine properties of the statistically\nself-averaging unlike the conventional duplication-divergence model,\nexponential-like degree distribution without overloaded hubs, strong robustness\nagainst both malicious attacks and random failures, and the efficiency with\nshort paths counted by the number of hops as mediators and by the Euclidean\ndistances. The adaptivity to heal over and to recover the performance of\nnetworking is also discussed for a change of environment in such disasters or\nbattlefields on a geographical map. These properties will be useful for a\nresilient and scalable infrastructure of network systems even in emergent\nsituations or poor environments.\n", "contributors": [{"name": "Hayashi, Yukio", "sameAs": [], "familyName": "Hayashi", "additionalName": "", "givenName": "Yukio", "email": ""}], "title": "Growing Self-organized Design of Efficient and Robust Complex Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.7719", "doi:10.1109/SASO.2014.17", "oai:arXiv.org:1411.7719"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:nlin", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  A self-organization of efficient and robust networks is important for a\nfuture design of communication or transportation systems, however both\ncharacteristics are incompatible in many real networks. Recently, it has been\nfound that the robustness of onion-like structure with positive degree-degree\ncorrelations is optimal against intentional attacks. We show that, by\nbiologically inspired copying, an onion-like network emerges in the incremental\ngrowth with functions of proxy access and reinforced connectivity on a space.\nThe proposed network consists of the backbone of tree-like structure by\ncopyings and the periphery by adding shortcut links between low degree nodes to\nenhance the connectivity. It has the fine properties of the statistically\nself-averaging unlike the conventional duplication-divergence model,\nexponential-like degree distribution without overloaded hubs, strong robustness\nagainst both malicious attacks and random failures, and the efficiency with\nshort paths counted by the number of hops as mediators and by the Euclidean\ndistances. The adaptivity to heal over and to recover the performance of\nnetworking is also discussed for a change of environment in such disasters or\nbattlefields on a geographical map. These properties will be useful for a\nresilient and scalable infrastructure of network systems even in emergent\nsituations or poor environments.\n", "Comment: 10 pages, 14 figures, 3 tables, Proc. of 2014 IEEE 8th Int. Conf. on\n  Self-Adaptive and Self-Organizing Systems, pp.50-59"]}}], "languages": [null], "subjects": ["physics - physics and society", "nonlinear sciences - adaptation and self-organizing systems", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-12-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.7719"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "Uncertainty in travel time is one of the key factors that could allow us to understand and manage congestion in transportation networks. Models that incorporate uncertainty in travel time need to specify two mechanisms: the mechanism through which travel time uncertainty is generated and the mechanism through which travel time uncertainty influences users' behavior. Existing traffic equilibrium models are not sufficient in capturing these two mechanisms in an integrated way. This thesis proposes a new stochastic traffic equilibrium model that incorporates travel time uncertainty in an integrated manner. We focus on how uncertainty in travel time induces uncertainty in the traffic flow and vice versa. Travelers independently make probabilistic path choice decisions, inducing stochastic traffic flows in the network, which in turn result in uncertain travel times. Our model, based on the distribution of the travel time, uses the mean-variance approach in order to evaluate travelers' travel times and subsequently induce a stochastic traffic equilibrium flow pattern. In this thesis, we also examine when the new model we present has a solution as well as when the solution is unique. We discuss algorithms for solving this new model, and compare the model with existing traffic equilibrium models in the literature. We find that existing models tend to overestimate traffic flows on links with high travel time variance-to-mean ratios. To benchmark the various traffic network equilibrium models in the literature relative to the model we introduce, we investigate the total system cost, namely the total travel time in the network, for all these models. We prove three bounds that allow us to compare the system cost for the new model relative to existing models. We discuss the tightness of these bounds but also test them through numerical experimentation on test networks.", "contributors": [{"name": "Chen, Daizhuo", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Daizhuo", "email": ""}, {"name": "Massachusetts Institute of Technology. Computation for Design and Optimization Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computation for Design and Optimization", "givenName": "Massachusetts", "email": ""}, {"name": "Georgia Perakis.", "sameAs": [], "familyName": "Perakis.", "additionalName": "", "givenName": "Georgia", "email": ""}], "title": "Modeling travel time uncertainty in traffic networks", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "154 p."}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by \ncopyright. They may be viewed from this source for any purpose, but \nreproduction or distribution in any format is prohibited without written \npermission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/61889", "706802887", "oai:dspace.mit.edu:1721.1/61889"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2011-03-24T20:22:12Z", "2011-03-24T20:22:12Z", "2010", "2010"]}}, {"name": "description", "properties": {"description": ["Uncertainty in travel time is one of the key factors that could allow us to understand and manage congestion in transportation networks. Models that incorporate uncertainty in travel time need to specify two mechanisms: the mechanism through which travel time uncertainty is generated and the mechanism through which travel time uncertainty influences users' behavior. Existing traffic equilibrium models are not sufficient in capturing these two mechanisms in an integrated way. This thesis proposes a new stochastic traffic equilibrium model that incorporates travel time uncertainty in an integrated manner. We focus on how uncertainty in travel time induces uncertainty in the traffic flow and vice versa. Travelers independently make probabilistic path choice decisions, inducing stochastic traffic flows in the network, which in turn result in uncertain travel times. Our model, based on the distribution of the travel time, uses the mean-variance approach in order to evaluate travelers' travel times and subsequently induce a stochastic traffic equilibrium flow pattern. In this thesis, we also examine when the new model we present has a solution as well as when the solution is unique. We discuss algorithms for solving this new model, and compare the model with existing traffic equilibrium models in the literature. We find that existing models tend to overestimate traffic flows on links with high travel time variance-to-mean ratios. To benchmark the various traffic network equilibrium models in the literature relative to the model we introduce, we investigate the total system cost, namely the total travel time in the network, for all these models. We prove three bounds that allow us to compare the system cost for the new model relative to existing models. We discuss the tightness of these bounds but also test them through numerical experimentation on test networks.", "by Daizhuo Chen.", "Thesis (S.M.)--Massachusetts Institute of Technology, Computation for Design and Optimization Program, 2010.", "Cataloged from PDF version of thesis.", "Includes bibliographical references (p. 147-154)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39115", "hdl_1721.1_39117"]}}], "languages": [null], "subjects": ["computation for design and optimization program."], "providerUpdatedDateTime": "2015-04-27T14:56:18", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/61889"}}, {"publisher": {"name": ""}, "description": "  Multi-threading allows agents to pursue a heterogeneous collection of tasks\nin an orderly manner. The view of multi-threading that emerges from thread\nalgebra is applied to the case where a single agent, who may be human,\nmaintains a hierarchical multithread as an architecture of its own activities.\n", "contributors": [{"name": "Bergstra, Jan A.", "sameAs": [], "familyName": "Bergstra", "additionalName": "A.", "givenName": "Jan", "email": ""}], "title": "Personal Multi-threading", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3579", "oai:arXiv.org:1412.3579"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Multi-threading allows agents to pursue a heterogeneous collection of tasks\nin an orderly manner. The view of multi-threading that emerges from thread\nalgebra is applied to the case where a single agent, who may be human,\nmaintains a hierarchical multithread as an architecture of its own activities.\n"}}], "languages": [null], "subjects": ["computer science - other computer science"], "providerUpdatedDateTime": "2014-12-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3579"}}, {"publisher": {"name": ""}, "description": "  In recent years the effectiveness of interactive theorem provers has\nincreased to an extent that the bottleneck in the interactive process shifted\nto efficiency: while in principle large and complex theorems are provable\n(effectiveness), it takes a lot of effort for the user interacting with the\nsystem (lack of efficiency). We conducted focus groups to evaluate the\nusability of Isabelle/HOL and the KeY system with two goals: (a) detect\nusability issues in the interaction between interactive theorem provers and\ntheir user, and (b) analyze how evaluation and survey methods commonly used in\nthe area of human-computer interaction, such as focus groups and co-operative\nevaluation, are applicable to the specific field of interactive theorem proving\n(ITP).\n  In this paper, we report on our experience using the evaluation method focus\ngroups and how we adapted this method to ITP. We describe our results and\nconclusions mainly on the \"meta-level,\" i.e., we focus on the impact that\nspecific characteristics of ITPs have on the setup and the results of focus\ngroups. On the concrete level, we briefly summarise insights into the usability\nof the ITPs used in our case study.\n", "contributors": [{"name": "Beckert, Bernhard", "sameAs": [], "familyName": "Beckert", "additionalName": "", "givenName": "Bernhard", "email": ""}, {"name": "Grebing, Sarah", "sameAs": [], "familyName": "Grebing", "additionalName": "", "givenName": "Sarah", "email": ""}, {"name": "B\u00f6hl, Florian", "sameAs": [], "familyName": "B\u00f6hl", "additionalName": "", "givenName": "Florian", "email": ""}], "title": "How to Put Usability into Focus: Using Focus Groups to Evaluate the\n  Usability of Interactive Theorem Provers", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-29"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.8215", "EPTCS 167, 2014, pp. 4-13", "doi:10.4204/EPTCS.167.3", "oai:arXiv.org:1410.8215"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  In recent years the effectiveness of interactive theorem provers has\nincreased to an extent that the bottleneck in the interactive process shifted\nto efficiency: while in principle large and complex theorems are provable\n(effectiveness), it takes a lot of effort for the user interacting with the\nsystem (lack of efficiency). We conducted focus groups to evaluate the\nusability of Isabelle/HOL and the KeY system with two goals: (a) detect\nusability issues in the interaction between interactive theorem provers and\ntheir user, and (b) analyze how evaluation and survey methods commonly used in\nthe area of human-computer interaction, such as focus groups and co-operative\nevaluation, are applicable to the specific field of interactive theorem proving\n(ITP).\n  In this paper, we report on our experience using the evaluation method focus\ngroups and how we adapted this method to ITP. We describe our results and\nconclusions mainly on the \"meta-level,\" i.e., we focus on the impact that\nspecific characteristics of ITPs have on the setup and the results of focus\ngroups. On the concrete level, we briefly summarise insights into the usability\nof the ITPs used in our case study.\n", "Comment: In Proceedings UITP 2014, arXiv:1410.7850"]}}], "languages": [null], "subjects": ["computer science - human-computer interaction", "computer science - logic in computer science"], "providerUpdatedDateTime": "2014-10-31T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.8215"}}, {"publisher": {"name": ""}, "description": "  WiMAX (Worldwide Interoperability for Microwave Access) technology has\nemerged in response to the increasing demand for multimedia services in the\ninternet broadband networks. WiMAX standard has defined five different\nscheduling services to meet the QoS (Quality of Service) requirement of\nmultimedia applications and this paper investigates one specific scheduling\nservice, i.e. UGS scheduling. In parallel, it was observed that in the\ndifference of the traditional quality assessment approaches, nowadays, current\nresearches are centered on the user perception of the quality, the existing\nscheduling approaches take into account the QoS, mobility and many other\nparameters, but do not consider the Quality of Experience (QoE). In order to\ncontrol the packet transmission rate so as to match with the minimum subjective\nrate requirements of each user and therefore reduce packet loss and delays, an\nefficient scheduling approach has been proposed in this paper. The solution has\nbeen implemented and evaluated in the WiMAX simulation platform developed based\non NS-2. Simulation results show that by applying various levels of MOS (Mean\nOpinion Score) the QoE provided to the users is enhanced in term of jitter,\npacket loss rate, throughput and delay.\n", "contributors": [{"name": "Anouari, Tarik", "sameAs": [], "familyName": "Anouari", "additionalName": "", "givenName": "Tarik", "email": ""}, {"name": "Haqiq, Abdelkrim", "sameAs": [], "familyName": "Haqiq", "additionalName": "", "givenName": "Abdelkrim", "email": ""}], "title": "An Improved UGS Scheduling with QoE Metrics in WiMAX Network", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-22"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.5944", "(IJCSIS) International Journal of Computer Science and Information\n  Security, Vol. 12, No. 9, September 2014", "oai:arXiv.org:1410.5944"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  WiMAX (Worldwide Interoperability for Microwave Access) technology has\nemerged in response to the increasing demand for multimedia services in the\ninternet broadband networks. WiMAX standard has defined five different\nscheduling services to meet the QoS (Quality of Service) requirement of\nmultimedia applications and this paper investigates one specific scheduling\nservice, i.e. UGS scheduling. In parallel, it was observed that in the\ndifference of the traditional quality assessment approaches, nowadays, current\nresearches are centered on the user perception of the quality, the existing\nscheduling approaches take into account the QoS, mobility and many other\nparameters, but do not consider the Quality of Experience (QoE). In order to\ncontrol the packet transmission rate so as to match with the minimum subjective\nrate requirements of each user and therefore reduce packet loss and delays, an\nefficient scheduling approach has been proposed in this paper. The solution has\nbeen implemented and evaluated in the WiMAX simulation platform developed based\non NS-2. Simulation results show that by applying various levels of MOS (Mean\nOpinion Score) the QoE provided to the users is enhanced in term of jitter,\npacket loss rate, throughput and delay.\n", "Comment: 6 pages, 8 figures"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-10-23T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.5944"}}, {"publisher": {"name": ""}, "description": "  This paper considers the distributed consensus problem of multi-agent systems\nwith general continuous-time linear dynamics. Two distributed adaptive dynamic\nconsensus protocols are proposed, based on the relative output information of\nneighboring agents. One protocol assigns an adaptive coupling weight to each\nedge in the communication graph while the other uses an adaptive coupling\nweight for each node. These two adaptive protocols are designed to ensure that\nconsensus is reached in a fully distributed fashion for any undirected\nconnected communication graphs without using any global information. A\nsufficient condition for the existence of these adaptive protocols is that each\nagent is stabilizable and detectable. The cases with leader-follower and\nswitching communication graphs are also studied.\n", "contributors": [{"name": "Li, Zhongkui", "sameAs": [], "familyName": "Li", "additionalName": "", "givenName": "Zhongkui", "email": ""}, {"name": "Liu, Xiangdong", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Xiangdong", "email": ""}, {"name": "Ren, Wei", "sameAs": [], "familyName": "Ren", "additionalName": "", "givenName": "Wei", "email": ""}, {"name": "Xie, Lihua", "sameAs": [], "familyName": "Xie", "additionalName": "", "givenName": "Lihua", "email": ""}], "title": "Distributed Consensus of Linear Multi-Agent Systems with Adaptive\n  Dynamic Protocols", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-09-17", "2011-09-22"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1109.3838", "Automatica, 49: 1986-1995, 2013", "doi:10.1016/j.automatica.2013.03.015", "oai:arXiv.org:1109.3838"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  This paper considers the distributed consensus problem of multi-agent systems\nwith general continuous-time linear dynamics. Two distributed adaptive dynamic\nconsensus protocols are proposed, based on the relative output information of\nneighboring agents. One protocol assigns an adaptive coupling weight to each\nedge in the communication graph while the other uses an adaptive coupling\nweight for each node. These two adaptive protocols are designed to ensure that\nconsensus is reached in a fully distributed fashion for any undirected\nconnected communication graphs without using any global information. A\nsufficient condition for the existence of these adaptive protocols is that each\nagent is stabilizable and detectable. The cases with leader-follower and\nswitching communication graphs are also studied.\n", "Comment: 17 pages, 5 figues"]}}], "languages": [null], "subjects": ["computer science - systems and control", "mathematics - optimization and control"], "providerUpdatedDateTime": "2015-01-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1109.3838"}}, {"publisher": {"name": ""}, "description": "  This paper advocates the use of the emerging distributed compressed sensing\n(DCS) paradigm to deploy energy harvesting (EH) wireless sensor networks (WSN)\nwith practical network lifetime and data gathering rates that are substantially\nhigher than the state-of-the-art. The basis of our work is a centralized EH WSN\narchitecture where the sensors convey data to a fusion center, using stylized\nmodels that capture the fact that the signals collected by different nodes can\nexhibit correlation and that the energy harvested by different nodes can also\nexhibit some degree of correlation. Via the probability of incorrect data\nreconstruction, we characterize the performance of both a compressive sensing\n(CS) and a DCS based approach to data acquisition and reconstruction. Moreover,\nwe perform an in-depth comparison of the proposed DCS based approach against a\nstate-of-the-art distributed source coding (DSC) system in terms of decoded\ndata distortion versus harvested energy. These performance characterizations\nand comparisons embody the effect of various system phenomena and parameters\nsuch as signal correlation, EH correlation, network size, and energy\navailability level. Our results unveil that, for an EH WSN consisting of eight\nSNs with our simple signal correlation and EH models, a target probability of\nincorrect reconstruction of $10^{-2}$, and under the same EH capability as CS,\nthe proposed approach allows for a six-fold increase in data gathering\ncapability with respect to the baseline CS-based approach. Moreover, under the\nsame energy harvested level, the proposed solution offers a substantial\nreduction of the mean-squared error distortion (up to 66.67\\%) with respect to\nthe state-of-the-art DSC system.\n", "contributors": [{"name": "Chen, Wei", "sameAs": [], "familyName": "Chen", "additionalName": "", "givenName": "Wei", "email": ""}, {"name": "Deligiannis, Nikos", "sameAs": [], "familyName": "Deligiannis", "additionalName": "", "givenName": "Nikos", "email": ""}, {"name": "Andreopoulos, Yiannis", "sameAs": [], "familyName": "Andreopoulos", "additionalName": "", "givenName": "Yiannis", "email": ""}, {"name": "Wassell, Ian J.", "sameAs": [], "familyName": "Wassell", "additionalName": "J.", "givenName": "Ian", "email": ""}, {"name": "Rodrigues, Miguel R. D.", "sameAs": [], "familyName": "Rodrigues", "additionalName": "R. D.", "givenName": "Miguel", "email": ""}], "title": "Unlocking Energy Neutrality in Energy Harvesting Wireless Sensor\n  Networks: An Approach Based on Distributed Compressed Sensing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-12-15", "2015-01-31"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1312.4207", "oai:arXiv.org:1312.4207"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": "  This paper advocates the use of the emerging distributed compressed sensing\n(DCS) paradigm to deploy energy harvesting (EH) wireless sensor networks (WSN)\nwith practical network lifetime and data gathering rates that are substantially\nhigher than the state-of-the-art. The basis of our work is a centralized EH WSN\narchitecture where the sensors convey data to a fusion center, using stylized\nmodels that capture the fact that the signals collected by different nodes can\nexhibit correlation and that the energy harvested by different nodes can also\nexhibit some degree of correlation. Via the probability of incorrect data\nreconstruction, we characterize the performance of both a compressive sensing\n(CS) and a DCS based approach to data acquisition and reconstruction. Moreover,\nwe perform an in-depth comparison of the proposed DCS based approach against a\nstate-of-the-art distributed source coding (DSC) system in terms of decoded\ndata distortion versus harvested energy. These performance characterizations\nand comparisons embody the effect of various system phenomena and parameters\nsuch as signal correlation, EH correlation, network size, and energy\navailability level. Our results unveil that, for an EH WSN consisting of eight\nSNs with our simple signal correlation and EH models, a target probability of\nincorrect reconstruction of $10^{-2}$, and under the same EH capability as CS,\nthe proposed approach allows for a six-fold increase in data gathering\ncapability with respect to the baseline CS-based approach. Moreover, under the\nsame energy harvested level, the proposed solution offers a substantial\nreduction of the mean-squared error distortion (up to 66.67\\%) with respect to\nthe state-of-the-art DSC system.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture", "computer science - information theory"], "providerUpdatedDateTime": "2015-02-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1312.4207"}}, {"publisher": {"name": ""}, "description": "  We present a linear-time algorithm for deciding first-order (FO) properties\nin classes of graphs with bounded expansion, a notion recently introduced by\nNesetril and Ossona de Mendez. This generalizes several results from the\nliterature, because many natural classes of graphs have bounded expansion:\ngraphs of bounded tree-width, all proper minor-closed classes of graphs, graphs\nof bounded degree, graphs with no subgraph isomorphic to a subdivision of a\nfixed graph, and graphs that can be drawn in a fixed surface in such a way that\neach edge crosses at most a constant number of other edges. We deduce that\nthere is an almost linear-time algorithm for deciding FO properties in classes\nof graphs with locally bounded expansion.\n  More generally, we design a dynamic data structure for graphs belonging to a\nfixed class of graphs of bounded expansion. After a linear-time initialization\nthe data structure allows us to test an FO property in constant time, and the\ndata structure can be updated in constant time after addition/deletion of an\nedge, provided the list of possible edges to be added is known in advance and\ntheir simultaneous addition results in a graph in the class. All our results\nalso hold for relational structures and are based on the seminal result of\nNesetril and Ossona de Mendez on the existence of low tree-depth colorings.\n", "contributors": [{"name": "Dvorak, Zdenek", "sameAs": [], "familyName": "Dvorak", "additionalName": "", "givenName": "Zdenek", "email": ""}, {"name": "Kral, Daniel", "sameAs": [], "familyName": "Kral", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Thomas, Robin", "sameAs": [], "familyName": "Thomas", "additionalName": "", "givenName": "Robin", "email": ""}], "title": "Testing first-order properties for subclasses of sparse graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-09-23", "2013-01-03"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1109.5036", "oai:arXiv.org:1109.5036"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We present a linear-time algorithm for deciding first-order (FO) properties\nin classes of graphs with bounded expansion, a notion recently introduced by\nNesetril and Ossona de Mendez. This generalizes several results from the\nliterature, because many natural classes of graphs have bounded expansion:\ngraphs of bounded tree-width, all proper minor-closed classes of graphs, graphs\nof bounded degree, graphs with no subgraph isomorphic to a subdivision of a\nfixed graph, and graphs that can be drawn in a fixed surface in such a way that\neach edge crosses at most a constant number of other edges. We deduce that\nthere is an almost linear-time algorithm for deciding FO properties in classes\nof graphs with locally bounded expansion.\n  More generally, we design a dynamic data structure for graphs belonging to a\nfixed class of graphs of bounded expansion. After a linear-time initialization\nthe data structure allows us to test an FO property in constant time, and the\ndata structure can be updated in constant time after addition/deletion of an\nedge, provided the list of possible edges to be added is known in advance and\ntheir simultaneous addition results in a graph in the class. All our results\nalso hold for relational structures and are based on the seminal result of\nNesetril and Ossona de Mendez on the existence of low tree-depth colorings.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms", "computer science - logic in computer science", "computer science - discrete mathematics"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1109.5036"}}, {"publisher": {"name": ""}, "description": "  Paper-by-paper results make it easy to miss the forest for the trees.We\nanalyse the remarkable progress of the last decade by discussing the main ideas\nexplored in the 40+ detectors currently present in the Caltech pedestrian\ndetection benchmark. We observe that there exist three families of approaches,\nall currently reaching similar detection quality. Based on our analysis, we\nstudy the complementarity of the most promising ideas by combining multiple\npublished strategies. This new decision forest detector achieves the current\nbest known performance on the challenging Caltech-USA dataset.\n", "contributors": [{"name": "Benenson, Rodrigo", "sameAs": [], "familyName": "Benenson", "additionalName": "", "givenName": "Rodrigo", "email": ""}, {"name": "Omran, Mohamed", "sameAs": [], "familyName": "Omran", "additionalName": "", "givenName": "Mohamed", "email": ""}, {"name": "Hosang, Jan", "sameAs": [], "familyName": "Hosang", "additionalName": "", "givenName": "Jan", "email": ""}, {"name": "Schiele, Bernt", "sameAs": [], "familyName": "Schiele", "additionalName": "", "givenName": "Bernt", "email": ""}], "title": "Ten Years of Pedestrian Detection, What Have We Learned?", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4304", "oai:arXiv.org:1411.4304"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Paper-by-paper results make it easy to miss the forest for the trees.We\nanalyse the remarkable progress of the last decade by discussing the main ideas\nexplored in the 40+ detectors currently present in the Caltech pedestrian\ndetection benchmark. We observe that there exist three families of approaches,\nall currently reaching similar detection quality. Based on our analysis, we\nstudy the complementarity of the most promising ideas by combining multiple\npublished strategies. This new decision forest detector achieves the current\nbest known performance on the challenging Caltech-USA dataset.\n", "Comment: To appear in ECCV 2014 CVRSUAD workshop proceedings"]}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4304"}}, {"publisher": {"name": ""}, "description": "  In this paper, we consider vector space interference alignment strategies\nover the $K$-user interference channel and derive an upper bound on the\nachievable degrees of freedom as a function of the channel diversity $L$. The\nchannel diversity $L$ is modeled by $L$ independently fading real-valued\nparallel channels. Existing results in the literature for $K=3$ show that the\noptimal $1/2$ degrees of freedom per user can be approached at the speed of\n$1/L$ (i.e., the gap to $1/2$ degrees of freedom per user decreases inversely\nproportional to $L$). In this paper, we show that when $K\\geq4$, the speed of\nconvergence is significantly slower. In particular, the gap to $1/2$ degrees of\nfreedom per user can decrease at most like $1/\\sqrt{L}$. Furthermore, when $K$\nis of the order of $\\sqrt{\\log L}$, we show that the speed of convergence is\nsmaller than $1/\\sqrt[4]{L}$ .\n", "contributors": [{"name": "Li, Cheuk Ting", "sameAs": [], "familyName": "Li", "additionalName": "Ting", "givenName": "Cheuk", "email": ""}, {"name": "\u00d6zg\u00fcr, Ayfer", "sameAs": [], "familyName": "\u00d6zg\u00fcr", "additionalName": "", "givenName": "Ayfer", "email": ""}], "title": "Channel Diversity needed for Vector Interference Alignment", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-21", "2014-11-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.5326", "oai:arXiv.org:1402.5326"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In this paper, we consider vector space interference alignment strategies\nover the $K$-user interference channel and derive an upper bound on the\nachievable degrees of freedom as a function of the channel diversity $L$. The\nchannel diversity $L$ is modeled by $L$ independently fading real-valued\nparallel channels. Existing results in the literature for $K=3$ show that the\noptimal $1/2$ degrees of freedom per user can be approached at the speed of\n$1/L$ (i.e., the gap to $1/2$ degrees of freedom per user decreases inversely\nproportional to $L$). In this paper, we show that when $K\\geq4$, the speed of\nconvergence is significantly slower. In particular, the gap to $1/2$ degrees of\nfreedom per user can decrease at most like $1/\\sqrt{L}$. Furthermore, when $K$\nis of the order of $\\sqrt{\\log L}$, we show that the speed of convergence is\nsmaller than $1/\\sqrt[4]{L}$ .\n", "Comment: 19 pages, 4 figures, short version presented at the International\n  Symposium on Information Theory 2014"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2014-12-01T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.5326"}}, {"publisher": {"name": ""}, "description": "  From the moment astronomical observations are made the resulting data\nproducts begin to grow stale. Even if perfect binary copies are preserved\nthrough repeated timely migration to more robust storage media, data standards\nevolve and new tools are created that require different kinds of data or\nmetadata. The expectations of the astronomical community change even if the\ndata do not. We discuss data engineering to mitigate the ensuing risks with\nexamples from a recent project to refactor seven million archival images to new\nstandards of nomenclature, metadata, format, and compression.\n", "contributors": [{"name": "Seaman, Rob", "sameAs": [], "familyName": "Seaman", "additionalName": "", "givenName": "Rob", "email": ""}], "title": "Data engineering for archive evolution", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-10-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1410.3481", "oai:arXiv.org:1410.3481"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:astro-ph"]}}, {"name": "description", "properties": {"description": ["  From the moment astronomical observations are made the resulting data\nproducts begin to grow stale. Even if perfect binary copies are preserved\nthrough repeated timely migration to more robust storage media, data standards\nevolve and new tools are created that require different kinds of data or\nmetadata. The expectations of the astronomical community change even if the\ndata do not. We discuss data engineering to mitigate the ensuing risks with\nexamples from a recent project to refactor seven million archival images to new\nstandards of nomenclature, metadata, format, and compression.\n", "Comment: 11 pages, this is a longer version of a poster paper submitted to the\n  proceedings of ADASS XXIV"]}}], "languages": [null], "subjects": ["computer science - digital libraries", "astrophysics - instrumentation and methods for astrophysics"], "providerUpdatedDateTime": "2014-10-15T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1410.3481"}}, {"publisher": {"name": ""}, "description": "  Titanium dioxide (TiO2) memristors exhibit complex conduction mechanism.\nSeveral models of different complexity have been developed in order to mimic\nthe experimental results for physical behaviors observed in memristor devices.\nPickett's tunneling barrier model describes the TiO2 memristors, and utilizes\ncomplex derivative of tunnel barrier width. It attains a large error in the ON\nswitching region. Variety of research consider it as the reference model for\nthe TiO2 memristors. In this paper, we first analyze the theory of operation of\nthe memristor and discuss Pickett's model. Then, we propose a modification to\nits derivative functions to provide a lower error and closer agreement with\nphysical behavior. This modification is represented by two additional fitting\nparameters to damp or accelerate the tunnel width derivative. Also, we\nincorporate a hard limiter term to limit the tunnel width to its physical\nextremes 1 nm and 2 nm. We run simulations to test the model modifications and\nwe compare the results to the experimental and original Pickett's model\nresults. The modified model more closely resembles the experimental behavior of\nTiO2 memristors and potentially enables the memristor to be used as a\nmultilevel memory.\n", "contributors": [{"name": "Daoud, Ahmad", "sameAs": [], "familyName": "Daoud", "additionalName": "", "givenName": "Ahmad", "email": ""}, {"name": "Dessouki, Ahmed", "sameAs": [], "familyName": "Dessouki", "additionalName": "", "givenName": "Ahmed", "email": ""}, {"name": "Abuelenin, Sherif", "sameAs": [], "familyName": "Abuelenin", "additionalName": "", "givenName": "Sherif", "email": ""}], "title": "Accuracy Enhancement of Pickett Tunnelling Barrier Memristor Model", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-25"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.07267", "oai:arXiv.org:1502.07267"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Titanium dioxide (TiO2) memristors exhibit complex conduction mechanism.\nSeveral models of different complexity have been developed in order to mimic\nthe experimental results for physical behaviors observed in memristor devices.\nPickett's tunneling barrier model describes the TiO2 memristors, and utilizes\ncomplex derivative of tunnel barrier width. It attains a large error in the ON\nswitching region. Variety of research consider it as the reference model for\nthe TiO2 memristors. In this paper, we first analyze the theory of operation of\nthe memristor and discuss Pickett's model. Then, we propose a modification to\nits derivative functions to provide a lower error and closer agreement with\nphysical behavior. This modification is represented by two additional fitting\nparameters to damp or accelerate the tunnel width derivative. Also, we\nincorporate a hard limiter term to limit the tunnel width to its physical\nextremes 1 nm and 2 nm. We run simulations to test the model modifications and\nwe compare the results to the experimental and original Pickett's model\nresults. The modified model more closely resembles the experimental behavior of\nTiO2 memristors and potentially enables the memristor to be used as a\nmultilevel memory.\n", "Comment: 5 pages, 5 figures, presented at the ICITACEE 2014 conference;\n  http://icitacee.undip.ac.id/index.php/icitacee/2014/paper/view/89"]}}], "languages": [null], "subjects": ["computer science - emerging technologies"], "providerUpdatedDateTime": "2015-02-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.07267"}}, {"publisher": {"name": ""}, "description": "  In this contribution, a Bayes Ying Yang(BYY) harmony based approach for\non-line signature verification is presented. In the proposed method, a simple\nbut effective Gaussian Mixture Models(GMMs) is used to represent for each\nuser's signature model based on the prior information collected. Different from\nthe early works, in this paper, we use the Bayes Ying Yang machine combined\nwith the harmony function to achieve Automatic Model Selection(AMS) during the\nparameter learning for the GMMs, so that a better approximation of the user\nmodel is assured. Experiments on a database from the First International\nSignature Verification Competition(SVC 2004) confirm that this combined\nalgorithm yields quite satisfactory results.\n", "contributors": [{"name": "Zhao, Xiaosha", "sameAs": [], "familyName": "Zhao", "additionalName": "", "givenName": "Xiaosha", "email": ""}, {"name": "Liu, Mandan", "sameAs": [], "familyName": "Liu", "additionalName": "", "givenName": "Mandan", "email": ""}], "title": "The application of the Bayes Ying Yang harmony based GMMs in on-line\n  signature verification", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.4205", "oai:arXiv.org:1412.4205"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  In this contribution, a Bayes Ying Yang(BYY) harmony based approach for\non-line signature verification is presented. In the proposed method, a simple\nbut effective Gaussian Mixture Models(GMMs) is used to represent for each\nuser's signature model based on the prior information collected. Different from\nthe early works, in this paper, we use the Bayes Ying Yang machine combined\nwith the harmony function to achieve Automatic Model Selection(AMS) during the\nparameter learning for the GMMs, so that a better approximation of the user\nmodel is assured. Experiments on a database from the First International\nSignature Verification Competition(SVC 2004) confirm that this combined\nalgorithm yields quite satisfactory results.\n"}}], "languages": [null], "subjects": ["computer science - computer vision and pattern recognition"], "providerUpdatedDateTime": "2014-12-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.4205"}}, {"publisher": {"name": ""}, "description": "  We establish the conditions under which several algorithmically exploitable\nstructural features hold for random intersection graphs, a natural model for\nmany real-world networks where edges correspond to shared attributes.\nSpecifically, we fully characterize the degeneracy of random intersection\ngraphs, and prove that the model asymptotically almost surely produces graphs\nwith hyperbolicity at least $\\log{n}$. Further, we prove that when degenerate,\nthe graphs generated by this model belong to a bounded-expansion graph class\nwith high probability.\n", "contributors": [{"name": "Farrell, Matthew", "sameAs": [], "familyName": "Farrell", "additionalName": "", "givenName": "Matthew", "email": ""}, {"name": "Goodrich, Timothy", "sameAs": [], "familyName": "Goodrich", "additionalName": "", "givenName": "Timothy", "email": ""}, {"name": "Lemons, Nathan", "sameAs": [], "familyName": "Lemons", "additionalName": "", "givenName": "Nathan", "email": ""}, {"name": "Reidl, Felix", "sameAs": [], "familyName": "Reidl", "additionalName": "", "givenName": "Felix", "email": ""}, {"name": "Villaamil, Fernando S\u00e1nchez", "sameAs": [], "familyName": "Villaamil", "additionalName": "S\u00e1nchez", "givenName": "Fernando", "email": ""}, {"name": "Sullivan, Blair D.", "sameAs": [], "familyName": "Sullivan", "additionalName": "D.", "givenName": "Blair", "email": ""}], "title": "Hyperbolicity, degeneracy, and expansion of random intersection graphs", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-09-29", "2015-03-09"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1409.8196", "oai:arXiv.org:1409.8196"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We establish the conditions under which several algorithmically exploitable\nstructural features hold for random intersection graphs, a natural model for\nmany real-world networks where edges correspond to shared attributes.\nSpecifically, we fully characterize the degeneracy of random intersection\ngraphs, and prove that the model asymptotically almost surely produces graphs\nwith hyperbolicity at least $\\log{n}$. Further, we prove that when degenerate,\nthe graphs generated by this model belong to a bounded-expansion graph class\nwith high probability.\n"}}], "languages": [null], "subjects": ["computer science - discrete mathematics", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-10T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1409.8196"}}, {"publisher": {"name": ""}, "description": "  Next generation cellular networks will be heterogeneous with dense deployment\nof small cells in order to deliver high data rate per unit area. Traffic\nvariations are more pronounced in a small cell, which in turn lead to more\ndynamic interference to other cells. It is crucial to adapt radio resource\nmanagement to traffic conditions in such a heterogeneous network (HetNet). This\npaper studies the optimization of spectrum allocation in HetNets on a\nrelatively slow timescale based on average traffic and channel conditions\n(typically over seconds or minutes). Specifically, in a cluster with $n$ base\ntransceiver stations (BTSs), the optimal partition of the spectrum into $2^n$\nsegments is determined, corresponding to all possible spectrum reuse patterns\nin the downlink. Each BTS's traffic is modeled using a queue with Poisson\narrivals, the service rate of which is a linear function of the combined\nbandwidth of all assigned spectrum segments. With the system average packet\nsojourn time as the objective, a convex optimization problem is first\nformulated, where it is shown that the optimal allocation divides the spectrum\ninto at most $n$ segments. A second, refined model is then proposed to address\nqueue interactions due to interference, where the corresponding optimal\nallocation problem admits an efficient suboptimal solution. Both allocation\nschemes attain the entire throughput region of a given network. Simulation\nresults show the two schemes perform similarly in the heavy-traffic regime, in\nwhich case they significantly outperform both the orthogonal allocation and the\nfull-frequency-reuse allocation. The refined allocation shows the best\nperformance under all traffic conditions.\n", "contributors": [{"name": "Zhuang, Binnan", "sameAs": [], "familyName": "Zhuang", "additionalName": "", "givenName": "Binnan", "email": ""}, {"name": "Guo, Dongning", "sameAs": [], "familyName": "Guo", "additionalName": "", "givenName": "Dongning", "email": ""}, {"name": "Honig, Michael L.", "sameAs": [], "familyName": "Honig", "additionalName": "L.", "givenName": "Michael", "email": ""}], "title": "Traffic-Driven Spectrum Allocation in Heterogeneous Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-08-26", "2015-03-26"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1408.6011", "oai:arXiv.org:1408.6011"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  Next generation cellular networks will be heterogeneous with dense deployment\nof small cells in order to deliver high data rate per unit area. Traffic\nvariations are more pronounced in a small cell, which in turn lead to more\ndynamic interference to other cells. It is crucial to adapt radio resource\nmanagement to traffic conditions in such a heterogeneous network (HetNet). This\npaper studies the optimization of spectrum allocation in HetNets on a\nrelatively slow timescale based on average traffic and channel conditions\n(typically over seconds or minutes). Specifically, in a cluster with $n$ base\ntransceiver stations (BTSs), the optimal partition of the spectrum into $2^n$\nsegments is determined, corresponding to all possible spectrum reuse patterns\nin the downlink. Each BTS's traffic is modeled using a queue with Poisson\narrivals, the service rate of which is a linear function of the combined\nbandwidth of all assigned spectrum segments. With the system average packet\nsojourn time as the objective, a convex optimization problem is first\nformulated, where it is shown that the optimal allocation divides the spectrum\ninto at most $n$ segments. A second, refined model is then proposed to address\nqueue interactions due to interference, where the corresponding optimal\nallocation problem admits an efficient suboptimal solution. Both allocation\nschemes attain the entire throughput region of a given network. Simulation\nresults show the two schemes perform similarly in the heavy-traffic regime, in\nwhich case they significantly outperform both the orthogonal allocation and the\nfull-frequency-reuse allocation. The refined allocation shows the best\nperformance under all traffic conditions.\n", "Comment: 13 pages, 11 figures, accepted for publication by JSAC-HCN"]}}], "languages": [null], "subjects": ["computer science - information theory"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1408.6011"}}, {"publisher": {"name": ""}, "description": "  This paper presents a novel approach to including non-instantaneous discrete\ncontrol transitions in the linear hybrid automaton approach to simulation and\nverification of hybrid control systems. In this paper we study the control of a\ncontinuously evolving analog plant using a controller programmed in a\nsynchronous programming language. We provide extensions to the synchronous\nsubset of the SystemJ programming language for modeling, implementation, and\nverification of such hybrid systems. We provide a sound rewrite semantics that\napproximate the evolution of the continuous variables in the discrete domain\ninspired from the classical supervisory control theory. The resultant discrete\ntime model can be verified using classical model-checking tools. Finally, we\nshow that systems designed using our approach have a higher fidelity than the\nones designed using the hybrid automaton approach.\n", "contributors": [{"name": "Malik, Avinash", "sameAs": [], "familyName": "Malik", "additionalName": "", "givenName": "Avinash", "email": ""}, {"name": "Roop, Partha", "sameAs": [], "familyName": "Roop", "additionalName": "", "givenName": "Partha", "email": ""}], "title": "A unified framework for modeling and implementation of hybrid systems\n  with synchronous controllers", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-23"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.05936", "oai:arXiv.org:1501.05936"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper presents a novel approach to including non-instantaneous discrete\ncontrol transitions in the linear hybrid automaton approach to simulation and\nverification of hybrid control systems. In this paper we study the control of a\ncontinuously evolving analog plant using a controller programmed in a\nsynchronous programming language. We provide extensions to the synchronous\nsubset of the SystemJ programming language for modeling, implementation, and\nverification of such hybrid systems. We provide a sound rewrite semantics that\napproximate the evolution of the continuous variables in the discrete domain\ninspired from the classical supervisory control theory. The resultant discrete\ntime model can be verified using classical model-checking tools. Finally, we\nshow that systems designed using our approach have a higher fidelity than the\nones designed using the hybrid automaton approach.\n", "Comment: 16 pages"]}}], "languages": [null], "subjects": ["computer science - systems and control", "computer science - programming languages"], "providerUpdatedDateTime": "2015-01-26T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.05936"}}, {"publisher": {"name": ""}, "description": "  The annotation of the results of database transformations was shown to be\nvery effective for various applications. Until recently, most works in this\ncontext focused on positive query languages. The provenance semirings is a\nparticular approach that was proven effective for these languages, and it was\nshown that when propagating provenance with semirings, the expected equivalence\naxioms of the corresponding query languages are satisfied. There have been\nseveral attempts to extend the framework to account for relational algebra\nqueries with difference. We show here that these suggestions fail to satisfy\nsome expected equivalence axioms (that in particular hold for queries on\n\"standard\" set and bag databases). Interestingly, we show that this is not a\npitfall of these particular attempts, but rather every such attempt is bound to\nfail in satisfying these axioms, for some semirings. Finally, we show\nparticular semirings for which an extension for supporting difference is\n(im)possible.\n", "contributors": [{"name": "Amsterdamer, Yael", "sameAs": [], "familyName": "Amsterdamer", "additionalName": "", "givenName": "Yael", "email": ""}, {"name": "Deutch, Daniel", "sameAs": [], "familyName": "Deutch", "additionalName": "", "givenName": "Daniel", "email": ""}, {"name": "Tannen, Val", "sameAs": [], "familyName": "Tannen", "additionalName": "", "givenName": "Val", "email": ""}], "title": "On the Limitations of Provenance for Queries With Difference", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-05-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.2255", "oai:arXiv.org:1105.2255"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  The annotation of the results of database transformations was shown to be\nvery effective for various applications. Until recently, most works in this\ncontext focused on positive query languages. The provenance semirings is a\nparticular approach that was proven effective for these languages, and it was\nshown that when propagating provenance with semirings, the expected equivalence\naxioms of the corresponding query languages are satisfied. There have been\nseveral attempts to extend the framework to account for relational algebra\nqueries with difference. We show here that these suggestions fail to satisfy\nsome expected equivalence axioms (that in particular hold for queries on\n\"standard\" set and bag databases). Interestingly, we show that this is not a\npitfall of these particular attempts, but rather every such attempt is bound to\nfail in satisfying these axioms, for some semirings. Finally, we show\nparticular semirings for which an extension for supporting difference is\n(im)possible.\n", "Comment: TAPP 2011"]}}], "languages": [null], "subjects": ["computer science - databases"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.2255"}}, {"publisher": {"name": "Department of Computer Science, Columbia University"}, "description": "Discovering code clones in a runtime environment helps software engineers identify hard to find logic-based bugs. Yet most research in the area of code clone discovery deals with source code due to the complexity of finding clones in a\ndynamic environment. KAMINO manipulates Java bytecode to track control and data flow dependencies at the methodlevel of Java programs during runtime. It then matches similar flows to find semantic code clones. With positive preliminary\nresults indicating code clones using KAMINO , future tests will compare the its robustness compared to existing code clones detection tools.", "contributors": [{"name": "Neubauer, Lindsay Anne", "sameAs": [], "familyName": "Neubauer", "additionalName": "Anne", "givenName": "Lindsay", "email": ""}], "title": "Kamino: Dynamic Approach to Semantic Code Clone Detection", "shareProperties": {"source": "columbia"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014"}}, {"name": "identifier", "properties": {"identifier": ["http://dx.doi.org/10.7916/D8542M79", "academiccommons.columbia.edu/ac:179003"]}}, {"name": "setSpec", "properties": {"setSpec": []}}], "languages": [null], "subjects": ["computer science"], "providerUpdatedDateTime": "2014-10-27T18:49:56", "uris": {"canonicalUri": "http://dx.doi.org/10.7916/D8542M79"}}, {"publisher": {"name": ""}, "description": "  We study the dynamics of majority automata networks when the vertices are\nupdated according to a block sequential updating scheme. In particular, we show\nthat the complexity of the problem of predicting an eventual state change in\nsome vertex, given an initial configuration, is PSPACE-complete.\n", "contributors": [{"name": "Goles, Eric", "sameAs": [], "familyName": "Goles", "additionalName": "", "givenName": "Eric", "email": ""}, {"name": "Montealegre, Pedro", "sameAs": [], "familyName": "Montealegre", "additionalName": "", "givenName": "Pedro", "email": ""}, {"name": "Salo, Ville", "sameAs": [], "familyName": "Salo", "additionalName": "", "givenName": "Ville", "email": ""}, {"name": "T\u00f6rm\u00e4, Ilkka", "sameAs": [], "familyName": "T\u00f6rm\u00e4", "additionalName": "", "givenName": "Ilkka", "email": ""}], "title": "PSPACE-Completeness of Majority Automata Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-01-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.03992", "oai:arXiv.org:1501.03992"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  We study the dynamics of majority automata networks when the vertices are\nupdated according to a block sequential updating scheme. In particular, we show\nthat the complexity of the problem of predicting an eventual state change in\nsome vertex, given an initial configuration, is PSPACE-complete.\n", "Comment: 14 pages, 8 figures"]}}], "languages": [null], "subjects": ["68r10", "f.2.2", "computer science - discrete mathematics", "g.2.2"], "providerUpdatedDateTime": "2015-01-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.03992"}}, {"publisher": {"name": ""}, "description": "  Due to the fact that quality of service requirements are not very strict for\nall traffic types, more calls of higher priority can be accommodated by\nreducing some bandwidth allocation for the bandwidth adaptive calls. The\nbandwidth adaptation to accept a higher priority call is more than that of a\nlower priority call. Therefore, the multi-level bandwidth adaptation technique\nimproves the overall forced call termination probability as well as provides\npriority of the traffic classes in terms of call blocking probability without\nreducing the bandwidth utilization. We propose a novel bandwidth adaptation\nmodel that releases multi-level of bandwidth from the existing multimedia\ntraffic calls. The amount of released bandwidth is decided based on the\npriority of the requesting traffic calls and the number of existing bandwidth\nadaptive calls. This prioritization of traffic classes does not reduce the\nbandwidth utilization. Moreover, our scheme reduces the overall forced call\ntermination probability significantly. The proposed scheme is modeled using the\nMarkov Chain. The numerical results show that the proposed scheme is able to\nprovide negligible handover call dropping probability as well as significantly\nreduced new call blocking probability of higher priority calls without\nincreasing the overall forced call termination probability.\n", "contributors": [{"name": "Chowdhury, Mostafa Zaman", "sameAs": [], "familyName": "Chowdhury", "additionalName": "Zaman", "givenName": "Mostafa", "email": ""}, {"name": "Jang, Yeong Min", "sameAs": [], "familyName": "Jang", "additionalName": "Min", "givenName": "Yeong", "email": ""}], "title": "Class-Based Service Connectivity using Multi-Level Bandwidth Adaptation\n  in Multimedia Wireless Networks", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-12-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1412.3625", "Wireless Personal Communications, vol. 77, no 4, pp. 2735-2745,\n  August 2014", "doi:10.1007/s11277-014-1665-7", "oai:arXiv.org:1412.3625"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Due to the fact that quality of service requirements are not very strict for\nall traffic types, more calls of higher priority can be accommodated by\nreducing some bandwidth allocation for the bandwidth adaptive calls. The\nbandwidth adaptation to accept a higher priority call is more than that of a\nlower priority call. Therefore, the multi-level bandwidth adaptation technique\nimproves the overall forced call termination probability as well as provides\npriority of the traffic classes in terms of call blocking probability without\nreducing the bandwidth utilization. We propose a novel bandwidth adaptation\nmodel that releases multi-level of bandwidth from the existing multimedia\ntraffic calls. The amount of released bandwidth is decided based on the\npriority of the requesting traffic calls and the number of existing bandwidth\nadaptive calls. This prioritization of traffic classes does not reduce the\nbandwidth utilization. Moreover, our scheme reduces the overall forced call\ntermination probability significantly. The proposed scheme is modeled using the\nMarkov Chain. The numerical results show that the proposed scheme is able to\nprovide negligible handover call dropping probability as well as significantly\nreduced new call blocking probability of higher priority calls without\nincreasing the overall forced call termination probability.\n", "Comment: Journal paper"]}}], "languages": [null], "subjects": ["computer science - performance", "computer science - networking and internet architecture", "computer science - multimedia"], "providerUpdatedDateTime": "2014-12-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1412.3625"}}, {"publisher": {"name": "Massachusetts Institute of Technology"}, "description": "This thesis presents a new simple lightweight C++ thread based parallelization library, intended for use in numerical algorithms. It provides simple multitasking and task synchronization functions. The library hides all internal system calls from the developer and utilizes thread pooling to provide better performance and utilization of system time and resources. The library is lightweight and platform independent, and has been tested on Linux, and Windows. Experiments were conducted to verify the proper functionality of the library and to show that parallelized algorithms on a single machine are more efficient than using the Message Passing Interface (MPI) using shared memory. In the opinion of several researchers who have used this library, the parallelized code is more easily understood and debugged than MPI. The results of initial experiments show that algorithms are as efficient or better than those using MPI.", "contributors": [{"name": "Alhubail, Maitham Makki", "sameAs": [], "familyName": "Alhubail", "additionalName": "Makki", "givenName": "Maitham", "email": ""}, {"name": "Massachusetts Institute of Technology. Computation for Design and Optimization Program.", "sameAs": [], "familyName": "Program.", "additionalName": "Institute of Technology. Computation for Design and Optimization", "givenName": "Massachusetts", "email": ""}, {"name": "John R. Williams.", "sameAs": [], "familyName": "Williams.", "additionalName": "R.", "givenName": "John", "email": ""}], "title": "A thread-based parallel programming library for numerical algorithms", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": "Thesis"}}, {"name": "source", "properties": {"source": []}}, {"name": "format", "properties": {"format": "47 pages"}}, {"name": "rights", "properties": {"rights": ["M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.", "http://dspace.mit.edu/handle/1721.1/7582"]}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/1721.1/90080", "890141986", "oai:dspace.mit.edu:1721.1/90080"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "date", "properties": {"date": ["2014-09-19T21:38:32Z", "2014-09-19T21:38:32Z", "2014", "2014"]}}, {"name": "description", "properties": {"description": ["This thesis presents a new simple lightweight C++ thread based parallelization library, intended for use in numerical algorithms. It provides simple multitasking and task synchronization functions. The library hides all internal system calls from the developer and utilizes thread pooling to provide better performance and utilization of system time and resources. The library is lightweight and platform independent, and has been tested on Linux, and Windows. Experiments were conducted to verify the proper functionality of the library and to show that parallelized algorithms on a single machine are more efficient than using the Message Passing Interface (MPI) using shared memory. In the opinion of several researchers who have used this library, the parallelized code is more easily understood and debugged than MPI. The results of initial experiments show that algorithms are as efficient or better than those using MPI.", "by Maitham Makki Alhubail.", "Thesis: S.M., Massachusetts Institute of Technology, Computation for Design and Optimization Program, 2014.", "Cataloged from PDF version of thesis.", "Includes bibliographical references (page 47)."]}}, {"name": "setSpec", "properties": {"setSpec": ["hdl_1721.1_39117", "hdl_1721.1_39115"]}}], "languages": [null], "subjects": ["computation for design and optimization program."], "providerUpdatedDateTime": "2015-04-27T14:56:20", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/90080"}}, {"publisher": {"name": ""}, "description": "  Orthogonal greedy learning (OGL) is a stepwise learning scheme that adds a\nnew atom from a dictionary via the steepest gradient descent and build the\nestimator via orthogonal projecting the target function to the space spanned by\nthe selected atoms in each greedy step. Here, \"greed\" means choosing a new atom\naccording to the steepest gradient descent principle. OGL then avoids the\noverfitting/underfitting by selecting an appropriate iteration number. In this\npaper, we point out that the overfitting/underfitting can also be avoided via\nredefining \"greed\" in OGL. To this end, we introduce a new greedy metric,\ncalled $\\delta$-greedy thresholds, to refine \"greed\" and theoretically verifies\nits feasibility. Furthermore, we reveals that such a greedy metric can bring an\nadaptive termination rule on the premise of maintaining the prominent learning\nperformance of OGL. Our results show that the steepest gradient descent is not\nthe unique greedy metric of OGL and some other more suitable metric may lessen\nthe hassle of model-selection of OGL.\n", "contributors": [{"name": "Xu, Lin", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Lin", "email": ""}, {"name": "Lin, Shaobo", "sameAs": [], "familyName": "Lin", "additionalName": "", "givenName": "Shaobo", "email": ""}, {"name": "Zeng, Jinshan", "sameAs": [], "familyName": "Zeng", "additionalName": "", "givenName": "Jinshan", "email": ""}, {"name": "Xu, Zongben", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Zongben", "email": ""}], "title": "Greedy metrics in orthogonal greedy learning", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.3553", "oai:arXiv.org:1411.3553"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Orthogonal greedy learning (OGL) is a stepwise learning scheme that adds a\nnew atom from a dictionary via the steepest gradient descent and build the\nestimator via orthogonal projecting the target function to the space spanned by\nthe selected atoms in each greedy step. Here, \"greed\" means choosing a new atom\naccording to the steepest gradient descent principle. OGL then avoids the\noverfitting/underfitting by selecting an appropriate iteration number. In this\npaper, we point out that the overfitting/underfitting can also be avoided via\nredefining \"greed\" in OGL. To this end, we introduce a new greedy metric,\ncalled $\\delta$-greedy thresholds, to refine \"greed\" and theoretically verifies\nits feasibility. Furthermore, we reveals that such a greedy metric can bring an\nadaptive termination rule on the premise of maintaining the prominent learning\nperformance of OGL. Our results show that the steepest gradient descent is not\nthe unique greedy metric of OGL and some other more suitable metric may lessen\nthe hassle of model-selection of OGL.\n", "Comment: 33 pages, 8 figures"]}}], "languages": [null], "subjects": ["f.2.2", "computer science - learning"], "providerUpdatedDateTime": "2014-11-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.3553"}}, {"publisher": {"name": ""}, "description": "  Caching data files directly on mobile user devices combined with\ndevice-to-device (D2D) communications has recently been suggested to improve\nthe capacity of wireless net6works. We investigate the performance of\nregenerating codes in terms of the total energy consumption of a cellular\nnetwork. We show that regenerating codes can offer large performance gains. It\nturns out that using redundancy against storage node failures is only\nbeneficial if the popularity of the data is between certain thresholds. As our\nmajor contribution, we investigate under which circumstances regenerating codes\nwith multiple redundant data fragments outdo uncoded caching.\n", "contributors": [{"name": "P\u00e4\u00e4kk\u00f6nen, Joonas", "sameAs": [], "familyName": "P\u00e4\u00e4kk\u00f6nen", "additionalName": "", "givenName": "Joonas", "email": ""}, {"name": "Hollanti, Camilla", "sameAs": [], "familyName": "Hollanti", "additionalName": "", "givenName": "Camilla", "email": ""}, {"name": "Tirkkonen, Olav", "sameAs": [], "familyName": "Tirkkonen", "additionalName": "", "givenName": "Olav", "email": ""}], "title": "Device-to-Device Data Storage with Regenerating Codes", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.1608", "oai:arXiv.org:1411.1608"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Caching data files directly on mobile user devices combined with\ndevice-to-device (D2D) communications has recently been suggested to improve\nthe capacity of wireless net6works. We investigate the performance of\nregenerating codes in terms of the total energy consumption of a cellular\nnetwork. We show that regenerating codes can offer large performance gains. It\nturns out that using redundancy against storage node failures is only\nbeneficial if the popularity of the data is between certain thresholds. As our\nmajor contribution, we investigate under which circumstances regenerating codes\nwith multiple redundant data fragments outdo uncoded caching.\n", "Comment: 6 pages, 8 figures"]}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2014-11-07T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.1608"}}, {"publisher": {"name": ""}, "description": "  The Locator/ID Separation Protocol (LISP) limits the growth of the\nDefault-Free Zone routing tables by creating a highly aggregatable and\nquasi-static Internet core. However, LISP pushes the forwarding state to edge\nrouters whose timely operation relies on caching of location to identity\nbindings. In this paper we develop an analytical model to study the asymptotic\nscalability of the LISP cache. Under the assumptions that (i) long-term\npopularity can be modeled as a constant Generalized Zipf distribution and (ii)\ntemporal locality is predominantly determined by long-term popularity, we find\nthat the scalability of the LISP cache is O(1) with respect to the amount of\nprefixes (Internet growth) and users (growth of the LISP site). We validate the\nmodel and discuss the accuracy of our assumptions using several one-day-long\npacket traces.\n", "contributors": [{"name": "Coras, Florin", "sameAs": [], "familyName": "Coras", "additionalName": "", "givenName": "Florin", "email": ""}, {"name": "Domingo-Pascual, Jordi", "sameAs": [], "familyName": "Domingo-Pascual", "additionalName": "", "givenName": "Jordi", "email": ""}, {"name": "Cabellos-Aparicio, Albert", "sameAs": [], "familyName": "Cabellos-Aparicio", "additionalName": "", "givenName": "Albert", "email": ""}], "title": "On the Scalability of LISP Mappings Caches", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-04-12", "2015-04-13"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1504.03004", "oai:arXiv.org:1504.03004"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The Locator/ID Separation Protocol (LISP) limits the growth of the\nDefault-Free Zone routing tables by creating a highly aggregatable and\nquasi-static Internet core. However, LISP pushes the forwarding state to edge\nrouters whose timely operation relies on caching of location to identity\nbindings. In this paper we develop an analytical model to study the asymptotic\nscalability of the LISP cache. Under the assumptions that (i) long-term\npopularity can be modeled as a constant Generalized Zipf distribution and (ii)\ntemporal locality is predominantly determined by long-term popularity, we find\nthat the scalability of the LISP cache is O(1) with respect to the amount of\nprefixes (Internet growth) and users (growth of the LISP site). We validate the\nmodel and discuss the accuracy of our assumptions using several one-day-long\npacket traces.\n"}}], "languages": [null], "subjects": ["computer science - networking and internet architecture"], "providerUpdatedDateTime": "2015-04-14T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1504.03004"}}, {"publisher": {"name": ""}, "description": "  Traditionally, there are three species of classification: unsupervised,\nsupervised, and semi-supervised. Supervised and semi-supervised classification\ndiffer by whether or not weight is given to unlabelled observations in the\nclassification procedure. In unsupervised classification, or clustering, no\nlabels are known and hence full weight is given to unlabelled observations. A\npriori, it can be very difficult to choose the optimal level of supervision,\nand the consequences of a sub-optimal choice can be non-trivial. A flexible\nfractionally-supervised approach to classification is introduced, where any\nlevel of supervision --- ranging from unsupervised to supervised --- can be\nattained. Our approach uses a weighted likelihood, wherein weights control the\nlevel of supervision. This paper investigates several choices for the\nspecification of these weights. Gaussian mixture models are used as a vehicle\nto illustrate our fractionally-supervised classification approach; however, it\nis broadly applicable and variations on the postulated model can easily be\nmade. A comparison between our approach and the traditional species is\npresented using simulated and real data.\n", "contributors": [{"name": "Vrbik, Irene", "sameAs": [], "familyName": "Vrbik", "additionalName": "", "givenName": "Irene", "email": ""}, {"name": "McNicholas, Paul D.", "sameAs": [], "familyName": "McNicholas", "additionalName": "D.", "givenName": "Paul", "email": ""}], "title": "Fractionally-Supervised Classification", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2013-07-12", "2015-01-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1307.3598", "oai:arXiv.org:1307.3598"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": "  Traditionally, there are three species of classification: unsupervised,\nsupervised, and semi-supervised. Supervised and semi-supervised classification\ndiffer by whether or not weight is given to unlabelled observations in the\nclassification procedure. In unsupervised classification, or clustering, no\nlabels are known and hence full weight is given to unlabelled observations. A\npriori, it can be very difficult to choose the optimal level of supervision,\nand the consequences of a sub-optimal choice can be non-trivial. A flexible\nfractionally-supervised approach to classification is introduced, where any\nlevel of supervision --- ranging from unsupervised to supervised --- can be\nattained. Our approach uses a weighted likelihood, wherein weights control the\nlevel of supervision. This paper investigates several choices for the\nspecification of these weights. Gaussian mixture models are used as a vehicle\nto illustrate our fractionally-supervised classification approach; however, it\nis broadly applicable and variations on the postulated model can easily be\nmade. A comparison between our approach and the traditional species is\npresented using simulated and real data.\n"}}], "languages": [null], "subjects": ["statistics - applications", "statistics - computation", "statistics - methodology", "statistics - machine learning"], "providerUpdatedDateTime": "2015-01-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1307.3598"}}, {"publisher": {"name": ""}, "description": "  In order to address the imprecision often introduced by widening operators,\npolicy iteration based on min-computations amounts to consider the\ncharacterization of reachable states of a program as an iterative computation\nof policies, starting from a post-fixpoint. Computing each policy and the\nassociated invariant relies on a sequence of numerical optimizations. While the\nearly papers rely on LP to address linear properties of linear programs, the\ncurrent state of the art is still limited to the analysis of linear programs\nwith at most quadratic invariant, relying on Semi-Definite Programming (SDP)\nsolvers to compute the next policy, and LP solvers to solve the selected\npolicy.\n  We propose here to extend the class of programs considered through the use of\nSums-of-Squares (SOS) optimizations. Our approach enables the precise analysis\nof switched systems with polynomial assigns and guards. The analysis presented\nhas been implemented in Matlab and applied on existing programs, improving both\nthe set of systems analyzable and the precision of analyzed ones.\n", "contributors": [{"name": "Adj\u00e9, Assal\u00e9", "sameAs": [], "familyName": "Adj\u00e9", "additionalName": "", "givenName": "Assal\u00e9", "email": ""}, {"name": "Garoche, Pierre-Lo\u00efc", "sameAs": [], "familyName": "Garoche", "additionalName": "", "givenName": "Pierre-Lo\u00efc", "email": ""}, {"name": "Magron, Victor", "sameAs": [], "familyName": "Magron", "additionalName": "", "givenName": "Victor", "email": ""}], "title": "A Sums-of-Squares Extension of Policy Iterations", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-03-27"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1503.08090", "oai:arXiv.org:1503.08090"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  In order to address the imprecision often introduced by widening operators,\npolicy iteration based on min-computations amounts to consider the\ncharacterization of reachable states of a program as an iterative computation\nof policies, starting from a post-fixpoint. Computing each policy and the\nassociated invariant relies on a sequence of numerical optimizations. While the\nearly papers rely on LP to address linear properties of linear programs, the\ncurrent state of the art is still limited to the analysis of linear programs\nwith at most quadratic invariant, relying on Semi-Definite Programming (SDP)\nsolvers to compute the next policy, and LP solvers to solve the selected\npolicy.\n  We propose here to extend the class of programs considered through the use of\nSums-of-Squares (SOS) optimizations. Our approach enables the precise analysis\nof switched systems with polynomial assigns and guards. The analysis presented\nhas been implemented in Matlab and applied on existing programs, improving both\nthe set of systems analyzable and the precision of analyzed ones.\n", "Comment: 20 pages, 1 figure"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - logic in computer science"], "providerUpdatedDateTime": "2015-03-30T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1503.08090"}}, {"publisher": {"name": ""}, "description": "  In this paper, analytic relations between the macroscopic variables and the\nmesoscopic variables are derived for lattice Boltzmann methods (LBM). The\nanalytic relations are achieved by two different methods for the exchange from\nvelocity fields of finite-type methods to the single particle distribution\nfunctions of LBM. The numerical errors of reconstructing the single particle\ndistribution functions and the non-equilibrium distribution function by\nmacroscopic fields are investigated. Results show that their accuracy is better\nthan the existing ones. The proposed reconstruction operator has been used to\nimplement the coupling computations of LBM and macro-numerical methods of FVM.\nThe lid-driven cavity flow is chosen to carry out the coupling computations\nbased on the numerical strategies of domain decomposition methods (DDM). The\nnumerical results show that the proposed lifting relations are accurate and\nrobust.\n", "contributors": [{"name": "Xu, Hui", "sameAs": [], "familyName": "Xu", "additionalName": "", "givenName": "Hui", "email": ""}, {"name": "Luan, Huibao", "sameAs": [], "familyName": "Luan", "additionalName": "", "givenName": "Huibao", "email": ""}, {"name": "He, Yaling", "sameAs": [], "familyName": "He", "additionalName": "", "givenName": "Yaling", "email": ""}, {"name": "Tao, Wenquan", "sameAs": [], "familyName": "Tao", "additionalName": "", "givenName": "Wenquan", "email": ""}], "title": "A Lifting Relation from Macroscopic Variables to Mesoscopic Variables in\n  Lattice Boltzmann Method: Derivation, Numerical Assessments and Coupling\n  Computations Validation", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-04-20", "2011-10-05"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1104.3958", "Computers and Fluids 54 (2012): 92-104", "doi:10.1016/j.compfluid.2011.10.007", "oai:arXiv.org:1104.3958"]}}, {"name": "setSpec", "properties": {"setSpec": "physics:physics"}}, {"name": "description", "properties": {"description": "  In this paper, analytic relations between the macroscopic variables and the\nmesoscopic variables are derived for lattice Boltzmann methods (LBM). The\nanalytic relations are achieved by two different methods for the exchange from\nvelocity fields of finite-type methods to the single particle distribution\nfunctions of LBM. The numerical errors of reconstructing the single particle\ndistribution functions and the non-equilibrium distribution function by\nmacroscopic fields are investigated. Results show that their accuracy is better\nthan the existing ones. The proposed reconstruction operator has been used to\nimplement the coupling computations of LBM and macro-numerical methods of FVM.\nThe lid-driven cavity flow is chosen to carry out the coupling computations\nbased on the numerical strategies of domain decomposition methods (DDM). The\nnumerical results show that the proposed lifting relations are accurate and\nrobust.\n"}}], "languages": [null], "subjects": ["physics - computational physics", "physics - fluid dynamics"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1104.3958"}}, {"publisher": {"name": ""}, "description": "  The equation in the title describes the number of bright images of a point\nsource under lensing by an elliptic object with isothermal density. We prove\nthat this equation has at most 6 solutions. Any number of solutions from 1 to 6\ncan actually occur.\n", "contributors": [{"name": "Bergweiler, Walter", "sameAs": [], "familyName": "Bergweiler", "additionalName": "", "givenName": "Walter", "email": ""}, {"name": "Eremenko, Alexandre", "sameAs": [], "familyName": "Eremenko", "additionalName": "", "givenName": "Alexandre", "email": ""}], "title": "On the number of solutions of a transcendental equation arising in the\n  theory of gravitational lensing", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2009-08-31", "2010-01-25"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/0908.4595", "Comput.Meth.Funct.Theory 10:303-324,2010", "oai:arXiv.org:0908.4595"]}}, {"name": "setSpec", "properties": {"setSpec": ["math", "physics:astro-ph", "physics:math-ph"]}}, {"name": "description", "properties": {"description": ["  The equation in the title describes the number of bright images of a point\nsource under lensing by an elliptic object with isothermal density. We prove\nthat this equation has at most 6 solutions. Any number of solutions from 1 to 6\ncan actually occur.\n", "Comment: 26 pages, 12 figures"]}}], "languages": [null], "subjects": ["astrophysics - cosmology and nongalactic astrophysics", "mathematical physics", "30e99", "85a99", "mathematics - complex variables"], "providerUpdatedDateTime": "2014-11-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/0908.4595"}}, {"publisher": {"name": ""}, "description": "  We present a fixed point theorem for a class of (potentially) non-monotonic\nfunctions over specially structured complete lattices. The theorem has as a\nspecial case the Knaster-Tarski fixed point theorem when restricted to the case\nof monotonic functions and Kleene's theorem when the functions are additionally\ncontinuous. From the practical side, the theorem has direct applications in the\nsemantics of negation in logic programming. In particular, it leads to a more\ndirect and elegant proof of the least fixed point result of [Rondogiannis and\nW.W.Wadge, ACM TOCL 6(2): 441-467 (2005)]. Moreover, the theorem appears to\nhave potential for possible applications outside the logic programming domain.\n", "contributors": [{"name": "\u00c9sik, Zolt\u00e1n", "sameAs": [], "familyName": "\u00c9sik", "additionalName": "", "givenName": "Zolt\u00e1n", "email": ""}, {"name": "Rondogiannis, Panos", "sameAs": [], "familyName": "Rondogiannis", "additionalName": "", "givenName": "Panos", "email": ""}], "title": "A Fixed Point Theorem for Non-Monotonic Functions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2014-02-03", "2015-02-01"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1402.0299", "oai:arXiv.org:1402.0299"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We present a fixed point theorem for a class of (potentially) non-monotonic\nfunctions over specially structured complete lattices. The theorem has as a\nspecial case the Knaster-Tarski fixed point theorem when restricted to the case\nof monotonic functions and Kleene's theorem when the functions are additionally\ncontinuous. From the practical side, the theorem has direct applications in the\nsemantics of negation in logic programming. In particular, it leads to a more\ndirect and elegant proof of the least fixed point result of [Rondogiannis and\nW.W.Wadge, ACM TOCL 6(2): 441-467 (2005)]. Moreover, the theorem appears to\nhave potential for possible applications outside the logic programming domain.\n", "Comment: 34 pages. Accepted in: Theoretical Computer Science (to appear)"]}}], "languages": [null], "subjects": ["mathematics - logic", "computer science - logic in computer science"], "providerUpdatedDateTime": "2015-02-03T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1402.0299"}}, {"publisher": {"name": ""}, "description": "  The word2vec model and application by Mikolov et al. have attracted a great\namount of attention in recent two years. The vector representations of words\nlearned by word2vec models have been proven to be able to carry semantic\nmeanings and are useful in various NLP tasks. As an increasing number of\nresearchers would like to experiment with word2vec, I notice that there lacks a\nmaterial that comprehensively explains the parameter learning process of\nword2vec in details, thus preventing many people with less neural network\nexperience from understanding how exactly word2vec works.\n  This note provides detailed derivations and explanations of the parameter\nupdate equations for the word2vec models, including the original continuous\nbag-of-word (CBOW) and skip-gram models, as well as advanced tricks,\nhierarchical soft-max and negative sampling. In the appendix a review is given\non the basics of neuron network models and backpropagation.\n", "contributors": [{"name": "Rong, Xin", "sameAs": [], "familyName": "Rong", "additionalName": "", "givenName": "Xin", "email": ""}], "title": "word2vec Parameter Learning Explained", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-11"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.2738", "oai:arXiv.org:1411.2738"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  The word2vec model and application by Mikolov et al. have attracted a great\namount of attention in recent two years. The vector representations of words\nlearned by word2vec models have been proven to be able to carry semantic\nmeanings and are useful in various NLP tasks. As an increasing number of\nresearchers would like to experiment with word2vec, I notice that there lacks a\nmaterial that comprehensively explains the parameter learning process of\nword2vec in details, thus preventing many people with less neural network\nexperience from understanding how exactly word2vec works.\n  This note provides detailed derivations and explanations of the parameter\nupdate equations for the word2vec models, including the original continuous\nbag-of-word (CBOW) and skip-gram models, as well as advanced tricks,\nhierarchical soft-max and negative sampling. In the appendix a review is given\non the basics of neuron network models and backpropagation.\n"}}], "languages": [null], "subjects": ["computer science - computation and language"], "providerUpdatedDateTime": "2014-11-12T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.2738"}}, {"publisher": {"name": ""}, "description": "  We propose a new data-augmentation strategy for fully Bayesian inference in\nmodels with binomial likelihoods. The approach appeals to a new class of\nPolya-Gamma distributions, which are constructed in detail. A variety of\nexamples are presented to show the versatility of the method, including\nlogistic regression, negative binomial regression, nonlinear mixed-effects\nmodels, and spatial models for count data. In each case, our data-augmentation\nstrategy leads to simple, effective methods for posterior inference that: (1)\ncircumvent the need for analytic approximations, numerical integration, or\nMetropolis-Hastings; and (2) outperform other known data-augmentation\nstrategies, both in ease of use and in computational efficiency. All methods,\nincluding an efficient sampler for the Polya-Gamma distribution, are\nimplemented in the R package BayesLogit.\n  In the technical supplement appended to the end of the paper, we provide\nfurther details regarding the generation of Polya-Gamma random variables; the\nempirical benchmarks reported in the main manuscript; and the extension of the\nbasic data-augmentation framework to contingency tables and multinomial\noutcomes.\n", "contributors": [{"name": "Polson, Nicholas G.", "sameAs": [], "familyName": "Polson", "additionalName": "G.", "givenName": "Nicholas", "email": ""}, {"name": "Scott, James G.", "sameAs": [], "familyName": "Scott", "additionalName": "G.", "givenName": "James", "email": ""}, {"name": "Windle, Jesse", "sameAs": [], "familyName": "Windle", "additionalName": "", "givenName": "Jesse", "email": ""}], "title": "Bayesian inference for logistic models using Polya-Gamma latent\n  variables", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2012-05-01", "2013-07-22"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1205.0310", "oai:arXiv.org:1205.0310"]}}, {"name": "setSpec", "properties": {"setSpec": "stat"}}, {"name": "description", "properties": {"description": "  We propose a new data-augmentation strategy for fully Bayesian inference in\nmodels with binomial likelihoods. The approach appeals to a new class of\nPolya-Gamma distributions, which are constructed in detail. A variety of\nexamples are presented to show the versatility of the method, including\nlogistic regression, negative binomial regression, nonlinear mixed-effects\nmodels, and spatial models for count data. In each case, our data-augmentation\nstrategy leads to simple, effective methods for posterior inference that: (1)\ncircumvent the need for analytic approximations, numerical integration, or\nMetropolis-Hastings; and (2) outperform other known data-augmentation\nstrategies, both in ease of use and in computational efficiency. All methods,\nincluding an efficient sampler for the Polya-Gamma distribution, are\nimplemented in the R package BayesLogit.\n  In the technical supplement appended to the end of the paper, we provide\nfurther details regarding the generation of Polya-Gamma random variables; the\nempirical benchmarks reported in the main manuscript; and the extension of the\nbasic data-augmentation framework to contingency tables and multinomial\noutcomes.\n"}}], "languages": [null], "subjects": ["statistics - computation", "statistics - methodology", "statistics - machine learning"], "providerUpdatedDateTime": "2015-03-20T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1205.0310"}}, {"publisher": {"name": "Institute of Electrical and Electronics Engineers"}, "description": "Abbreviation Completion is a novel technique to improve the efficiency of code-writing by supporting code completion of multiple keywords based on non-predefined abbreviated input - a different approach from conventional code completion that finds one keyword at a time based on an exact character match. Abbreviated input is expanded into keywords by a Hidden Markov Model learned from a corpus of existing code. The technique does not require the user to memorize abbreviations and provides incremental feedback of the most likely completions. This paper presents the algorithm for abbreviation completion, integrated with a new user interface for multiple-keyword completion. We tested the system by sampling 3000 code lines from open source projects and found that more than 98% of the code lines could be resolved from acronym-like abbreviations. A user study found 30% reduction in time usage and 41% reduction of keystrokes over conventional code completion.", "contributors": [{"name": "Miller, Robert C.", "sameAs": [], "familyName": "Miller", "additionalName": "C.", "givenName": "Robert", "email": ""}, {"name": "Han, Sangmok", "sameAs": [], "familyName": "Han", "additionalName": "", "givenName": "Sangmok", "email": ""}, {"name": "Wallace, David Robert", "sameAs": [], "familyName": "Wallace", "additionalName": "Robert", "givenName": "David", "email": ""}], "title": "Code Completion From Abbreviated Input", "shareProperties": {"source": "mit"}, "otherProperties": [{"name": "type", "properties": {"type": ["Article", "http://purl.org/eprint/type/JournalArticle"]}}, {"name": "source", "properties": {"source": "IEEE"}}, {"name": "format", "properties": {"format": []}}, {"name": "rights", "properties": {"rights": "Article is made available in accordance with the publisher's policy and may be subject to US copyright law. Please refer to the publisher's site for terms of use."}}, {"name": "identifier", "properties": {"identifier": ["978-1-4244-5259-0", "1527-1366", "INSPEC Accession Number: 11205136", "http://hdl.handle.net/1721.1/59377", "Sangmok Han, D.R. Wallace, and R.C. Miller. \u201cCode Completion from Abbreviated Input.\u201d Automated Software Engineering, 2009. ASE '09. 24th IEEE/ACM International Conference on. 2009. 332-343. \u00a9 2010 Institute of Electrical and Electronics Engineers.", "PUBLISHER_POLICY", "oai:dspace.mit.edu:1721.1/59377"]}}, {"name": "relation", "properties": {"relation": ["http://dx.doi.org/10.1109/ase.2009.64", "24th IEEE/ACM International Conference on Automated Software Engineering"]}}, {"name": "date", "properties": {"date": ["2010-10-15T15:48:31Z", "2010-10-15T15:48:31Z", "2010-03", "2009-11"]}}, {"name": "description", "properties": {"description": ["Abbreviation Completion is a novel technique to improve the efficiency of code-writing by supporting code completion of multiple keywords based on non-predefined abbreviated input - a different approach from conventional code completion that finds one keyword at a time based on an exact character match. Abbreviated input is expanded into keywords by a Hidden Markov Model learned from a corpus of existing code. The technique does not require the user to memorize abbreviations and provides incremental feedback of the most likely completions. This paper presents the algorithm for abbreviation completion, integrated with a new user interface for multiple-keyword completion. We tested the system by sampling 3000 code lines from open source projects and found that more than 98% of the code lines could be resolved from acronym-like abbreviations. A user study found 30% reduction in time usage and 41% reduction of keystrokes over conventional code completion.", "Samsung Scholarship Foundation"]}}, {"name": "setSpec", "properties": {"setSpec": "hdl_1721.1_49433"}}], "languages": [null], "subjects": ["code assistants", "abbreviation", "code completion", "multiple keywords", "data mining", "hidden markov model"], "providerUpdatedDateTime": "2015-03-20T19:26:03", "uris": {"canonicalUri": "http://hdl.handle.net/1721.1/59377"}}, {"publisher": {"name": ""}, "description": "  We compare variants of Anderson Mixing with the Jacobian-Free Newton-Krylov\nand Broyden methods applied to an instance of the k-eigenvalue formulation of\nthe linear Boltzmann transport equation. We present evidence that one variant\nof Anderson Mixing finds solutions in the fewest number of iterations. We\nexamine and strengthen theoretical results of Anderson Mixing applied to linear\nproblems.\n", "contributors": [{"name": "Calef, Matthew T.", "sameAs": [], "familyName": "Calef", "additionalName": "T.", "givenName": "Matthew", "email": ""}, {"name": "Fichtl, Erin D.", "sameAs": [], "familyName": "Fichtl", "additionalName": "D.", "givenName": "Erin", "email": ""}, {"name": "Warsa, James S.", "sameAs": [], "familyName": "Warsa", "additionalName": "S.", "givenName": "James", "email": ""}, {"name": "Berndt, Markus", "sameAs": [], "familyName": "Berndt", "additionalName": "", "givenName": "Markus", "email": ""}, {"name": "Carlson, Neil N.", "sameAs": [], "familyName": "Carlson", "additionalName": "N.", "givenName": "Neil", "email": ""}], "title": "Nonlinear Krylov Acceleration Applied to a Discrete Ordinates\n  Formulation of the k-Eigenvalue Problem", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-12-15", "2013-01-17"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1112.3568", "doi:10.1016/j.jcp.2012.12.024", "oai:arXiv.org:1112.3568"]}}, {"name": "setSpec", "properties": {"setSpec": "physics:physics"}}, {"name": "description", "properties": {"description": ["  We compare variants of Anderson Mixing with the Jacobian-Free Newton-Krylov\nand Broyden methods applied to an instance of the k-eigenvalue formulation of\nthe linear Boltzmann transport equation. We present evidence that one variant\nof Anderson Mixing finds solutions in the fewest number of iterations. We\nexamine and strengthen theoretical results of Anderson Mixing applied to linear\nproblems.\n", "Comment: This final revision includes results of the C5G7-MOX problem;\n  Nonlinear Krylov Acceleration Applied to a Discrete Ordinates Formulation of\n  the k-Eigenvalue Problem, Accepted by the Journal of Computational Physics\n  December 2012"]}}], "languages": [null], "subjects": ["physics - computational physics"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1112.3568"}}, {"publisher": {"name": ""}, "description": "  The spread of ideas across a social network can be studied using complex\ncontagion models, in which agents are activated by contact with multiple\nactivated neighbors. The investigation of complex contagions can provide\ncrucial insights into social influence and behavior-adoption cascades on\nnetworks. In this paper, we introduce a model of a multi-stage complex\ncontagion on networks. Agents at different stages --- which could, for example,\nrepresent differing levels of support for a social movement or differing levels\nof commitment to a certain product or idea --- exert different amounts of\ninfluence on their neighbors. We demonstrate that the presence of even one\nadditional stage introduces novel dynamical behavior, including interplay\nbetween multiple cascades, that cannot occur in single-stage contagion models.\nWe find that cascades --- and hence collective action --- can be driven not\nonly by high-stage influencers but also by low-stage influencers.\n", "contributors": [{"name": "Melnik, Sergey", "sameAs": [], "familyName": "Melnik", "additionalName": "", "givenName": "Sergey", "email": ""}, {"name": "Ward, Jonathan A.", "sameAs": [], "familyName": "Ward", "additionalName": "A.", "givenName": "Jonathan", "email": ""}, {"name": "Gleeson, James P.", "sameAs": [], "familyName": "Gleeson", "additionalName": "P.", "givenName": "James", "email": ""}, {"name": "Porter, Mason A.", "sameAs": [], "familyName": "Porter", "additionalName": "A.", "givenName": "Mason", "email": ""}], "title": "Multi-Stage Complex Contagions", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-11-07", "2013-02-22"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1111.1596", "Chaos 23, 013124 (2013)", "doi:10.1063/1.4790836", "oai:arXiv.org:1111.1596"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math", "physics:nlin", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  The spread of ideas across a social network can be studied using complex\ncontagion models, in which agents are activated by contact with multiple\nactivated neighbors. The investigation of complex contagions can provide\ncrucial insights into social influence and behavior-adoption cascades on\nnetworks. In this paper, we introduce a model of a multi-stage complex\ncontagion on networks. Agents at different stages --- which could, for example,\nrepresent differing levels of support for a social movement or differing levels\nof commitment to a certain product or idea --- exert different amounts of\ninfluence on their neighbors. We demonstrate that the presence of even one\nadditional stage introduces novel dynamical behavior, including interplay\nbetween multiple cascades, that cannot occur in single-stage contagion models.\nWe find that cascades --- and hence collective action --- can be driven not\nonly by high-stage influencers but also by low-stage influencers.\n", "Comment: 12 pages, 10 figures. This version is accepted to appear in Chaos"]}}], "languages": [null], "subjects": ["physics - physics and society", "nonlinear sciences - adaptation and self-organizing systems", "mathematics - dynamical systems", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1111.1596"}}, {"publisher": {"name": ""}, "description": "abstract: As we migrate into an era of personalized medicine, understanding how bio-molecules interact with one another to form cellular systems is one of the key focus areas of systems biology. Several challenges such as the dynamic nature of cellular systems, uncertainty due to environmental influences, and the heterogeneity between individual patients render this a difficult task. In the last decade, several algorithms have been proposed to elucidate cellular systems from data, resulting in numerous data-driven hypotheses. However, due to the large number of variables involved in the process, many of which are unknown or not measurable, such computational approaches often lead to a high proportion of false positives. This renders interpretation of the data-driven hypotheses extremely difficult. Consequently, a dismal proportion of these hypotheses are subject to further experimental validation, eventually limiting their potential to augment existing biological knowledge. This dissertation develops a framework of computational methods for the analysis of such data-driven hypotheses leveraging existing biological knowledge. Specifically, I show how biological knowledge can be mapped onto these hypotheses and subsequently augmented through novel hypotheses. Biological hypotheses are learnt in three levels of abstraction -- individual interactions, functional modules and relationships between pathways, corresponding to three complementary aspects of biological systems. The computational methods developed in this dissertation are applied to high throughput cancer data, resulting in novel hypotheses with potentially significant biological impact.", "contributors": [{"name": "Ramesh, Archana  (Author)", "sameAs": [], "familyName": "Ramesh", "additionalName": "", "givenName": "Archana", "email": ""}, {"name": "Kim, Seungchan  (Advisor)", "sameAs": [], "familyName": "Kim", "additionalName": "", "givenName": "Seungchan", "email": ""}, {"name": "Langley, Patrick W (Committee member)", "sameAs": [], "familyName": "Langley", "additionalName": "W", "givenName": "Patrick", "email": ""}, {"name": "Baral, Chitta  (Committee member)", "sameAs": [], "familyName": "Baral", "additionalName": "", "givenName": "Chitta", "email": ""}, {"name": "Kiefer, Jeffrey  (Committee member)", "sameAs": [], "familyName": "Kiefer", "additionalName": "", "givenName": "Jeffrey", "email": ""}, {"name": "Arizona State University (Publisher)", "sameAs": [], "familyName": "University", "additionalName": "", "givenName": "Arizona", "email": ""}], "title": "Computational Methods for Knowledge Integration in the Analysis of Large-scale Biological Networks", "shareProperties": {"source": "asu"}, "otherProperties": [{"name": "type", "properties": {"type": "Doctoral Dissertation"}}, {"name": "format", "properties": {"format": "130 pages"}}, {"name": "date", "properties": {"date": "2012"}}, {"name": "description", "properties": {"description": ["abstract: As we migrate into an era of personalized medicine, understanding how bio-molecules interact with one another to form cellular systems is one of the key focus areas of systems biology. Several challenges such as the dynamic nature of cellular systems, uncertainty due to environmental influences, and the heterogeneity between individual patients render this a difficult task. In the last decade, several algorithms have been proposed to elucidate cellular systems from data, resulting in numerous data-driven hypotheses. However, due to the large number of variables involved in the process, many of which are unknown or not measurable, such computational approaches often lead to a high proportion of false positives. This renders interpretation of the data-driven hypotheses extremely difficult. Consequently, a dismal proportion of these hypotheses are subject to further experimental validation, eventually limiting their potential to augment existing biological knowledge. This dissertation develops a framework of computational methods for the analysis of such data-driven hypotheses leveraging existing biological knowledge. Specifically, I show how biological knowledge can be mapped onto these hypotheses and subsequently augmented through novel hypotheses. Biological hypotheses are learnt in three levels of abstraction -- individual interactions, functional modules and relationships between pathways, corresponding to three complementary aspects of biological systems. The computational methods developed in this dissertation are applied to high throughput cancer data, resulting in novel hypotheses with potentially significant biological impact.", "Dissertation/Thesis", "Ph.D. Computer Science 2012"]}}, {"name": "relation", "properties": {"relation": []}}, {"name": "setSpec", "properties": {"setSpec": ["collections:7", "research"]}}, {"name": "rights", "properties": {"rights": "All Rights Reserved"}}, {"name": "identifier", "properties": {"identifier": ["http://hdl.handle.net/2286/R.I.15204", "item:15204"]}}], "languages": [null], "subjects": ["microarray data", "bioinformatics", "knowledge integration", "computer science", "data mining", "machine learning", "gene regulatory networks", "artificial intelligence"], "providerUpdatedDateTime": "2015-02-12T01:13:51", "uris": {"canonicalUri": "http://hdl.handle.net/2286/R.I.15204"}}, {"publisher": {"name": ""}, "description": "  Interdependent networks are ubiquitous in our society, ranging from\ninfrastructure to economics, and the study of their cascading behaviors using\npercolation theory has attracted much attention in the recent years. To analyze\nthe percolation phenomena of these systems, different mathematical frameworks\nhave been proposed including generating functions, eigenvalues among some\nothers. These different frameworks approach the phase transition behaviors from\ndifferent angles, and have been very successful in shaping the different\nquantities of interest including critical threshold, size of the giant\ncomponent, order of phase transition and the dynamics of cascading. These\nmethods also vary in their mathematical complexity in dealing with\ninterdependent networks that have additional complexity in terms of the\ncorrelation among different layers of networks or links. In this work, we\nreview a particular approach of simple self-consistent probability equations,\nand illustrate that it can greatly simplify the mathematical analysis for\nsystems ranging from single layer network to various different interdependent\nnetworks. We give an overview on the detailed framework to study the nature of\nthe critical phase transition, value of the critical threshold and size of the\ngiant component for these different systems.\n", "contributors": [{"name": "Feng, Ling", "sameAs": [], "familyName": "Feng", "additionalName": "", "givenName": "Ling", "email": ""}, {"name": "Monterola, Christopher Pineda", "sameAs": [], "familyName": "Monterola", "additionalName": "Pineda", "givenName": "Christopher", "email": ""}, {"name": "Hu, Yanqing", "sameAs": [], "familyName": "Hu", "additionalName": "", "givenName": "Yanqing", "email": ""}], "title": "A Simplified Self-Consistent Probabilities Framework to Characterize\n  Percolation Phenomena on Interdependent Networks : An Overview", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-05"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01601", "oai:arXiv.org:1502.01601"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:cond-mat", "physics:physics"]}}, {"name": "description", "properties": {"description": "  Interdependent networks are ubiquitous in our society, ranging from\ninfrastructure to economics, and the study of their cascading behaviors using\npercolation theory has attracted much attention in the recent years. To analyze\nthe percolation phenomena of these systems, different mathematical frameworks\nhave been proposed including generating functions, eigenvalues among some\nothers. These different frameworks approach the phase transition behaviors from\ndifferent angles, and have been very successful in shaping the different\nquantities of interest including critical threshold, size of the giant\ncomponent, order of phase transition and the dynamics of cascading. These\nmethods also vary in their mathematical complexity in dealing with\ninterdependent networks that have additional complexity in terms of the\ncorrelation among different layers of networks or links. In this work, we\nreview a particular approach of simple self-consistent probability equations,\nand illustrate that it can greatly simplify the mathematical analysis for\nsystems ranging from single layer network to various different interdependent\nnetworks. We give an overview on the detailed framework to study the nature of\nthe critical phase transition, value of the critical threshold and size of the\ngiant component for these different systems.\n"}}], "languages": [null], "subjects": ["physics - physics and society", "condensed matter - statistical mechanics", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-02-06T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01601"}}, {"publisher": {"name": ""}, "description": "  We propose adaptation strategies to modify the standard constrained model\npredictive controller scheme in order to guarantee a certain lower bound on the\ndegree of suboptimality. Within this analysis, the length of the optimization\nhorizon is the parameter we wish to adapt. We develop and prove several\nshortening and prolongation strategies which also allow for an effective\nimplementation. Moreover, extensions of stability results and suboptimality\nestimates to model predictive controllers with varying optimization horizon are\nshown.\n", "contributors": [{"name": "Pannek, J\u00fcrgen", "sameAs": [], "familyName": "Pannek", "additionalName": "", "givenName": "J\u00fcrgen", "email": ""}], "title": "Horizon Adaptation for Nonlinear Model Predictive Controllers with\n  guaranteed Degree of Suboptimality", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2011-05-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1105.3037", "oai:arXiv.org:1105.3037"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "math"]}}, {"name": "description", "properties": {"description": ["  We propose adaptation strategies to modify the standard constrained model\npredictive controller scheme in order to guarantee a certain lower bound on the\ndegree of suboptimality. Within this analysis, the length of the optimization\nhorizon is the parameter we wish to adapt. We develop and prove several\nshortening and prolongation strategies which also allow for an effective\nimplementation. Moreover, extensions of stability results and suboptimality\nestimates to model predictive controllers with varying optimization horizon are\nshown.\n", "Comment: 20 pages, 3 figures"]}}], "languages": [null], "subjects": ["mathematics - optimization and control", "computer science - systems and control"], "providerUpdatedDateTime": "2015-03-19T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1105.3037"}}, {"publisher": {"name": ""}, "description": "  Background: Confirmation bias is the tendency to acquire or evaluate new\ninformation in a way that is consistent with one's preexisting beliefs. It is\nomnipresent in psychology, economics, and even scientific practices. Prior\ntheoretical research of this phenomenon has mainly focused on its economic\nimplications possibly missing its potential connections with broader notions of\ncognitive science. Methodology/Principal Findings: We formulate a\n(non-Bayesian) model for revising subjective probabilistic opinion of a\nconfirmationally-biased agent in the light of a persuasive opinion. The\nrevision rule ensures that the agent does not react to persuasion that is\neither far from his current opinion or coincides with it. We demonstrate that\nthe model accounts for the basic phenomenology of the social judgment theory,\nand allows to study various phenomena such as cognitive dissonance and\nboomerang effect. The model also displays the order of presentation effect|when\nconsecutively exposed to two opinions, the preference is given to the last\nopinion (recency) or the first opinion (primacy)|and relates recency to\nconfirmation bias. Finally, we study the model in the case of repeated\npersuasion and analyze its convergence properties. Conclusions: The standard\nBayesian approach to probabilistic opinion revision is inadequate for\ndescribing the observed phenomenology of persuasion process. The simple\nnon-Bayesian model proposed here does agree with this phenomenology and is\ncapable of reproducing a spectrum of effects observed in psychology:\nprimacy-recency phenomenon, boomerang effect and cognitive dissonance. We point\nout several limitations of the model that should motivate its future\ndevelopment.\n", "contributors": [{"name": "Allahverdyan, A. E.", "sameAs": [], "familyName": "Allahverdyan", "additionalName": "E.", "givenName": "A.", "email": ""}, {"name": "Galstyan, Aram", "sameAs": [], "familyName": "Galstyan", "additionalName": "", "givenName": "Aram", "email": ""}], "title": "Opinion Dynamics with Confirmation Bias", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2014-11-16"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1411.4328", "PLoS ONE 9(7), e99557 (2014)", "doi:10.1371/journal.pone.0099557", "oai:arXiv.org:1411.4328"]}}, {"name": "setSpec", "properties": {"setSpec": ["cs", "physics:physics"]}}, {"name": "description", "properties": {"description": ["  Background: Confirmation bias is the tendency to acquire or evaluate new\ninformation in a way that is consistent with one's preexisting beliefs. It is\nomnipresent in psychology, economics, and even scientific practices. Prior\ntheoretical research of this phenomenon has mainly focused on its economic\nimplications possibly missing its potential connections with broader notions of\ncognitive science. Methodology/Principal Findings: We formulate a\n(non-Bayesian) model for revising subjective probabilistic opinion of a\nconfirmationally-biased agent in the light of a persuasive opinion. The\nrevision rule ensures that the agent does not react to persuasion that is\neither far from his current opinion or coincides with it. We demonstrate that\nthe model accounts for the basic phenomenology of the social judgment theory,\nand allows to study various phenomena such as cognitive dissonance and\nboomerang effect. The model also displays the order of presentation effect|when\nconsecutively exposed to two opinions, the preference is given to the last\nopinion (recency) or the first opinion (primacy)|and relates recency to\nconfirmation bias. Finally, we study the model in the case of repeated\npersuasion and analyze its convergence properties. Conclusions: The standard\nBayesian approach to probabilistic opinion revision is inadequate for\ndescribing the observed phenomenology of persuasion process. The simple\nnon-Bayesian model proposed here does agree with this phenomenology and is\ncapable of reproducing a spectrum of effects observed in psychology:\nprimacy-recency phenomenon, boomerang effect and cognitive dissonance. We point\nout several limitations of the model that should motivate its future\ndevelopment.\n", "Comment: 18 pages"]}}], "languages": [null], "subjects": ["physics - physics and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2014-11-18T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1411.4328"}}, {"publisher": {"name": ""}, "description": "  We study the problem of maximizing constrained non-monotone submodular\nfunctions and provide approximation algorithms that improve existing algorithms\nin terms of either the approximation factor or simplicity. Our algorithms\ncombine existing local search and greedy based algorithms. Different\nconstraints that we study are exact cardinality and multiple knapsack\nconstraints. For the multiple-knapsack constraints we achieve a\n$(0.25-2\\epsilon)$-factor algorithm.\n  We also show, as our main contribution, how to use the continuous greedy\nprocess for non-monotone functions and, as a result, obtain a 0.13-factor\napproximation algorithm for maximization over any solvable down-monotone\npolytope. The continuous greedy process has been previously used for maximizing\nsmooth monotone submodular function over a down-monotone polytope\n\\cite{CCPV08}. This implies a 0.13-approximation for several discrete problems,\nsuch as maximizing a non-negative submodular function subject to a matroid\nconstraint and/or multiple knapsack constraints.\n", "contributors": [{"name": "Fadaei, Salman", "sameAs": [], "familyName": "Fadaei", "additionalName": "", "givenName": "Salman", "email": ""}, {"name": "Fazli, MohammadAmin", "sameAs": [], "familyName": "Fazli", "additionalName": "", "givenName": "MohammadAmin", "email": ""}, {"name": "Safari, MohammadAli", "sameAs": [], "familyName": "Safari", "additionalName": "", "givenName": "MohammadAli", "email": ""}], "title": "Maximizing Non-monotone Submodular Set Functions Subject to Different\n  Constraints: Combined Algorithms", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2011-01-15", "2011-07-10"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1101.2973", "oai:arXiv.org:1101.2973"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  We study the problem of maximizing constrained non-monotone submodular\nfunctions and provide approximation algorithms that improve existing algorithms\nin terms of either the approximation factor or simplicity. Our algorithms\ncombine existing local search and greedy based algorithms. Different\nconstraints that we study are exact cardinality and multiple knapsack\nconstraints. For the multiple-knapsack constraints we achieve a\n$(0.25-2\\epsilon)$-factor algorithm.\n  We also show, as our main contribution, how to use the continuous greedy\nprocess for non-monotone functions and, as a result, obtain a 0.13-factor\napproximation algorithm for maximization over any solvable down-monotone\npolytope. The continuous greedy process has been previously used for maximizing\nsmooth monotone submodular function over a down-monotone polytope\n\\cite{CCPV08}. This implies a 0.13-approximation for several discrete problems,\nsuch as maximizing a non-negative submodular function subject to a matroid\nconstraint and/or multiple knapsack constraints.\n"}}], "languages": [null], "subjects": ["computer science - data structures and algorithms"], "providerUpdatedDateTime": "2015-03-17T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1101.2973"}}, {"publisher": {"name": ""}, "description": "  This paper aims to present the different aspects and characteristics of\nstrategic and operational information and propose a categorization pattern\nallowing to consider an information as strategic or operational. This\ncategorization is to be used in the two decision making processes to assist its\nmining, and usage by the two related decision support systems. This is\nconducted trough the results of an investigative study of information used as\nbasis for strategic decisions inside three different companies.\n", "contributors": [{"name": "Abahmane, Omar", "sameAs": [], "familyName": "Abahmane", "additionalName": "", "givenName": "Omar", "email": ""}, {"name": "Binkkour, Mohamed", "sameAs": [], "familyName": "Binkkour", "additionalName": "", "givenName": "Mohamed", "email": ""}], "title": "Strategic and Operational information support of decision making\n  processes and systems", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-06"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.01803", "oai:arXiv.org:1502.01803"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  This paper aims to present the different aspects and characteristics of\nstrategic and operational information and propose a categorization pattern\nallowing to consider an information as strategic or operational. This\ncategorization is to be used in the two decision making processes to assist its\nmining, and usage by the two related decision support systems. This is\nconducted trough the results of an investigative study of information used as\nbasis for strategic decisions inside three different companies.\n", "Comment: Proceedings of the Information Systems and Business Intelligence\n  Conference, (SIIE-2008) Hammamet, Tunisia, February, 2008"]}}], "languages": [null], "subjects": ["computer science - computers and society"], "providerUpdatedDateTime": "2015-02-09T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.01803"}}, {"publisher": {"name": ""}, "description": "  Inspired by the brain, deep neural networks (DNN) are thought to learn\nabstract representations through their hierarchical architecture. However, at\npresent, how this happens is not well understood. Here, we demonstrate that DNN\nlearn abstract representations by a process of demodulation. We introduce a\nbiased sigmoid activation function and use it to show that DNN learn and\nperform better when optimized for demodulation. Our findings constitute the\nfirst unambiguous evidence that DNN perform abstract learning in practical use.\nOur findings may also explain abstract learning in the human brain.\n", "contributors": [{"name": "Simpson, Andrew J. R.", "sameAs": [], "familyName": "Simpson", "additionalName": "J. R.", "givenName": "Andrew", "email": ""}], "title": "Abstract Learning via Demodulation in a Deep Neural Network", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": "2015-02-13"}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1502.04042", "oai:arXiv.org:1502.04042"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": "  Inspired by the brain, deep neural networks (DNN) are thought to learn\nabstract representations through their hierarchical architecture. However, at\npresent, how this happens is not well understood. Here, we demonstrate that DNN\nlearn abstract representations by a process of demodulation. We introduce a\nbiased sigmoid activation function and use it to show that DNN learn and\nperform better when optimized for demodulation. Our findings constitute the\nfirst unambiguous evidence that DNN perform abstract learning in practical use.\nOur findings may also explain abstract learning in the human brain.\n"}}], "languages": [null], "subjects": ["computer science - neural and evolutionary computing", "computer science - learning", "68txx"], "providerUpdatedDateTime": "2015-02-16T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1502.04042"}}, {"publisher": {"name": ""}, "description": "  Wikipedia is a community-created encyclopedia that contains information about\nnotable people from different countries, epochs and disciplines and aims to\ndocument the world's knowledge from a neutral point of view. However, the\nnarrow diversity of the Wikipedia editor community has the potential to\nintroduce systemic biases such as gender biases into the content of Wikipedia.\nIn this paper we aim to tackle a sub problem of this larger challenge by\npresenting and applying a computational method for assessing gender bias on\nWikipedia along multiple dimensions. We find that while women on Wikipedia are\ncovered and featured well in many Wikipedia language editions, the way women\nare portrayed starkly differs from the way men are portrayed. We hope our work\ncontributes to increasing awareness about gender biases online, and in\nparticular to raising attention to the different levels in which gender biases\ncan manifest themselves on the web.\n", "contributors": [{"name": "Wagner, Claudia", "sameAs": [], "familyName": "Wagner", "additionalName": "", "givenName": "Claudia", "email": ""}, {"name": "Garcia, David", "sameAs": [], "familyName": "Garcia", "additionalName": "", "givenName": "David", "email": ""}, {"name": "Jadidi, Mohsen", "sameAs": [], "familyName": "Jadidi", "additionalName": "", "givenName": "Mohsen", "email": ""}, {"name": "Strohmaier, Markus", "sameAs": [], "familyName": "Strohmaier", "additionalName": "", "givenName": "Markus", "email": ""}], "title": "It's a Man's Wikipedia? Assessing Gender Inequality in an Online\n  Encyclopedia", "shareProperties": {"source": "arxiv_oai"}, "otherProperties": [{"name": "type", "properties": {"type": "text"}}, {"name": "format", "properties": {"format": []}}, {"name": "date", "properties": {"date": ["2015-01-26", "2015-03-23"]}}, {"name": "identifier", "properties": {"identifier": ["http://arxiv.org/abs/1501.06307", "oai:arXiv.org:1501.06307"]}}, {"name": "setSpec", "properties": {"setSpec": "cs"}}, {"name": "description", "properties": {"description": ["  Wikipedia is a community-created encyclopedia that contains information about\nnotable people from different countries, epochs and disciplines and aims to\ndocument the world's knowledge from a neutral point of view. However, the\nnarrow diversity of the Wikipedia editor community has the potential to\nintroduce systemic biases such as gender biases into the content of Wikipedia.\nIn this paper we aim to tackle a sub problem of this larger challenge by\npresenting and applying a computational method for assessing gender bias on\nWikipedia along multiple dimensions. We find that while women on Wikipedia are\ncovered and featured well in many Wikipedia language editions, the way women\nare portrayed starkly differs from the way men are portrayed. We hope our work\ncontributes to increasing awareness about gender biases online, and in\nparticular to raising attention to the different levels in which gender biases\ncan manifest themselves on the web.\n", "Comment: in The International AAAI Conference on Web and Social Media\n  (ICWSM2015), Oxford, May 2015"]}}], "languages": [null], "subjects": ["computer science - computers and society", "computer science - social and information networks"], "providerUpdatedDateTime": "2015-03-25T00:00:00", "uris": {"canonicalUri": "http://arxiv.org/abs/1501.06307"}}], "time": 0.05}